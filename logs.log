2023-07-26 18:17:13,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-26 18:17:13,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-26 18:17:13,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-26 18:17:13,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-26 18:17:15,695:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-26 19:06:25,063:INFO:PyCaret ClassificationExperiment
2023-07-26 19:06:25,063:INFO:Logging name: EXP_01
2023-07-26 19:06:25,063:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-26 19:06:25,063:INFO:version 3.0.0.rc9
2023-07-26 19:06:25,063:INFO:Initializing setup()
2023-07-26 19:06:25,063:INFO:self.USI: f367
2023-07-26 19:06:25,063:INFO:self._variable_keys: {'fold_generator', 'exp_id', 'target_param', 'fix_imbalance', 'USI', 'gpu_param', 'y_test', 'X_train', 'fold_groups_param', 'n_jobs_param', 'y', 'fold_shuffle_param', '_ml_usecase', 'data', 'idx', 'X_test', 'is_multiclass', 'html_param', 'pipeline', 'logging_param', '_available_plots', 'memory', 'y_train', 'exp_name_log', 'log_plots_param', 'X', 'gpu_n_jobs_param', 'seed'}
2023-07-26 19:06:25,063:INFO:Checking environment
2023-07-26 19:06:25,063:INFO:python_version: 3.9.13
2023-07-26 19:06:25,063:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-07-26 19:06:25,063:INFO:machine: AMD64
2023-07-26 19:06:25,070:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-26 19:06:25,073:INFO:Memory: svmem(total=8266518528, available=1077190656, percent=87.0, used=7189327872, free=1077190656)
2023-07-26 19:06:25,073:INFO:Physical Core: 4
2023-07-26 19:06:25,074:INFO:Logical Core: 8
2023-07-26 19:06:25,074:INFO:Checking libraries
2023-07-26 19:06:25,074:INFO:System:
2023-07-26 19:06:25,074:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-07-26 19:06:25,074:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-07-26 19:06:25,074:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-26 19:06:25,074:INFO:PyCaret required dependencies:
2023-07-26 19:06:25,078:INFO:                 pip: 22.2.2
2023-07-26 19:06:25,078:INFO:          setuptools: 63.4.1
2023-07-26 19:06:25,078:INFO:             pycaret: 3.0.0rc9
2023-07-26 19:06:25,078:INFO:             IPython: 7.31.1
2023-07-26 19:06:25,078:INFO:          ipywidgets: 7.6.5
2023-07-26 19:06:25,078:INFO:                tqdm: 4.64.1
2023-07-26 19:06:25,078:INFO:               numpy: 1.21.5
2023-07-26 19:06:25,078:INFO:              pandas: 1.4.4
2023-07-26 19:06:25,078:INFO:              jinja2: 3.0.3
2023-07-26 19:06:25,078:INFO:               scipy: 1.9.1
2023-07-26 19:06:25,078:INFO:              joblib: 1.2.0
2023-07-26 19:06:25,078:INFO:             sklearn: 1.0.2
2023-07-26 19:06:25,078:INFO:                pyod: 1.0.7
2023-07-26 19:06:25,082:INFO:            imblearn: 0.10.1
2023-07-26 19:06:25,082:INFO:   category_encoders: 2.6.0
2023-07-26 19:06:25,082:INFO:            lightgbm: 3.3.5
2023-07-26 19:06:25,082:INFO:               numba: 0.55.1
2023-07-26 19:06:25,082:INFO:            requests: 2.28.1
2023-07-26 19:06:25,082:INFO:          matplotlib: 3.5.2
2023-07-26 19:06:25,082:INFO:          scikitplot: 0.3.7
2023-07-26 19:06:25,082:INFO:         yellowbrick: 1.5
2023-07-26 19:06:25,082:INFO:              plotly: 5.9.0
2023-07-26 19:06:25,082:INFO:             kaleido: 0.2.1
2023-07-26 19:06:25,082:INFO:         statsmodels: 0.13.2
2023-07-26 19:06:25,083:INFO:              sktime: 0.16.1
2023-07-26 19:06:25,083:INFO:               tbats: 1.1.2
2023-07-26 19:06:25,083:INFO:            pmdarima: 2.0.2
2023-07-26 19:06:25,083:INFO:              psutil: 5.9.0
2023-07-26 19:06:25,083:INFO:PyCaret optional dependencies:
2023-07-26 19:06:25,122:INFO:                shap: Not installed
2023-07-26 19:06:25,122:INFO:           interpret: Not installed
2023-07-26 19:06:25,123:INFO:                umap: Not installed
2023-07-26 19:06:25,123:INFO:    pandas_profiling: 4.3.1
2023-07-26 19:06:25,123:INFO:  explainerdashboard: Not installed
2023-07-26 19:06:25,123:INFO:             autoviz: 0.1.720
2023-07-26 19:06:25,123:INFO:           fairlearn: Not installed
2023-07-26 19:06:25,123:INFO:             xgboost: 1.7.5
2023-07-26 19:06:25,123:INFO:            catboost: Not installed
2023-07-26 19:06:25,123:INFO:              kmodes: Not installed
2023-07-26 19:06:25,123:INFO:             mlxtend: Not installed
2023-07-26 19:06:25,123:INFO:       statsforecast: Not installed
2023-07-26 19:06:25,123:INFO:        tune_sklearn: Not installed
2023-07-26 19:06:25,123:INFO:                 ray: Not installed
2023-07-26 19:06:25,123:INFO:            hyperopt: Not installed
2023-07-26 19:06:25,123:INFO:              optuna: Not installed
2023-07-26 19:06:25,123:INFO:               skopt: Not installed
2023-07-26 19:06:25,123:INFO:              mlflow: Not installed
2023-07-26 19:06:25,123:INFO:              gradio: Not installed
2023-07-26 19:06:25,123:INFO:             fastapi: Not installed
2023-07-26 19:06:25,123:INFO:             uvicorn: Not installed
2023-07-26 19:06:25,123:INFO:              m2cgen: Not installed
2023-07-26 19:06:25,123:INFO:           evidently: Not installed
2023-07-26 19:06:25,123:INFO:               fugue: Not installed
2023-07-26 19:06:25,123:INFO:           streamlit: Not installed
2023-07-26 19:06:25,123:INFO:             prophet: Not installed
2023-07-26 19:06:25,123:INFO:None
2023-07-26 19:06:25,123:INFO:Set up data.
2023-07-26 19:06:25,273:INFO:Set up train/test split.
2023-07-26 19:06:25,340:INFO:Set up index.
2023-07-26 19:06:25,341:INFO:Set up folding strategy.
2023-07-26 19:06:25,342:INFO:Assigning column types.
2023-07-26 19:06:25,353:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-26 19:06:25,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-26 19:06:25,494:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-26 19:06:25,588:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:25,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:25,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-26 19:06:25,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-26 19:06:25,995:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:26,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:26,004:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-26 19:06:26,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-26 19:06:26,185:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:26,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:26,300:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-26 19:06:26,363:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:26,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:26,365:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-26 19:06:26,537:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:26,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:26,726:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:26,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:26,753:INFO:Preparing preprocessing pipeline...
2023-07-26 19:06:26,758:INFO:Set up simple imputation.
2023-07-26 19:06:26,767:INFO:Set up encoding of ordinal features.
2023-07-26 19:06:26,775:INFO:Set up encoding of categorical features.
2023-07-26 19:06:26,783:INFO:Set up feature normalization.
2023-07-26 19:06:27,182:INFO:Finished creating preprocessing pipeline.
2023-07-26 19:06:27,275:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_valu...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-07-26 19:06:27,275:INFO:Creating final display dataframe.
2023-07-26 19:06:28,327:INFO:Setup _display_container:                     Description            Value
0                    Session id             1935
1                        Target             ALVO
2                   Target type           Binary
3           Original data shape        (283, 14)
4        Transformed data shape        (283, 23)
5   Transformed train set shape        (198, 23)
6    Transformed test set shape         (85, 23)
7              Ordinal features                3
8              Numeric features                6
9          Categorical features                7
10     Rows with missing values             1.4%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           EXP_01
25                          USI             f367
2023-07-26 19:06:28,590:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:28,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:28,775:INFO:Soft dependency imported: xgboost: 1.7.5
2023-07-26 19:06:28,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-26 19:06:28,784:INFO:setup() successfully completed in 3.77s...............
2023-07-26 19:09:12,080:INFO:Initializing get_config()
2023-07-26 19:09:12,080:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, variable=X_train_transformed)
2023-07-26 19:09:12,146:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_4  Chest_pain_LEVEL_2  \
0   -1.159515  0.747700            1.051847           -0.414243   
1   -0.270086  0.747700           -0.950708            2.414039   
2    0.396987  0.747700            1.051847           -0.414243   
3   -0.603622 -1.337435            1.051847           -0.414243   
4   -1.715409  0.747700            1.051847           -0.414243   
..        ...       ...                 ...                 ...   
193  0.952880  0.747700           -0.950708           -0.414243   
194 -1.270694  0.747700           -0.950708           -0.414243   
195 -0.047728 -1.337435           -0.950708            2.414039   
196  0.396987  0.747700           -0.950708           -0.414243   
197 -2.271302 -1.337435           -0.950708            2.414039   

     Chest_pain_LEVEL_3  Chest_pain_LEVEL_1  Resting_blood_pressure  \
0             -0.691095           -0.242536               -1.108392   
1             -0.691095           -0.242536               -0.161416   
2             -0.691095           -0.242536               -1.818624   
3             -0.691095           -0.242536               -0.043044   
4             -0.691095           -0.242536               -0.753276   
..                  ...                 ...                     ...   
193           -0.691095            4.123106                0.844746   
194            1.446980           -0.242536               -0.043044   
195           -0.691095           -0.242536                0.075328   
196            1.446980           -0.242536               -1.522694   
197           -0.691095           -0.242536               -0.753276   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_2  ...  \
0            0.753778             0.463383             1.020410  ...   
1           -0.820569            -2.158041            -0.979998  ...   
2           -0.283439             0.463383            -0.979998  ...   
3            0.364822             0.463383            -0.979998  ...   
4           -0.561265             0.463383            -0.979998  ...   
..                ...                  ...                  ...  ...   
193         -0.301960            -2.158041             1.020410  ...   
194          1.216822             0.463383            -0.979998  ...   
195          0.716735            -2.158041             1.020410  ...   
196         -0.172308             0.463383             1.020410  ...   
197         -0.727960             0.463383            -0.979998  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                   0.153366                -0.764199      -0.929071   
1                   1.527613                -0.764199      -0.929071   
2                   0.286358                -0.764199      -0.840546   
3                   0.596671                -0.764199      -0.929071   
4                  -0.422931                -0.764199       0.133235   
..                       ...                      ...            ...   
193                 0.020374                -0.764199       1.107017   
194                 0.552341                -0.764199       0.752914   
195                 0.419349                 1.308560      -0.929071   
196                 0.197696                 1.308560      -0.397918   
197                 1.882258                -0.764199      -0.309392   

     Peak_exercise_ST_segment_LEVEL_1  Peak_exercise_ST_segment_LEVEL_2  \
0                            1.062559                         -0.931625   
1                            1.062559                         -0.931625   
2                            1.062559                         -0.931625   
3                            1.062559                         -0.931625   
4                           -0.941124                          1.073394   
..                                ...                               ...   
193                         -0.941124                         -0.931625   
194                          1.062559                         -0.931625   
195                          1.062559                         -0.931625   
196                         -0.941124                          1.073394   
197                          1.062559                         -0.931625   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_3  \
0                           -0.265085                 0.274107      0.867302   
1                           -0.265085                -0.744743      0.867302   
2                           -0.265085                 0.274107     -1.153001   
3                           -0.265085                -0.744743      0.867302   
4                           -0.265085                -0.744743     -1.153001   
..                                ...                      ...           ...   
193                          3.772369                -0.744743     -1.153001   
194                         -0.265085                 0.274107      0.867302   
195                         -0.265085                 0.274107      0.867302   
196                         -0.265085                -0.744743     -1.153001   
197                         -0.265085                -0.744743      0.867302   

     Thal_LEVEL_7  Thal_LEVEL_6  
0       -0.764199     -0.254000  
1       -0.764199     -0.254000  
2        1.308560     -0.254000  
3       -0.764199     -0.254000  
4        1.308560     -0.254000  
..            ...           ...  
193     -0.764199      3.937004  
194     -0.764199     -0.254000  
195     -0.764199     -0.254000  
196      1.308560     -0.254000  
197     -0.764199     -0.254000  

[198 rows x 22 columns]
2023-07-26 19:09:12,149:INFO:get_config() successfully completed......................................
2023-07-26 19:09:39,213:INFO:Initializing get_config()
2023-07-26 19:09:39,213:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, variable=X_train_transformed)
2023-07-26 19:09:39,271:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_4  Chest_pain_LEVEL_2  \
0   -1.159515  0.747700            1.051847           -0.414243   
1   -0.270086  0.747700           -0.950708            2.414039   
2    0.396987  0.747700            1.051847           -0.414243   
3   -0.603622 -1.337435            1.051847           -0.414243   
4   -1.715409  0.747700            1.051847           -0.414243   
..        ...       ...                 ...                 ...   
193  0.952880  0.747700           -0.950708           -0.414243   
194 -1.270694  0.747700           -0.950708           -0.414243   
195 -0.047728 -1.337435           -0.950708            2.414039   
196  0.396987  0.747700           -0.950708           -0.414243   
197 -2.271302 -1.337435           -0.950708            2.414039   

     Chest_pain_LEVEL_3  Chest_pain_LEVEL_1  Resting_blood_pressure  \
0             -0.691095           -0.242536               -1.108392   
1             -0.691095           -0.242536               -0.161416   
2             -0.691095           -0.242536               -1.818624   
3             -0.691095           -0.242536               -0.043044   
4             -0.691095           -0.242536               -0.753276   
..                  ...                 ...                     ...   
193           -0.691095            4.123106                0.844746   
194            1.446980           -0.242536               -0.043044   
195           -0.691095           -0.242536                0.075328   
196            1.446980           -0.242536               -1.522694   
197           -0.691095           -0.242536               -0.753276   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_2  ...  \
0            0.753778             0.463383             1.020410  ...   
1           -0.820569            -2.158041            -0.979998  ...   
2           -0.283439             0.463383            -0.979998  ...   
3            0.364822             0.463383            -0.979998  ...   
4           -0.561265             0.463383            -0.979998  ...   
..                ...                  ...                  ...  ...   
193         -0.301960            -2.158041             1.020410  ...   
194          1.216822             0.463383            -0.979998  ...   
195          0.716735            -2.158041             1.020410  ...   
196         -0.172308             0.463383             1.020410  ...   
197         -0.727960             0.463383            -0.979998  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                   0.153366                -0.764199      -0.929071   
1                   1.527613                -0.764199      -0.929071   
2                   0.286358                -0.764199      -0.840546   
3                   0.596671                -0.764199      -0.929071   
4                  -0.422931                -0.764199       0.133235   
..                       ...                      ...            ...   
193                 0.020374                -0.764199       1.107017   
194                 0.552341                -0.764199       0.752914   
195                 0.419349                 1.308560      -0.929071   
196                 0.197696                 1.308560      -0.397918   
197                 1.882258                -0.764199      -0.309392   

     Peak_exercise_ST_segment_LEVEL_1  Peak_exercise_ST_segment_LEVEL_2  \
0                            1.062559                         -0.931625   
1                            1.062559                         -0.931625   
2                            1.062559                         -0.931625   
3                            1.062559                         -0.931625   
4                           -0.941124                          1.073394   
..                                ...                               ...   
193                         -0.941124                         -0.931625   
194                          1.062559                         -0.931625   
195                          1.062559                         -0.931625   
196                         -0.941124                          1.073394   
197                          1.062559                         -0.931625   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_3  \
0                           -0.265085                 0.274107      0.867302   
1                           -0.265085                -0.744743      0.867302   
2                           -0.265085                 0.274107     -1.153001   
3                           -0.265085                -0.744743      0.867302   
4                           -0.265085                -0.744743     -1.153001   
..                                ...                      ...           ...   
193                          3.772369                -0.744743     -1.153001   
194                         -0.265085                 0.274107      0.867302   
195                         -0.265085                 0.274107      0.867302   
196                         -0.265085                -0.744743     -1.153001   
197                         -0.265085                -0.744743      0.867302   

     Thal_LEVEL_7  Thal_LEVEL_6  
0       -0.764199     -0.254000  
1       -0.764199     -0.254000  
2        1.308560     -0.254000  
3       -0.764199     -0.254000  
4        1.308560     -0.254000  
..            ...           ...  
193     -0.764199      3.937004  
194     -0.764199     -0.254000  
195     -0.764199     -0.254000  
196      1.308560     -0.254000  
197     -0.764199     -0.254000  

[198 rows x 22 columns]
2023-07-26 19:09:39,271:INFO:get_config() successfully completed......................................
2023-07-26 19:10:09,445:INFO:Initializing get_config()
2023-07-26 19:10:09,445:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, variable=X_test_transformed)
2023-07-26 19:10:09,503:INFO:Variable: X_test returned as           Age       Sex  Chest_pain_LEVEL_4  Chest_pain_LEVEL_2  \
198  0.285808 -1.337435            1.051847           -0.414243   
199  1.286416  0.747700            1.051847           -0.414243   
200 -0.270086  0.747700            1.051847           -0.414243   
201  0.508165 -1.337435            1.051847           -0.414243   
202  0.619344  0.747700            1.051847           -0.414243   
..        ...       ...                 ...                 ...   
278  0.508165  0.747700           -0.950708           -0.414243   
279 -0.270086  0.747700            1.051847           -0.414243   
280  0.508165  0.747700           -0.950708           -0.414243   
281 -2.271302  0.747700           -0.950708           -0.414243   
282  1.175237  0.747700            1.051847           -0.414243   

     Chest_pain_LEVEL_3  Chest_pain_LEVEL_1  Resting_blood_pressure  \
198           -0.691095           -0.242536               -0.161416   
199           -0.691095           -0.242536                1.732535   
200           -0.691095           -0.242536               -1.108392   
201           -0.691095           -0.242536                2.561139   
202           -0.691095           -0.242536               -0.043044   
..                  ...                 ...                     ...   
278           -0.691095            4.123106                0.193700   
279           -0.691095           -0.242536               -1.345136   
280           -0.691095            4.123106                2.324395   
281           -0.691095            4.123106               -0.753276   
282           -0.691095           -0.242536               -0.634904   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_2  ...  \
198          0.994561             0.463383             1.020410  ...   
199         -0.394569             0.463383             1.020410  ...   
200         -0.357526             0.463383            -0.979998  ...   
201         -0.005613             0.463383            -0.979998  ...   
202         -0.802047             0.463383             1.020410  ...   
..                ...                  ...                  ...  ...   
278         -0.839090             0.463383            -0.979998  ...   
279         -0.301960            -2.158041            -0.979998  ...   
280          0.716735             0.463383             1.020410  ...   
281         -1.246569             0.463383             1.020410  ...   
282         -1.339177             0.463383            -0.979998  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
198                 0.419349                -0.764199      -0.929071   
199                -0.511593                -0.764199       1.107017   
200                 0.463680                -0.764199      -0.929071   
201                -0.289940                 1.308560      -0.929071   
202                -0.777576                 1.308560       1.195542   
..                       ...                      ...            ...   
278                 0.552341                -0.764199      -0.220867   
279                -0.112618                -0.764199      -0.840546   
280                 0.419349                -0.764199      -0.752020   
281                 1.084308                -0.764199      -0.929071   
282                -0.422931                -0.764199      -0.574969   

     Peak_exercise_ST_segment_LEVEL_1  Peak_exercise_ST_segment_LEVEL_2  \
198                          1.062559                         -0.931625   
199                          1.062559                         -0.931625   
200                          1.062559                         -0.931625   
201                         -0.941124                          1.073394   
202                         -0.941124                          1.073394   
..                                ...                               ...   
278                          1.062559                         -0.931625   
279                          1.062559                         -0.931625   
280                         -0.941124                          1.073394   
281                          1.062559                         -0.931625   
282                          1.062559                         -0.931625   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_3  \
198                         -0.265085                 0.274107      0.867302   
199                         -0.265085                -0.744743     -1.153001   
200                         -0.265085                 0.274107      0.867302   
201                         -0.265085                -0.744743      0.867302   
202                         -0.265085                 1.292957     -1.153001   
..                                ...                      ...           ...   
278                         -0.265085                 1.292957      0.867302   
279                         -0.265085                 2.311808     -1.153001   
280                         -0.265085                -0.744743     -1.153001   
281                         -0.265085                -0.744743      0.867302   
282                         -0.265085                -0.744743     -1.153001   

     Thal_LEVEL_7  Thal_LEVEL_6  
198     -0.764199     -0.254000  
199     -0.764199      3.937004  
200     -0.764199     -0.254000  
201     -0.764199     -0.254000  
202      1.308560     -0.254000  
..            ...           ...  
278     -0.764199     -0.254000  
279      1.308560     -0.254000  
280      1.308560     -0.254000  
281     -0.764199     -0.254000  
282      1.308560     -0.254000  

[85 rows x 22 columns]
2023-07-26 19:10:09,503:INFO:get_config() successfully completed......................................
2023-07-26 19:15:05,860:INFO:Initializing compare_models()
2023-07-26 19:15:05,863:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-26 19:15:05,863:INFO:Checking exceptions
2023-07-26 19:15:05,871:INFO:Preparing display monitor
2023-07-26 19:15:05,975:INFO:Initializing Logistic Regression
2023-07-26 19:15:05,975:INFO:Total runtime is 0.0 minutes
2023-07-26 19:15:05,987:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:05,987:INFO:Initializing create_model()
2023-07-26 19:15:05,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:05,987:INFO:Checking exceptions
2023-07-26 19:15:05,987:INFO:Importing libraries
2023-07-26 19:15:05,987:INFO:Copying training dataset
2023-07-26 19:15:06,004:INFO:Defining folds
2023-07-26 19:15:06,004:INFO:Declaring metric variables
2023-07-26 19:15:06,013:INFO:Importing untrained model
2023-07-26 19:15:06,020:INFO:Logistic Regression Imported successfully
2023-07-26 19:15:06,037:INFO:Starting cross validation
2023-07-26 19:15:06,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:17,744:INFO:Calculating mean and std
2023-07-26 19:15:17,752:INFO:Creating metrics dataframe
2023-07-26 19:15:17,756:INFO:Uploading results into container
2023-07-26 19:15:17,756:INFO:Uploading model into container now
2023-07-26 19:15:17,756:INFO:_master_model_container: 1
2023-07-26 19:15:17,756:INFO:_display_container: 2
2023-07-26 19:15:17,756:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-26 19:15:17,756:INFO:create_model() successfully completed......................................
2023-07-26 19:15:17,997:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:17,997:INFO:Creating metrics dataframe
2023-07-26 19:15:18,022:INFO:Initializing K Neighbors Classifier
2023-07-26 19:15:18,022:INFO:Total runtime is 0.20077389081319172 minutes
2023-07-26 19:15:18,030:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:18,030:INFO:Initializing create_model()
2023-07-26 19:15:18,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:18,030:INFO:Checking exceptions
2023-07-26 19:15:18,030:INFO:Importing libraries
2023-07-26 19:15:18,030:INFO:Copying training dataset
2023-07-26 19:15:18,044:INFO:Defining folds
2023-07-26 19:15:18,044:INFO:Declaring metric variables
2023-07-26 19:15:18,049:INFO:Importing untrained model
2023-07-26 19:15:18,056:INFO:K Neighbors Classifier Imported successfully
2023-07-26 19:15:18,071:INFO:Starting cross validation
2023-07-26 19:15:18,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:19,200:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:19,201:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:19,226:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:19,226:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:19,234:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:19,245:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:19,534:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:20,147:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:20,194:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-07-26 19:15:20,264:INFO:Calculating mean and std
2023-07-26 19:15:20,266:INFO:Creating metrics dataframe
2023-07-26 19:15:20,273:INFO:Uploading results into container
2023-07-26 19:15:20,274:INFO:Uploading model into container now
2023-07-26 19:15:20,275:INFO:_master_model_container: 2
2023-07-26 19:15:20,275:INFO:_display_container: 2
2023-07-26 19:15:20,276:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-26 19:15:20,276:INFO:create_model() successfully completed......................................
2023-07-26 19:15:20,462:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:20,462:INFO:Creating metrics dataframe
2023-07-26 19:15:20,486:INFO:Initializing Naive Bayes
2023-07-26 19:15:20,487:INFO:Total runtime is 0.24186017513275146 minutes
2023-07-26 19:15:20,494:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:20,495:INFO:Initializing create_model()
2023-07-26 19:15:20,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:20,495:INFO:Checking exceptions
2023-07-26 19:15:20,495:INFO:Importing libraries
2023-07-26 19:15:20,495:INFO:Copying training dataset
2023-07-26 19:15:20,504:INFO:Defining folds
2023-07-26 19:15:20,504:INFO:Declaring metric variables
2023-07-26 19:15:20,514:INFO:Importing untrained model
2023-07-26 19:15:20,524:INFO:Naive Bayes Imported successfully
2023-07-26 19:15:20,537:INFO:Starting cross validation
2023-07-26 19:15:20,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:22,643:INFO:Calculating mean and std
2023-07-26 19:15:22,644:INFO:Creating metrics dataframe
2023-07-26 19:15:22,654:INFO:Uploading results into container
2023-07-26 19:15:22,654:INFO:Uploading model into container now
2023-07-26 19:15:22,658:INFO:_master_model_container: 3
2023-07-26 19:15:22,658:INFO:_display_container: 2
2023-07-26 19:15:22,658:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-26 19:15:22,658:INFO:create_model() successfully completed......................................
2023-07-26 19:15:22,818:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:22,818:INFO:Creating metrics dataframe
2023-07-26 19:15:22,835:INFO:Initializing Decision Tree Classifier
2023-07-26 19:15:22,835:INFO:Total runtime is 0.28099518616994223 minutes
2023-07-26 19:15:22,844:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:22,844:INFO:Initializing create_model()
2023-07-26 19:15:22,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:22,844:INFO:Checking exceptions
2023-07-26 19:15:22,844:INFO:Importing libraries
2023-07-26 19:15:22,844:INFO:Copying training dataset
2023-07-26 19:15:22,859:INFO:Defining folds
2023-07-26 19:15:22,860:INFO:Declaring metric variables
2023-07-26 19:15:22,867:INFO:Importing untrained model
2023-07-26 19:15:22,875:INFO:Decision Tree Classifier Imported successfully
2023-07-26 19:15:22,892:INFO:Starting cross validation
2023-07-26 19:15:22,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:25,060:INFO:Calculating mean and std
2023-07-26 19:15:25,064:INFO:Creating metrics dataframe
2023-07-26 19:15:25,068:INFO:Uploading results into container
2023-07-26 19:15:25,070:INFO:Uploading model into container now
2023-07-26 19:15:25,070:INFO:_master_model_container: 4
2023-07-26 19:15:25,070:INFO:_display_container: 2
2023-07-26 19:15:25,070:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-07-26 19:15:25,070:INFO:create_model() successfully completed......................................
2023-07-26 19:15:25,244:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:25,244:INFO:Creating metrics dataframe
2023-07-26 19:15:25,265:INFO:Initializing SVM - Linear Kernel
2023-07-26 19:15:25,265:INFO:Total runtime is 0.32149857680002847 minutes
2023-07-26 19:15:25,274:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:25,274:INFO:Initializing create_model()
2023-07-26 19:15:25,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:25,274:INFO:Checking exceptions
2023-07-26 19:15:25,274:INFO:Importing libraries
2023-07-26 19:15:25,274:INFO:Copying training dataset
2023-07-26 19:15:25,285:INFO:Defining folds
2023-07-26 19:15:25,285:INFO:Declaring metric variables
2023-07-26 19:15:25,297:INFO:Importing untrained model
2023-07-26 19:15:25,304:INFO:SVM - Linear Kernel Imported successfully
2023-07-26 19:15:25,315:INFO:Starting cross validation
2023-07-26 19:15:25,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:27,364:INFO:Calculating mean and std
2023-07-26 19:15:27,364:INFO:Creating metrics dataframe
2023-07-26 19:15:27,375:INFO:Uploading results into container
2023-07-26 19:15:27,375:INFO:Uploading model into container now
2023-07-26 19:15:27,379:INFO:_master_model_container: 5
2023-07-26 19:15:27,379:INFO:_display_container: 2
2023-07-26 19:15:27,379:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-26 19:15:27,379:INFO:create_model() successfully completed......................................
2023-07-26 19:15:27,574:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:27,574:INFO:Creating metrics dataframe
2023-07-26 19:15:27,598:INFO:Initializing Ridge Classifier
2023-07-26 19:15:27,601:INFO:Total runtime is 0.36043850183486936 minutes
2023-07-26 19:15:27,604:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:27,604:INFO:Initializing create_model()
2023-07-26 19:15:27,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:27,604:INFO:Checking exceptions
2023-07-26 19:15:27,604:INFO:Importing libraries
2023-07-26 19:15:27,604:INFO:Copying training dataset
2023-07-26 19:15:27,618:INFO:Defining folds
2023-07-26 19:15:27,618:INFO:Declaring metric variables
2023-07-26 19:15:27,624:INFO:Importing untrained model
2023-07-26 19:15:27,626:INFO:Ridge Classifier Imported successfully
2023-07-26 19:15:27,644:INFO:Starting cross validation
2023-07-26 19:15:27,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:29,604:INFO:Calculating mean and std
2023-07-26 19:15:29,614:INFO:Creating metrics dataframe
2023-07-26 19:15:29,621:INFO:Uploading results into container
2023-07-26 19:15:29,623:INFO:Uploading model into container now
2023-07-26 19:15:29,624:INFO:_master_model_container: 6
2023-07-26 19:15:29,624:INFO:_display_container: 2
2023-07-26 19:15:29,624:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1935, solver='auto', tol=0.001)
2023-07-26 19:15:29,624:INFO:create_model() successfully completed......................................
2023-07-26 19:15:29,814:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:29,814:INFO:Creating metrics dataframe
2023-07-26 19:15:29,842:INFO:Initializing Random Forest Classifier
2023-07-26 19:15:29,842:INFO:Total runtime is 0.39778588215510047 minutes
2023-07-26 19:15:29,850:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:29,850:INFO:Initializing create_model()
2023-07-26 19:15:29,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:29,850:INFO:Checking exceptions
2023-07-26 19:15:29,850:INFO:Importing libraries
2023-07-26 19:15:29,850:INFO:Copying training dataset
2023-07-26 19:15:29,858:INFO:Defining folds
2023-07-26 19:15:29,860:INFO:Declaring metric variables
2023-07-26 19:15:29,864:INFO:Importing untrained model
2023-07-26 19:15:29,874:INFO:Random Forest Classifier Imported successfully
2023-07-26 19:15:29,884:INFO:Starting cross validation
2023-07-26 19:15:29,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:31,573:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:31,574:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:31,578:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:31,672:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:31,673:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:33,404:INFO:Calculating mean and std
2023-07-26 19:15:33,408:INFO:Creating metrics dataframe
2023-07-26 19:15:33,415:INFO:Uploading results into container
2023-07-26 19:15:33,416:INFO:Uploading model into container now
2023-07-26 19:15:33,416:INFO:_master_model_container: 7
2023-07-26 19:15:33,416:INFO:_display_container: 2
2023-07-26 19:15:33,416:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-07-26 19:15:33,416:INFO:create_model() successfully completed......................................
2023-07-26 19:15:33,595:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:33,595:INFO:Creating metrics dataframe
2023-07-26 19:15:33,624:INFO:Initializing Quadratic Discriminant Analysis
2023-07-26 19:15:33,625:INFO:Total runtime is 0.4608364820480346 minutes
2023-07-26 19:15:33,628:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:33,628:INFO:Initializing create_model()
2023-07-26 19:15:33,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:33,628:INFO:Checking exceptions
2023-07-26 19:15:33,633:INFO:Importing libraries
2023-07-26 19:15:33,633:INFO:Copying training dataset
2023-07-26 19:15:33,636:INFO:Defining folds
2023-07-26 19:15:33,636:INFO:Declaring metric variables
2023-07-26 19:15:33,645:INFO:Importing untrained model
2023-07-26 19:15:33,654:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-26 19:15:33,669:INFO:Starting cross validation
2023-07-26 19:15:33,669:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:34,214:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:34,214:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:34,240:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:34,249:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:34,254:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:34,254:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:34,318:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:35,325:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:35,335:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-26 19:15:35,796:INFO:Calculating mean and std
2023-07-26 19:15:35,804:INFO:Creating metrics dataframe
2023-07-26 19:15:35,805:INFO:Uploading results into container
2023-07-26 19:15:35,805:INFO:Uploading model into container now
2023-07-26 19:15:35,811:INFO:_master_model_container: 8
2023-07-26 19:15:35,811:INFO:_display_container: 2
2023-07-26 19:15:35,811:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-26 19:15:35,811:INFO:create_model() successfully completed......................................
2023-07-26 19:15:36,008:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:36,008:INFO:Creating metrics dataframe
2023-07-26 19:15:36,035:INFO:Initializing Ada Boost Classifier
2023-07-26 19:15:36,035:INFO:Total runtime is 0.5009981195131937 minutes
2023-07-26 19:15:36,044:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:36,044:INFO:Initializing create_model()
2023-07-26 19:15:36,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:36,045:INFO:Checking exceptions
2023-07-26 19:15:36,045:INFO:Importing libraries
2023-07-26 19:15:36,045:INFO:Copying training dataset
2023-07-26 19:15:36,048:INFO:Defining folds
2023-07-26 19:15:36,048:INFO:Declaring metric variables
2023-07-26 19:15:36,059:INFO:Importing untrained model
2023-07-26 19:15:36,064:INFO:Ada Boost Classifier Imported successfully
2023-07-26 19:15:36,083:INFO:Starting cross validation
2023-07-26 19:15:36,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:39,164:INFO:Calculating mean and std
2023-07-26 19:15:39,167:INFO:Creating metrics dataframe
2023-07-26 19:15:39,176:INFO:Uploading results into container
2023-07-26 19:15:39,177:INFO:Uploading model into container now
2023-07-26 19:15:39,177:INFO:_master_model_container: 9
2023-07-26 19:15:39,177:INFO:_display_container: 2
2023-07-26 19:15:39,177:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1935)
2023-07-26 19:15:39,177:INFO:create_model() successfully completed......................................
2023-07-26 19:15:39,365:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:39,365:INFO:Creating metrics dataframe
2023-07-26 19:15:39,396:INFO:Initializing Gradient Boosting Classifier
2023-07-26 19:15:39,396:INFO:Total runtime is 0.5570205489794413 minutes
2023-07-26 19:15:39,405:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:39,405:INFO:Initializing create_model()
2023-07-26 19:15:39,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:39,405:INFO:Checking exceptions
2023-07-26 19:15:39,405:INFO:Importing libraries
2023-07-26 19:15:39,405:INFO:Copying training dataset
2023-07-26 19:15:39,414:INFO:Defining folds
2023-07-26 19:15:39,418:INFO:Declaring metric variables
2023-07-26 19:15:39,424:INFO:Importing untrained model
2023-07-26 19:15:39,428:INFO:Gradient Boosting Classifier Imported successfully
2023-07-26 19:15:39,443:INFO:Starting cross validation
2023-07-26 19:15:39,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:40,875:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:42,335:INFO:Calculating mean and std
2023-07-26 19:15:42,339:INFO:Creating metrics dataframe
2023-07-26 19:15:42,347:INFO:Uploading results into container
2023-07-26 19:15:42,347:INFO:Uploading model into container now
2023-07-26 19:15:42,347:INFO:_master_model_container: 10
2023-07-26 19:15:42,347:INFO:_display_container: 2
2023-07-26 19:15:42,353:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-26 19:15:42,353:INFO:create_model() successfully completed......................................
2023-07-26 19:15:42,545:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:42,545:INFO:Creating metrics dataframe
2023-07-26 19:15:42,565:INFO:Initializing Linear Discriminant Analysis
2023-07-26 19:15:42,565:INFO:Total runtime is 0.6098319927851359 minutes
2023-07-26 19:15:42,575:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:42,575:INFO:Initializing create_model()
2023-07-26 19:15:42,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:42,575:INFO:Checking exceptions
2023-07-26 19:15:42,575:INFO:Importing libraries
2023-07-26 19:15:42,575:INFO:Copying training dataset
2023-07-26 19:15:42,587:INFO:Defining folds
2023-07-26 19:15:42,587:INFO:Declaring metric variables
2023-07-26 19:15:42,595:INFO:Importing untrained model
2023-07-26 19:15:42,601:INFO:Linear Discriminant Analysis Imported successfully
2023-07-26 19:15:42,614:INFO:Starting cross validation
2023-07-26 19:15:42,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:44,695:INFO:Calculating mean and std
2023-07-26 19:15:44,704:INFO:Creating metrics dataframe
2023-07-26 19:15:44,714:INFO:Uploading results into container
2023-07-26 19:15:44,715:INFO:Uploading model into container now
2023-07-26 19:15:44,715:INFO:_master_model_container: 11
2023-07-26 19:15:44,715:INFO:_display_container: 2
2023-07-26 19:15:44,715:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-26 19:15:44,715:INFO:create_model() successfully completed......................................
2023-07-26 19:15:44,854:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:44,854:INFO:Creating metrics dataframe
2023-07-26 19:15:44,877:INFO:Initializing Extra Trees Classifier
2023-07-26 19:15:44,877:INFO:Total runtime is 0.6483595927556356 minutes
2023-07-26 19:15:44,885:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:44,885:INFO:Initializing create_model()
2023-07-26 19:15:44,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:44,885:INFO:Checking exceptions
2023-07-26 19:15:44,885:INFO:Importing libraries
2023-07-26 19:15:44,885:INFO:Copying training dataset
2023-07-26 19:15:44,895:INFO:Defining folds
2023-07-26 19:15:44,895:INFO:Declaring metric variables
2023-07-26 19:15:44,904:INFO:Importing untrained model
2023-07-26 19:15:44,915:INFO:Extra Trees Classifier Imported successfully
2023-07-26 19:15:44,935:INFO:Starting cross validation
2023-07-26 19:15:44,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:46,681:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:46,713:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:46,725:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:46,735:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:46,746:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:46,778:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:46,843:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:46,888:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-26 19:15:48,574:INFO:Calculating mean and std
2023-07-26 19:15:48,574:INFO:Creating metrics dataframe
2023-07-26 19:15:48,585:INFO:Uploading results into container
2023-07-26 19:15:48,585:INFO:Uploading model into container now
2023-07-26 19:15:48,585:INFO:_master_model_container: 12
2023-07-26 19:15:48,585:INFO:_display_container: 2
2023-07-26 19:15:48,585:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-07-26 19:15:48,585:INFO:create_model() successfully completed......................................
2023-07-26 19:15:48,784:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:48,784:INFO:Creating metrics dataframe
2023-07-26 19:15:48,815:INFO:Initializing Extreme Gradient Boosting
2023-07-26 19:15:48,818:INFO:Total runtime is 0.7140549222628276 minutes
2023-07-26 19:15:48,827:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:48,827:INFO:Initializing create_model()
2023-07-26 19:15:48,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:48,827:INFO:Checking exceptions
2023-07-26 19:15:48,827:INFO:Importing libraries
2023-07-26 19:15:48,827:INFO:Copying training dataset
2023-07-26 19:15:48,844:INFO:Defining folds
2023-07-26 19:15:48,844:INFO:Declaring metric variables
2023-07-26 19:15:48,855:INFO:Importing untrained model
2023-07-26 19:15:48,865:INFO:Extreme Gradient Boosting Imported successfully
2023-07-26 19:15:48,880:INFO:Starting cross validation
2023-07-26 19:15:48,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:51,254:INFO:Calculating mean and std
2023-07-26 19:15:51,259:INFO:Creating metrics dataframe
2023-07-26 19:15:51,265:INFO:Uploading results into container
2023-07-26 19:15:51,265:INFO:Uploading model into container now
2023-07-26 19:15:51,265:INFO:_master_model_container: 13
2023-07-26 19:15:51,265:INFO:_display_container: 2
2023-07-26 19:15:51,273:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-07-26 19:15:51,274:INFO:create_model() successfully completed......................................
2023-07-26 19:15:51,474:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:51,474:INFO:Creating metrics dataframe
2023-07-26 19:15:51,505:INFO:Initializing Light Gradient Boosting Machine
2023-07-26 19:15:51,505:INFO:Total runtime is 0.758830217520396 minutes
2023-07-26 19:15:51,514:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:51,517:INFO:Initializing create_model()
2023-07-26 19:15:51,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:51,518:INFO:Checking exceptions
2023-07-26 19:15:51,518:INFO:Importing libraries
2023-07-26 19:15:51,518:INFO:Copying training dataset
2023-07-26 19:15:51,534:INFO:Defining folds
2023-07-26 19:15:51,536:INFO:Declaring metric variables
2023-07-26 19:15:51,545:INFO:Importing untrained model
2023-07-26 19:15:51,554:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-26 19:15:51,565:INFO:Starting cross validation
2023-07-26 19:15:51,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:56,535:INFO:Calculating mean and std
2023-07-26 19:15:56,535:INFO:Creating metrics dataframe
2023-07-26 19:15:56,554:INFO:Uploading results into container
2023-07-26 19:15:56,555:INFO:Uploading model into container now
2023-07-26 19:15:56,555:INFO:_master_model_container: 14
2023-07-26 19:15:56,555:INFO:_display_container: 2
2023-07-26 19:15:56,555:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-26 19:15:56,555:INFO:create_model() successfully completed......................................
2023-07-26 19:15:56,753:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:56,753:INFO:Creating metrics dataframe
2023-07-26 19:15:56,764:INFO:Initializing Dummy Classifier
2023-07-26 19:15:56,764:INFO:Total runtime is 0.8464829007784527 minutes
2023-07-26 19:15:56,775:INFO:SubProcess create_model() called ==================================
2023-07-26 19:15:56,775:INFO:Initializing create_model()
2023-07-26 19:15:56,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEA44FA0>, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:56,775:INFO:Checking exceptions
2023-07-26 19:15:56,775:INFO:Importing libraries
2023-07-26 19:15:56,775:INFO:Copying training dataset
2023-07-26 19:15:56,790:INFO:Defining folds
2023-07-26 19:15:56,790:INFO:Declaring metric variables
2023-07-26 19:15:56,795:INFO:Importing untrained model
2023-07-26 19:15:56,809:INFO:Dummy Classifier Imported successfully
2023-07-26 19:15:56,824:INFO:Starting cross validation
2023-07-26 19:15:56,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:15:57,955:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:57,977:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:57,985:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:57,996:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:57,996:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:58,003:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:58,023:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:58,075:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:58,833:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:58,834:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-26 19:15:58,846:INFO:Calculating mean and std
2023-07-26 19:15:58,846:INFO:Creating metrics dataframe
2023-07-26 19:15:58,858:INFO:Uploading results into container
2023-07-26 19:15:58,858:INFO:Uploading model into container now
2023-07-26 19:15:58,858:INFO:_master_model_container: 15
2023-07-26 19:15:58,862:INFO:_display_container: 2
2023-07-26 19:15:58,862:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-07-26 19:15:58,863:INFO:create_model() successfully completed......................................
2023-07-26 19:15:59,063:INFO:SubProcess create_model() end ==================================
2023-07-26 19:15:59,063:INFO:Creating metrics dataframe
2023-07-26 19:15:59,121:INFO:Initializing create_model()
2023-07-26 19:15:59,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:15:59,124:INFO:Checking exceptions
2023-07-26 19:15:59,127:INFO:Importing libraries
2023-07-26 19:15:59,127:INFO:Copying training dataset
2023-07-26 19:15:59,138:INFO:Defining folds
2023-07-26 19:15:59,138:INFO:Declaring metric variables
2023-07-26 19:15:59,138:INFO:Importing untrained model
2023-07-26 19:15:59,138:INFO:Declaring custom model
2023-07-26 19:15:59,138:INFO:Logistic Regression Imported successfully
2023-07-26 19:15:59,145:INFO:Cross validation set to False
2023-07-26 19:15:59,145:INFO:Fitting Model
2023-07-26 19:15:59,486:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-26 19:15:59,486:INFO:create_model() successfully completed......................................
2023-07-26 19:15:59,764:INFO:_master_model_container: 15
2023-07-26 19:15:59,765:INFO:_display_container: 2
2023-07-26 19:15:59,765:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-26 19:15:59,765:INFO:compare_models() successfully completed......................................
2023-07-26 19:19:35,118:INFO:Initializing create_model()
2023-07-26 19:19:35,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:19:35,123:INFO:Checking exceptions
2023-07-26 19:19:35,207:INFO:Importing libraries
2023-07-26 19:19:35,207:INFO:Copying training dataset
2023-07-26 19:19:35,230:INFO:Defining folds
2023-07-26 19:19:35,232:INFO:Declaring metric variables
2023-07-26 19:19:35,235:INFO:Importing untrained model
2023-07-26 19:19:35,244:INFO:Logistic Regression Imported successfully
2023-07-26 19:19:35,257:INFO:Starting cross validation
2023-07-26 19:19:35,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:19:36,413:INFO:Calculating mean and std
2023-07-26 19:19:36,417:INFO:Creating metrics dataframe
2023-07-26 19:19:36,434:INFO:Finalizing model
2023-07-26 19:19:36,794:INFO:Uploading results into container
2023-07-26 19:19:36,801:INFO:Uploading model into container now
2023-07-26 19:19:36,831:INFO:_master_model_container: 16
2023-07-26 19:19:36,831:INFO:_display_container: 3
2023-07-26 19:19:36,831:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-26 19:19:36,833:INFO:create_model() successfully completed......................................
2023-07-26 19:22:56,405:INFO:Initializing create_model()
2023-07-26 19:22:56,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:22:56,405:INFO:Checking exceptions
2023-07-26 19:22:56,454:INFO:Importing libraries
2023-07-26 19:22:56,454:INFO:Copying training dataset
2023-07-26 19:22:56,465:INFO:Defining folds
2023-07-26 19:22:56,465:INFO:Declaring metric variables
2023-07-26 19:22:56,474:INFO:Importing untrained model
2023-07-26 19:22:56,485:INFO:Extreme Gradient Boosting Imported successfully
2023-07-26 19:22:56,497:INFO:Starting cross validation
2023-07-26 19:22:56,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:22:57,785:INFO:Calculating mean and std
2023-07-26 19:22:57,787:INFO:Creating metrics dataframe
2023-07-26 19:22:57,795:INFO:Finalizing model
2023-07-26 19:22:58,284:INFO:Uploading results into container
2023-07-26 19:22:58,285:INFO:Uploading model into container now
2023-07-26 19:22:58,304:INFO:_master_model_container: 17
2023-07-26 19:22:58,304:INFO:_display_container: 4
2023-07-26 19:22:58,307:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-07-26 19:22:58,307:INFO:create_model() successfully completed......................................
2023-07-26 19:28:02,212:INFO:Initializing predict_model()
2023-07-26 19:28:02,212:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223DF5E8C10>)
2023-07-26 19:28:02,212:INFO:Checking exceptions
2023-07-26 19:28:02,212:INFO:Preloading libraries
2023-07-26 19:28:41,615:INFO:Initializing predict_model()
2023-07-26 19:28:41,619:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223DF3C5700>)
2023-07-26 19:28:41,619:INFO:Checking exceptions
2023-07-26 19:28:41,620:INFO:Preloading libraries
2023-07-26 19:29:35,225:INFO:Initializing create_model()
2023-07-26 19:29:35,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:29:35,228:INFO:Checking exceptions
2023-07-26 19:29:35,282:INFO:Importing libraries
2023-07-26 19:29:35,282:INFO:Copying training dataset
2023-07-26 19:29:35,291:INFO:Defining folds
2023-07-26 19:29:35,291:INFO:Declaring metric variables
2023-07-26 19:29:35,300:INFO:Importing untrained model
2023-07-26 19:29:35,311:INFO:Random Forest Classifier Imported successfully
2023-07-26 19:29:35,322:INFO:Starting cross validation
2023-07-26 19:29:35,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:29:45,305:INFO:Calculating mean and std
2023-07-26 19:29:45,310:INFO:Creating metrics dataframe
2023-07-26 19:29:45,322:INFO:Finalizing model
2023-07-26 19:29:46,145:INFO:Uploading results into container
2023-07-26 19:29:46,145:INFO:Uploading model into container now
2023-07-26 19:29:46,170:INFO:_master_model_container: 18
2023-07-26 19:29:46,170:INFO:_display_container: 7
2023-07-26 19:29:46,171:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-07-26 19:29:46,171:INFO:create_model() successfully completed......................................
2023-07-26 19:29:57,681:INFO:Initializing predict_model()
2023-07-26 19:29:57,681:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223DF3C5430>)
2023-07-26 19:29:57,681:INFO:Checking exceptions
2023-07-26 19:29:57,681:INFO:Preloading libraries
2023-07-26 19:41:16,738:INFO:Initializing tune_model()
2023-07-26 19:41:16,742:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>)
2023-07-26 19:41:16,742:INFO:Checking exceptions
2023-07-26 19:41:16,929:INFO:Copying training dataset
2023-07-26 19:41:16,938:INFO:Checking base model
2023-07-26 19:41:16,947:INFO:Base model : Logistic Regression
2023-07-26 19:41:16,957:INFO:Declaring metric variables
2023-07-26 19:41:16,967:INFO:Defining Hyperparameters
2023-07-26 19:41:17,497:INFO:Tuning with n_jobs=-1
2023-07-26 19:41:17,497:INFO:Initializing RandomizedSearchCV
2023-07-26 19:41:39,238:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 9.137}
2023-07-26 19:41:39,248:INFO:Hyperparameter search completed
2023-07-26 19:41:39,248:INFO:SubProcess create_model() called ==================================
2023-07-26 19:41:39,248:INFO:Initializing create_model()
2023-07-26 19:41:39,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000223DEC6E820>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 9.137})
2023-07-26 19:41:39,248:INFO:Checking exceptions
2023-07-26 19:41:39,248:INFO:Importing libraries
2023-07-26 19:41:39,248:INFO:Copying training dataset
2023-07-26 19:41:39,266:INFO:Defining folds
2023-07-26 19:41:39,267:INFO:Declaring metric variables
2023-07-26 19:41:39,271:INFO:Importing untrained model
2023-07-26 19:41:39,271:INFO:Declaring custom model
2023-07-26 19:41:39,286:INFO:Logistic Regression Imported successfully
2023-07-26 19:41:39,297:INFO:Starting cross validation
2023-07-26 19:41:39,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:41:40,771:INFO:Calculating mean and std
2023-07-26 19:41:40,771:INFO:Creating metrics dataframe
2023-07-26 19:41:40,787:INFO:Finalizing model
2023-07-26 19:41:41,119:INFO:Uploading results into container
2023-07-26 19:41:41,119:INFO:Uploading model into container now
2023-07-26 19:41:41,119:INFO:_master_model_container: 19
2023-07-26 19:41:41,119:INFO:_display_container: 9
2023-07-26 19:41:41,126:INFO:LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-26 19:41:41,126:INFO:create_model() successfully completed......................................
2023-07-26 19:41:41,338:INFO:SubProcess create_model() end ==================================
2023-07-26 19:41:41,338:INFO:choose_better activated
2023-07-26 19:41:41,347:INFO:SubProcess create_model() called ==================================
2023-07-26 19:41:41,347:INFO:Initializing create_model()
2023-07-26 19:41:41,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-26 19:41:41,354:INFO:Checking exceptions
2023-07-26 19:41:41,357:INFO:Importing libraries
2023-07-26 19:41:41,357:INFO:Copying training dataset
2023-07-26 19:41:41,367:INFO:Defining folds
2023-07-26 19:41:41,367:INFO:Declaring metric variables
2023-07-26 19:41:41,367:INFO:Importing untrained model
2023-07-26 19:41:41,367:INFO:Declaring custom model
2023-07-26 19:41:41,367:INFO:Logistic Regression Imported successfully
2023-07-26 19:41:41,367:INFO:Starting cross validation
2023-07-26 19:41:41,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-26 19:41:42,817:INFO:Calculating mean and std
2023-07-26 19:41:42,817:INFO:Creating metrics dataframe
2023-07-26 19:41:42,828:INFO:Finalizing model
2023-07-26 19:41:43,141:INFO:Uploading results into container
2023-07-26 19:41:43,141:INFO:Uploading model into container now
2023-07-26 19:41:43,141:INFO:_master_model_container: 20
2023-07-26 19:41:43,141:INFO:_display_container: 10
2023-07-26 19:41:43,141:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-26 19:41:43,141:INFO:create_model() successfully completed......................................
2023-07-26 19:41:43,338:INFO:SubProcess create_model() end ==================================
2023-07-26 19:41:43,338:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8592
2023-07-26 19:41:43,338:INFO:LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8645
2023-07-26 19:41:43,338:INFO:LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-07-26 19:41:43,338:INFO:choose_better completed
2023-07-26 19:41:43,367:INFO:_master_model_container: 20
2023-07-26 19:41:43,367:INFO:_display_container: 9
2023-07-26 19:41:43,367:INFO:LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-26 19:41:43,367:INFO:tune_model() successfully completed......................................
2023-07-26 19:42:13,467:INFO:Initializing predict_model()
2023-07-26 19:42:13,467:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223DF42DDC0>)
2023-07-26 19:42:13,467:INFO:Checking exceptions
2023-07-26 19:42:13,467:INFO:Preloading libraries
2023-07-26 19:43:54,936:INFO:Initializing plot_model()
2023-07-26 19:43:54,936:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, system=True)
2023-07-26 19:43:54,937:INFO:Checking exceptions
2023-07-26 19:43:54,944:INFO:Preloading libraries
2023-07-26 19:43:54,944:INFO:Copying training dataset
2023-07-26 19:43:54,944:INFO:Plot type: ks
2023-07-26 19:43:54,944:INFO:Generating predictions / predict_proba on X_test
2023-07-26 19:43:55,596:INFO:Visual Rendered Successfully
2023-07-26 19:43:55,769:INFO:plot_model() successfully completed......................................
2023-07-26 19:50:03,578:INFO:Initializing plot_model()
2023-07-26 19:50:03,586:INFO:plot_model(plot=auc, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, system=True)
2023-07-26 19:50:03,586:INFO:Checking exceptions
2023-07-26 19:50:03,682:INFO:Preloading libraries
2023-07-26 19:50:03,688:INFO:Copying training dataset
2023-07-26 19:50:03,688:INFO:Plot type: auc
2023-07-26 19:50:03,923:INFO:Fitting Model
2023-07-26 19:50:03,937:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-07-26 19:50:03,937:INFO:Scoring test/hold-out set
2023-07-26 19:50:04,341:INFO:Visual Rendered Successfully
2023-07-26 19:50:04,919:INFO:plot_model() successfully completed......................................
2023-07-26 19:50:13,946:INFO:Initializing plot_model()
2023-07-26 19:50:13,946:INFO:plot_model(plot=ks, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, system=True)
2023-07-26 19:50:13,946:INFO:Checking exceptions
2023-07-26 19:50:13,957:INFO:Preloading libraries
2023-07-26 19:50:13,957:INFO:Copying training dataset
2023-07-26 19:50:13,957:INFO:Plot type: ks
2023-07-26 19:50:13,957:INFO:Generating predictions / predict_proba on X_test
2023-07-26 19:50:14,329:INFO:Visual Rendered Successfully
2023-07-26 19:50:14,487:INFO:plot_model() successfully completed......................................
2023-07-26 19:50:25,797:INFO:Initializing plot_model()
2023-07-26 19:50:25,805:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, system=True)
2023-07-26 19:50:25,805:INFO:Checking exceptions
2023-07-26 19:50:25,811:INFO:Preloading libraries
2023-07-26 19:50:25,813:INFO:Copying training dataset
2023-07-26 19:50:25,813:INFO:Plot type: ks
2023-07-26 19:50:25,813:INFO:Generating predictions / predict_proba on X_test
2023-07-26 19:50:26,173:INFO:Visual Rendered Successfully
2023-07-26 19:50:26,319:INFO:plot_model() successfully completed......................................
2023-07-26 19:51:02,051:INFO:Initializing plot_model()
2023-07-26 19:51:02,051:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=9.137, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, system=True)
2023-07-26 19:51:02,051:INFO:Checking exceptions
2023-07-26 19:51:02,062:INFO:Preloading libraries
2023-07-26 19:51:02,062:INFO:Copying training dataset
2023-07-26 19:51:02,062:INFO:Plot type: ks
2023-07-26 19:51:02,062:INFO:Generating predictions / predict_proba on X_test
2023-07-26 19:51:02,540:INFO:Visual Rendered Successfully
2023-07-26 19:51:02,702:INFO:plot_model() successfully completed......................................
2023-07-26 20:03:49,070:INFO:Initializing get_config()
2023-07-26 20:03:49,088:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, variable=X_train)
2023-07-26 20:03:49,104:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-07-26 20:03:49,119:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-07-26 20:03:49,293:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     44    MALE    LEVEL_4                     112               290   
1     52    MALE    LEVEL_2                     128               205   
2     58    MALE    LEVEL_4                     100               234   
3     49  FEMALE    LEVEL_4                     130               269   
4     39    MALE    LEVEL_4                     118               219   
..   ...     ...        ...                     ...               ...   
193   63    MALE    LEVEL_1                     145               233   
194   43    MALE    LEVEL_3                     130               315   
195   54  FEMALE    LEVEL_2                     132               288   
196   58    MALE    LEVEL_3                     105               240   
197   34  FEMALE    LEVEL_2                     118               210   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_2                      153   
1                  HIGH     LEVEL_0                      184   
2                   LOW     LEVEL_0                      156   
3                   LOW     LEVEL_0                      163   
4                   LOW     LEVEL_0                      140   
..                  ...         ...                      ...   
193                HIGH     LEVEL_2                      150   
194                 LOW     LEVEL_0                      162   
195                HIGH     LEVEL_2                      159   
196                 LOW     LEVEL_2                      154   
197                 LOW     LEVEL_0                      192   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            0.0                  LEVEL_1   
1                   NO_PAIN            0.0                  LEVEL_1   
2                   NO_PAIN            0.1                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                   NO_PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
193                 NO_PAIN            2.3                  LEVEL_3   
194                 NO_PAIN            1.9                  LEVEL_1   
195                    PAIN            0.0                  LEVEL_1   
196                    PAIN            0.6                  LEVEL_2   
197                 NO_PAIN            0.7                  LEVEL_1   

     Number_of_major_vessels     Thal  
0                          1  LEVEL_3  
1                          0  LEVEL_3  
2                          1  LEVEL_7  
3                          0  LEVEL_3  
4                          0  LEVEL_7  
..                       ...      ...  
193                        0  LEVEL_6  
194                        1  LEVEL_3  
195                        1  LEVEL_3  
196                        0  LEVEL_7  
197                        0  LEVEL_3  

[198 rows x 13 columns]
2023-07-26 20:03:49,293:INFO:get_config() successfully completed......................................
2023-07-26 20:03:49,293:INFO:Initializing get_config()
2023-07-26 20:03:49,293:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, variable=X_test)
2023-07-26 20:03:49,293:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2023-07-26 20:03:49,293:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-07-26 20:03:49,308:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
198   57  FEMALE    LEVEL_4                     128               303   
199   66    MALE    LEVEL_4                     160               228   
200   52    MALE    LEVEL_4                     112               230   
201   59  FEMALE    LEVEL_4                     174               249   
202   60    MALE    LEVEL_4                     130               206   
..   ...     ...        ...                     ...               ...   
278   59    MALE    LEVEL_1                     134               204   
279   52    MALE    LEVEL_4                     108               233   
280   59    MALE    LEVEL_1                     170               288   
281   34    MALE    LEVEL_1                     118               182   
282   65    MALE    LEVEL_4                     120               177   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
198                 LOW     LEVEL_2                      159   
199                 LOW     LEVEL_2                      138   
200                 LOW     LEVEL_0                      160   
201                 LOW     LEVEL_0                      143   
202                 LOW     LEVEL_2                      132   
..                  ...         ...                      ...   
278                 LOW     LEVEL_0                      162   
279                HIGH     LEVEL_0                      147   
280                 LOW     LEVEL_2                      159   
281                 LOW     LEVEL_2                      174   
282                 LOW     LEVEL_0                      140   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            2.3                  LEVEL_1   
200                 NO_PAIN            0.0                  LEVEL_1   
201                    PAIN            0.0                  LEVEL_2   
202                    PAIN            2.4                  LEVEL_2   
..                      ...            ...                      ...   
278                 NO_PAIN            0.8                  LEVEL_1   
279                 NO_PAIN            0.1                  LEVEL_1   
280                 NO_PAIN            0.2                  LEVEL_2   
281                 NO_PAIN            0.0                  LEVEL_1   
282                 NO_PAIN            0.4                  LEVEL_1   

     Number_of_major_vessels     Thal  
198                        1  LEVEL_3  
199                        0  LEVEL_6  
200                        1  LEVEL_3  
201                        0  LEVEL_3  
202                        2  LEVEL_7  
..                       ...      ...  
278                        2  LEVEL_3  
279                        3  LEVEL_7  
280                        0  LEVEL_7  
281                        0  LEVEL_3  
282                        0  LEVEL_7  

[85 rows x 13 columns]
2023-07-26 20:03:49,308:INFO:get_config() successfully completed......................................
2023-07-26 20:05:21,041:INFO:Initializing get_config()
2023-07-26 20:05:21,050:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, variable=data_before_preprocess)
2023-07-26 20:06:31,528:INFO:Initializing predict_model()
2023-07-26 20:06:31,528:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223DF3C54C0>)
2023-07-26 20:06:31,528:INFO:Checking exceptions
2023-07-26 20:06:31,529:INFO:Preloading libraries
2023-07-26 20:06:31,539:INFO:Set up data.
2023-07-26 20:06:31,548:INFO:Set up index.
2023-07-26 20:07:06,504:INFO:Initializing predict_model()
2023-07-26 20:07:06,504:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223DF7E8AF0>)
2023-07-26 20:07:06,504:INFO:Checking exceptions
2023-07-26 20:07:06,504:INFO:Preloading libraries
2023-07-26 20:07:06,512:INFO:Set up data.
2023-07-26 20:07:06,524:INFO:Set up index.
2023-07-26 20:07:19,747:INFO:Initializing predict_model()
2023-07-26 20:07:19,751:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223E00E1CA0>)
2023-07-26 20:07:19,751:INFO:Checking exceptions
2023-07-26 20:07:19,751:INFO:Preloading libraries
2023-07-26 20:07:19,757:INFO:Set up data.
2023-07-26 20:07:19,759:INFO:Set up index.
2023-07-26 20:07:27,339:INFO:Initializing predict_model()
2023-07-26 20:07:27,339:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000223DEA44B80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000223DF7E89D0>)
2023-07-26 20:07:27,340:INFO:Checking exceptions
2023-07-26 20:07:27,340:INFO:Preloading libraries
2023-07-26 20:07:27,342:INFO:Set up data.
2023-07-26 20:07:27,348:INFO:Set up index.
2023-08-06 10:36:37,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-06 10:36:37,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-06 10:36:37,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-06 10:36:37,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-06 10:36:37,991:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-08-06 12:03:37,885:INFO:PyCaret ClassificationExperiment
2023-08-06 12:03:37,885:INFO:Logging name: EXP_01
2023-08-06 12:03:37,885:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-06 12:03:37,885:INFO:version 3.0.0.rc9
2023-08-06 12:03:37,885:INFO:Initializing setup()
2023-08-06 12:03:37,885:INFO:self.USI: 7d72
2023-08-06 12:03:37,885:INFO:self._variable_keys: {'gpu_param', 'fix_imbalance', 'idx', 'fold_groups_param', 'exp_id', '_available_plots', 'X_train', 'X', 'memory', 'html_param', 'n_jobs_param', 'pipeline', 'seed', 'logging_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'log_plots_param', 'y_train', 'USI', 'target_param', 'data', 'y_test', 'is_multiclass', 'y', 'fold_generator', '_ml_usecase', 'exp_name_log', 'X_test'}
2023-08-06 12:03:37,885:INFO:Checking environment
2023-08-06 12:03:37,893:INFO:python_version: 3.9.13
2023-08-06 12:03:37,893:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-06 12:03:37,893:INFO:machine: AMD64
2023-08-06 12:03:37,893:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-06 12:03:37,893:INFO:Memory: svmem(total=8266518528, available=389615616, percent=95.3, used=7876902912, free=389615616)
2023-08-06 12:03:37,893:INFO:Physical Core: 4
2023-08-06 12:03:37,893:INFO:Logical Core: 8
2023-08-06 12:03:37,893:INFO:Checking libraries
2023-08-06 12:03:37,893:INFO:System:
2023-08-06 12:03:37,893:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-06 12:03:37,893:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-08-06 12:03:37,893:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-06 12:03:37,893:INFO:PyCaret required dependencies:
2023-08-06 12:03:37,893:INFO:                 pip: 22.2.2
2023-08-06 12:03:37,893:INFO:          setuptools: 63.4.1
2023-08-06 12:03:37,893:INFO:             pycaret: 3.0.0rc9
2023-08-06 12:03:37,893:INFO:             IPython: 7.31.1
2023-08-06 12:03:37,893:INFO:          ipywidgets: 7.6.5
2023-08-06 12:03:37,901:INFO:                tqdm: 4.64.1
2023-08-06 12:03:37,901:INFO:               numpy: 1.21.5
2023-08-06 12:03:37,901:INFO:              pandas: 1.4.4
2023-08-06 12:03:37,901:INFO:              jinja2: 3.0.3
2023-08-06 12:03:37,901:INFO:               scipy: 1.9.1
2023-08-06 12:03:37,901:INFO:              joblib: 1.2.0
2023-08-06 12:03:37,901:INFO:             sklearn: 1.0.2
2023-08-06 12:03:37,901:INFO:                pyod: 1.0.7
2023-08-06 12:03:37,901:INFO:            imblearn: 0.10.1
2023-08-06 12:03:37,901:INFO:   category_encoders: 2.6.0
2023-08-06 12:03:37,901:INFO:            lightgbm: 3.3.5
2023-08-06 12:03:37,901:INFO:               numba: 0.55.1
2023-08-06 12:03:37,901:INFO:            requests: 2.28.1
2023-08-06 12:03:37,901:INFO:          matplotlib: 3.5.2
2023-08-06 12:03:37,901:INFO:          scikitplot: 0.3.7
2023-08-06 12:03:37,901:INFO:         yellowbrick: 1.5
2023-08-06 12:03:37,901:INFO:              plotly: 5.9.0
2023-08-06 12:03:37,901:INFO:             kaleido: 0.2.1
2023-08-06 12:03:37,901:INFO:         statsmodels: 0.13.2
2023-08-06 12:03:37,901:INFO:              sktime: 0.16.1
2023-08-06 12:03:37,901:INFO:               tbats: 1.1.2
2023-08-06 12:03:37,901:INFO:            pmdarima: 2.0.2
2023-08-06 12:03:37,901:INFO:              psutil: 5.9.0
2023-08-06 12:03:37,901:INFO:PyCaret optional dependencies:
2023-08-06 12:03:37,918:INFO:                shap: Not installed
2023-08-06 12:03:37,918:INFO:           interpret: Not installed
2023-08-06 12:03:37,918:INFO:                umap: Not installed
2023-08-06 12:03:37,918:INFO:    pandas_profiling: 4.3.1
2023-08-06 12:03:37,918:INFO:  explainerdashboard: Not installed
2023-08-06 12:03:37,918:INFO:             autoviz: 0.1.720
2023-08-06 12:03:37,918:INFO:           fairlearn: Not installed
2023-08-06 12:03:37,918:INFO:             xgboost: 1.7.5
2023-08-06 12:03:37,918:INFO:            catboost: Not installed
2023-08-06 12:03:37,918:INFO:              kmodes: Not installed
2023-08-06 12:03:37,918:INFO:             mlxtend: Not installed
2023-08-06 12:03:37,918:INFO:       statsforecast: Not installed
2023-08-06 12:03:37,918:INFO:        tune_sklearn: Not installed
2023-08-06 12:03:37,918:INFO:                 ray: Not installed
2023-08-06 12:03:37,918:INFO:            hyperopt: Not installed
2023-08-06 12:03:37,918:INFO:              optuna: Not installed
2023-08-06 12:03:37,918:INFO:               skopt: Not installed
2023-08-06 12:03:37,918:INFO:              mlflow: Not installed
2023-08-06 12:03:37,918:INFO:              gradio: Not installed
2023-08-06 12:03:37,918:INFO:             fastapi: Not installed
2023-08-06 12:03:37,918:INFO:             uvicorn: Not installed
2023-08-06 12:03:37,918:INFO:              m2cgen: Not installed
2023-08-06 12:03:37,918:INFO:           evidently: Not installed
2023-08-06 12:03:37,918:INFO:               fugue: Not installed
2023-08-06 12:03:37,918:INFO:           streamlit: Not installed
2023-08-06 12:03:37,918:INFO:             prophet: Not installed
2023-08-06 12:03:37,918:INFO:None
2023-08-06 12:03:37,918:INFO:Set up data.
2023-08-06 12:03:38,063:INFO:Set up train/test split.
2023-08-06 12:03:38,092:INFO:Set up index.
2023-08-06 12:03:38,092:INFO:Set up folding strategy.
2023-08-06 12:03:38,092:INFO:Assigning column types.
2023-08-06 12:03:38,092:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-06 12:03:38,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-06 12:03:38,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-06 12:03:38,233:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:38,406:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:38,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-06 12:03:38,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-06 12:03:38,469:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:38,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:38,469:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-06 12:03:38,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-06 12:03:38,550:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:38,558:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:38,611:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-06 12:03:38,635:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:38,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:38,643:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-06 12:03:38,690:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:38,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:38,750:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:38,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:38,761:INFO:Preparing preprocessing pipeline...
2023-08-06 12:03:38,761:INFO:Set up simple imputation.
2023-08-06 12:03:38,761:INFO:Set up encoding of ordinal features.
2023-08-06 12:03:38,778:INFO:Set up encoding of categorical features.
2023-08-06 12:03:38,778:INFO:Set up feature normalization.
2023-08-06 12:03:38,977:INFO:Finished creating preprocessing pipeline.
2023-08-06 12:03:39,008:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_valu...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-06 12:03:39,008:INFO:Creating final display dataframe.
2023-08-06 12:03:39,420:INFO:Setup _display_container:                     Description            Value
0                    Session id             1935
1                        Target             ALVO
2                   Target type           Binary
3           Original data shape        (303, 14)
4        Transformed data shape        (303, 23)
5   Transformed train set shape        (196, 23)
6    Transformed test set shape        (107, 23)
7              Ordinal features                3
8              Numeric features                6
9          Categorical features                7
10     Rows with missing values             2.0%
11                   Preprocess             True
12              Imputation type           simple
13           Numeric imputation             mean
14       Categorical imputation             mode
15     Maximum one-hot encoding               25
16              Encoding method             None
17                    Normalize             True
18             Normalize method           zscore
19               Fold Generator  StratifiedKFold
20                  Fold Number               10
21                     CPU Jobs               -1
22                      Use GPU            False
23               Log Experiment            False
24              Experiment Name           EXP_01
25                          USI             7d72
2023-08-06 12:03:39,528:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:39,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:39,584:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-06 12:03:39,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-06 12:03:39,584:INFO:setup() successfully completed in 1.73s...............
2023-08-06 12:13:23,054:INFO:Initializing get_config()
2023-08-06 12:13:23,054:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=X_train_transformed)
2023-08-06 12:13:23,141:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-08-06 12:13:23,141:INFO:get_config() successfully completed......................................
2023-08-06 12:14:00,474:INFO:Initializing get_config()
2023-08-06 12:14:00,474:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=X_train)
2023-08-06 12:14:00,474:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-08-06 12:14:00,480:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-06 12:14:00,488:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  
0                        3.0  LEVEL_7  
1                        0.0  LEVEL_3  
2                        2.0  LEVEL_7  
3                        0.0  LEVEL_7  
4                        1.0  LEVEL_7  
..                       ...      ...  
191                      0.0  LEVEL_3  
192                      1.0  LEVEL_7  
193                      0.0  LEVEL_7  
194                      0.0  LEVEL_3  
195                      0.0  LEVEL_3  

[196 rows x 13 columns]
2023-08-06 12:14:00,488:INFO:get_config() successfully completed......................................
2023-08-06 12:14:50,671:INFO:Initializing get_config()
2023-08-06 12:14:50,671:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=X_test_transformed)
2023-08-06 12:14:50,749:INFO:Variable: X_test returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
196  1.597237  0.704403            1.621613           -0.940540   
197  0.893472 -1.419642           -0.616670            1.063219   
198  0.776177 -1.419642           -0.616670            1.063219   
199 -1.921592  0.704403            1.621613           -0.940540   
200 -0.162177 -1.419642           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
298 -0.748649  0.704403           -0.616670           -0.940540   
299 -1.804298  0.704403            1.621613           -0.940540   
300  1.362649  0.704403           -0.616670            1.063219   
301  1.479943  0.704403           -0.616670            1.063219   
302  0.658883  0.704403           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
196           -0.298142           -0.458123               -0.758105   
197           -0.298142           -0.458123                0.497251   
198           -0.298142           -0.458123               -0.073365   
199           -0.298142           -0.458123                0.383128   
200           -0.298142           -0.458123               -0.073365   
..                  ...                 ...                     ...   
298           -0.298142            2.182821               -1.214598   
299           -0.298142           -0.458123                0.497251   
300           -0.298142           -0.458123               -1.100474   
301           -0.298142           -0.458123               -0.643981   
302           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
196          0.581772             0.441726             1.052391  ...   
197          2.755666             0.441726            -0.950217  ...   
198          1.566527             0.441726            -0.950217  ...   
199         -1.313418             0.441726             1.052391  ...   
200          0.340228             0.441726            -0.950217  ...   
..                ...                  ...                  ...  ...   
298         -0.310082             0.441726             1.052391  ...   
299          1.399304             0.441726            -0.950217  ...   
300         -0.625947             0.441726            -0.950217  ...   
301         -0.161440             0.441726             1.052391  ...   
302         -0.737429             0.441726            -0.950217  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
196                 0.106581                -0.728869      -0.076209   
197                 0.371010                -0.728869       0.090684   
198                 0.899867                -0.728869      -0.910673   
199                 1.076153                -0.728869      -0.910673   
200                -0.245991                -0.728869      -0.576888   
..                       ...                      ...            ...   
298                 0.855796                -0.728869      -0.076209   
299                 1.472796                -0.728869      -0.910673   
300                -0.730777                 1.371989      -0.827227   
301                -3.419135                -0.728869      -0.076209   
302                -0.730777                 1.371989       1.092042   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
196                         -0.969842                          1.107823   
197                          1.031095                         -0.902671   
198                         -0.969842                          1.107823   
199                         -0.969842                          1.107823   
200                          1.031095                         -0.902671   
..                                ...                               ...   
298                         -0.969842                         -0.902671   
299                         -0.969842                          1.107823   
300                         -0.969842                          1.107823   
301                          1.031095                         -0.902671   
302                          1.031095                         -0.902671   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
196                         -0.266530                 0.379460      1.256562   
197                         -0.266530                -0.735922     -0.795822   
198                         -0.266530                -0.735922     -0.795822   
199                         -0.266530                 0.000000     -0.795822   
200                         -0.266530                -0.735922     -0.795822   
..                                ...                      ...           ...   
298                          3.751923                -0.735922      1.256562   
299                         -0.266530                -0.735922     -0.795822   
300                         -0.266530                 0.379460     -0.795822   
301                         -0.266530                -0.735922     -0.795822   
302                         -0.266530                 1.494842      1.256562   

     Thal_LEVEL_3  Thal_LEVEL_6  
196     -1.119318     -0.243843  
197      0.893401     -0.243843  
198      0.893401     -0.243843  
199      0.893401     -0.243843  
200      0.893401     -0.243843  
..            ...           ...  
298     -1.119318     -0.243843  
299      0.893401     -0.243843  
300      0.893401     -0.243843  
301      0.893401     -0.243843  
302     -1.119318     -0.243843  

[107 rows x 22 columns]
2023-08-06 12:14:50,749:INFO:get_config() successfully completed......................................
2023-08-06 12:15:21,486:INFO:Initializing get_config()
2023-08-06 12:15:21,486:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=X_test)
2023-08-06 12:15:21,486:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2023-08-06 12:15:21,486:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-06 12:15:21,495:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  
196                      1.0  LEVEL_7  
197                      0.0  LEVEL_3  
198                      0.0  LEVEL_3  
199                      NaN  LEVEL_3  
200                      0.0  LEVEL_3  
..                       ...      ...  
298                      0.0  LEVEL_7  
299                      0.0  LEVEL_3  
300                      1.0  LEVEL_3  
301                      0.0  LEVEL_3  
302                      2.0  LEVEL_7  

[107 rows x 13 columns]
2023-08-06 12:15:21,495:INFO:get_config() successfully completed......................................
2023-08-06 12:17:54,161:INFO:Initializing get_config()
2023-08-06 12:17:54,161:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=Y_train)
2023-08-06 12:18:13,930:INFO:Initializing get_config()
2023-08-06 12:18:13,930:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=y_train)
2023-08-06 12:18:13,930:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2023-08-06 12:18:13,930:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-06 12:18:13,939:INFO:Variable:  returned as 0      1
1      0
2      1
3      1
4      1
      ..
191    0
192    1
193    1
194    0
195    0
Name: ALVO, Length: 196, dtype: int8
2023-08-06 12:18:13,939:INFO:get_config() successfully completed......................................
2023-08-06 12:19:00,481:INFO:Initializing get_config()
2023-08-06 12:19:00,481:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=X_test_transformed)
2023-08-06 12:19:00,550:INFO:Variable: X_test returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
196  1.597237  0.704403            1.621613           -0.940540   
197  0.893472 -1.419642           -0.616670            1.063219   
198  0.776177 -1.419642           -0.616670            1.063219   
199 -1.921592  0.704403            1.621613           -0.940540   
200 -0.162177 -1.419642           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
298 -0.748649  0.704403           -0.616670           -0.940540   
299 -1.804298  0.704403            1.621613           -0.940540   
300  1.362649  0.704403           -0.616670            1.063219   
301  1.479943  0.704403           -0.616670            1.063219   
302  0.658883  0.704403           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
196           -0.298142           -0.458123               -0.758105   
197           -0.298142           -0.458123                0.497251   
198           -0.298142           -0.458123               -0.073365   
199           -0.298142           -0.458123                0.383128   
200           -0.298142           -0.458123               -0.073365   
..                  ...                 ...                     ...   
298           -0.298142            2.182821               -1.214598   
299           -0.298142           -0.458123                0.497251   
300           -0.298142           -0.458123               -1.100474   
301           -0.298142           -0.458123               -0.643981   
302           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
196          0.581772             0.441726             1.052391  ...   
197          2.755666             0.441726            -0.950217  ...   
198          1.566527             0.441726            -0.950217  ...   
199         -1.313418             0.441726             1.052391  ...   
200          0.340228             0.441726            -0.950217  ...   
..                ...                  ...                  ...  ...   
298         -0.310082             0.441726             1.052391  ...   
299          1.399304             0.441726            -0.950217  ...   
300         -0.625947             0.441726            -0.950217  ...   
301         -0.161440             0.441726             1.052391  ...   
302         -0.737429             0.441726            -0.950217  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
196                 0.106581                -0.728869      -0.076209   
197                 0.371010                -0.728869       0.090684   
198                 0.899867                -0.728869      -0.910673   
199                 1.076153                -0.728869      -0.910673   
200                -0.245991                -0.728869      -0.576888   
..                       ...                      ...            ...   
298                 0.855796                -0.728869      -0.076209   
299                 1.472796                -0.728869      -0.910673   
300                -0.730777                 1.371989      -0.827227   
301                -3.419135                -0.728869      -0.076209   
302                -0.730777                 1.371989       1.092042   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
196                         -0.969842                          1.107823   
197                          1.031095                         -0.902671   
198                         -0.969842                          1.107823   
199                         -0.969842                          1.107823   
200                          1.031095                         -0.902671   
..                                ...                               ...   
298                         -0.969842                         -0.902671   
299                         -0.969842                          1.107823   
300                         -0.969842                          1.107823   
301                          1.031095                         -0.902671   
302                          1.031095                         -0.902671   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
196                         -0.266530                 0.379460      1.256562   
197                         -0.266530                -0.735922     -0.795822   
198                         -0.266530                -0.735922     -0.795822   
199                         -0.266530                 0.000000     -0.795822   
200                         -0.266530                -0.735922     -0.795822   
..                                ...                      ...           ...   
298                          3.751923                -0.735922      1.256562   
299                         -0.266530                -0.735922     -0.795822   
300                         -0.266530                 0.379460     -0.795822   
301                         -0.266530                -0.735922     -0.795822   
302                         -0.266530                 1.494842      1.256562   

     Thal_LEVEL_3  Thal_LEVEL_6  
196     -1.119318     -0.243843  
197      0.893401     -0.243843  
198      0.893401     -0.243843  
199      0.893401     -0.243843  
200      0.893401     -0.243843  
..            ...           ...  
298     -1.119318     -0.243843  
299      0.893401     -0.243843  
300      0.893401     -0.243843  
301      0.893401     -0.243843  
302     -1.119318     -0.243843  

[107 rows x 22 columns]
2023-08-06 12:19:00,550:INFO:get_config() successfully completed......................................
2023-08-06 12:20:36,689:INFO:Initializing get_config()
2023-08-06 12:20:36,689:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=y_test)
2023-08-06 12:20:36,689:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2023-08-06 12:20:36,689:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-06 12:20:36,689:INFO:Variable:  returned as 196    0
197    0
198    1
199    0
200    0
      ..
298    1
299    0
300    1
301    1
302    1
Name: ALVO, Length: 107, dtype: int8
2023-08-06 12:20:36,689:INFO:get_config() successfully completed......................................
2023-08-06 12:20:53,616:INFO:Initializing get_config()
2023-08-06 12:20:53,616:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, variable=y_test)
2023-08-06 12:20:53,616:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2023-08-06 12:20:53,616:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-06 12:20:53,616:INFO:Variable:  returned as 196    0
197    0
198    1
199    0
200    0
      ..
298    1
299    0
300    1
301    1
302    1
Name: ALVO, Length: 107, dtype: int8
2023-08-06 12:20:53,616:INFO:get_config() successfully completed......................................
2023-08-06 12:37:23,730:INFO:Initializing compare_models()
2023-08-06 12:37:23,730:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-06 12:37:23,730:INFO:Checking exceptions
2023-08-06 12:37:23,770:INFO:Preparing display monitor
2023-08-06 12:37:23,950:INFO:Initializing Logistic Regression
2023-08-06 12:37:23,950:INFO:Total runtime is 0.0 minutes
2023-08-06 12:37:23,954:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:23,966:INFO:Initializing create_model()
2023-08-06 12:37:23,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:23,966:INFO:Checking exceptions
2023-08-06 12:37:23,966:INFO:Importing libraries
2023-08-06 12:37:23,966:INFO:Copying training dataset
2023-08-06 12:37:23,966:INFO:Defining folds
2023-08-06 12:37:23,966:INFO:Declaring metric variables
2023-08-06 12:37:23,976:INFO:Importing untrained model
2023-08-06 12:37:23,982:INFO:Logistic Regression Imported successfully
2023-08-06 12:37:23,991:INFO:Starting cross validation
2023-08-06 12:37:23,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:34,558:INFO:Calculating mean and std
2023-08-06 12:37:34,563:INFO:Creating metrics dataframe
2023-08-06 12:37:34,569:INFO:Uploading results into container
2023-08-06 12:37:34,570:INFO:Uploading model into container now
2023-08-06 12:37:34,570:INFO:_master_model_container: 1
2023-08-06 12:37:34,570:INFO:_display_container: 2
2023-08-06 12:37:34,573:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-06 12:37:34,573:INFO:create_model() successfully completed......................................
2023-08-06 12:37:34,696:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:34,696:INFO:Creating metrics dataframe
2023-08-06 12:37:34,709:INFO:Initializing K Neighbors Classifier
2023-08-06 12:37:34,709:INFO:Total runtime is 0.1793274203936259 minutes
2023-08-06 12:37:34,709:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:34,709:INFO:Initializing create_model()
2023-08-06 12:37:34,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:34,709:INFO:Checking exceptions
2023-08-06 12:37:34,709:INFO:Importing libraries
2023-08-06 12:37:34,709:INFO:Copying training dataset
2023-08-06 12:37:34,725:INFO:Defining folds
2023-08-06 12:37:34,725:INFO:Declaring metric variables
2023-08-06 12:37:34,725:INFO:Importing untrained model
2023-08-06 12:37:34,725:INFO:K Neighbors Classifier Imported successfully
2023-08-06 12:37:34,741:INFO:Starting cross validation
2023-08-06 12:37:34,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:35,270:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,301:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,346:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,352:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,355:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,388:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,421:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,450:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,665:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,668:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-06 12:37:35,740:INFO:Calculating mean and std
2023-08-06 12:37:35,748:INFO:Creating metrics dataframe
2023-08-06 12:37:35,748:INFO:Uploading results into container
2023-08-06 12:37:35,748:INFO:Uploading model into container now
2023-08-06 12:37:35,748:INFO:_master_model_container: 2
2023-08-06 12:37:35,748:INFO:_display_container: 2
2023-08-06 12:37:35,748:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-06 12:37:35,748:INFO:create_model() successfully completed......................................
2023-08-06 12:37:35,865:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:35,865:INFO:Creating metrics dataframe
2023-08-06 12:37:35,876:INFO:Initializing Naive Bayes
2023-08-06 12:37:35,876:INFO:Total runtime is 0.1987807830174764 minutes
2023-08-06 12:37:35,876:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:35,876:INFO:Initializing create_model()
2023-08-06 12:37:35,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:35,876:INFO:Checking exceptions
2023-08-06 12:37:35,876:INFO:Importing libraries
2023-08-06 12:37:35,876:INFO:Copying training dataset
2023-08-06 12:37:35,884:INFO:Defining folds
2023-08-06 12:37:35,884:INFO:Declaring metric variables
2023-08-06 12:37:35,884:INFO:Importing untrained model
2023-08-06 12:37:35,892:INFO:Naive Bayes Imported successfully
2023-08-06 12:37:35,892:INFO:Starting cross validation
2023-08-06 12:37:35,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:36,807:INFO:Calculating mean and std
2023-08-06 12:37:36,807:INFO:Creating metrics dataframe
2023-08-06 12:37:36,807:INFO:Uploading results into container
2023-08-06 12:37:36,807:INFO:Uploading model into container now
2023-08-06 12:37:36,807:INFO:_master_model_container: 3
2023-08-06 12:37:36,807:INFO:_display_container: 2
2023-08-06 12:37:36,807:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-06 12:37:36,807:INFO:create_model() successfully completed......................................
2023-08-06 12:37:36,933:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:36,933:INFO:Creating metrics dataframe
2023-08-06 12:37:36,946:INFO:Initializing Decision Tree Classifier
2023-08-06 12:37:36,946:INFO:Total runtime is 0.2166112502415975 minutes
2023-08-06 12:37:36,946:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:36,946:INFO:Initializing create_model()
2023-08-06 12:37:36,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:36,946:INFO:Checking exceptions
2023-08-06 12:37:36,946:INFO:Importing libraries
2023-08-06 12:37:36,946:INFO:Copying training dataset
2023-08-06 12:37:36,963:INFO:Defining folds
2023-08-06 12:37:36,963:INFO:Declaring metric variables
2023-08-06 12:37:36,967:INFO:Importing untrained model
2023-08-06 12:37:36,967:INFO:Decision Tree Classifier Imported successfully
2023-08-06 12:37:36,980:INFO:Starting cross validation
2023-08-06 12:37:36,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:37,810:INFO:Calculating mean and std
2023-08-06 12:37:37,810:INFO:Creating metrics dataframe
2023-08-06 12:37:37,810:INFO:Uploading results into container
2023-08-06 12:37:37,810:INFO:Uploading model into container now
2023-08-06 12:37:37,810:INFO:_master_model_container: 4
2023-08-06 12:37:37,810:INFO:_display_container: 2
2023-08-06 12:37:37,810:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-08-06 12:37:37,810:INFO:create_model() successfully completed......................................
2023-08-06 12:37:37,929:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:37,929:INFO:Creating metrics dataframe
2023-08-06 12:37:37,948:INFO:Initializing SVM - Linear Kernel
2023-08-06 12:37:37,948:INFO:Total runtime is 0.23330516417821248 minutes
2023-08-06 12:37:37,948:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:37,948:INFO:Initializing create_model()
2023-08-06 12:37:37,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:37,948:INFO:Checking exceptions
2023-08-06 12:37:37,948:INFO:Importing libraries
2023-08-06 12:37:37,948:INFO:Copying training dataset
2023-08-06 12:37:37,948:INFO:Defining folds
2023-08-06 12:37:37,961:INFO:Declaring metric variables
2023-08-06 12:37:37,962:INFO:Importing untrained model
2023-08-06 12:37:37,968:INFO:SVM - Linear Kernel Imported successfully
2023-08-06 12:37:37,970:INFO:Starting cross validation
2023-08-06 12:37:37,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:38,873:INFO:Calculating mean and std
2023-08-06 12:37:38,873:INFO:Creating metrics dataframe
2023-08-06 12:37:38,873:INFO:Uploading results into container
2023-08-06 12:37:38,873:INFO:Uploading model into container now
2023-08-06 12:37:38,873:INFO:_master_model_container: 5
2023-08-06 12:37:38,873:INFO:_display_container: 2
2023-08-06 12:37:38,873:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-06 12:37:38,873:INFO:create_model() successfully completed......................................
2023-08-06 12:37:39,015:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:39,015:INFO:Creating metrics dataframe
2023-08-06 12:37:39,031:INFO:Initializing Ridge Classifier
2023-08-06 12:37:39,031:INFO:Total runtime is 0.25134995381037395 minutes
2023-08-06 12:37:39,046:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:39,046:INFO:Initializing create_model()
2023-08-06 12:37:39,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:39,046:INFO:Checking exceptions
2023-08-06 12:37:39,046:INFO:Importing libraries
2023-08-06 12:37:39,046:INFO:Copying training dataset
2023-08-06 12:37:39,046:INFO:Defining folds
2023-08-06 12:37:39,046:INFO:Declaring metric variables
2023-08-06 12:37:39,062:INFO:Importing untrained model
2023-08-06 12:37:39,070:INFO:Ridge Classifier Imported successfully
2023-08-06 12:37:39,078:INFO:Starting cross validation
2023-08-06 12:37:39,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:40,746:INFO:Calculating mean and std
2023-08-06 12:37:40,761:INFO:Creating metrics dataframe
2023-08-06 12:37:40,761:INFO:Uploading results into container
2023-08-06 12:37:40,761:INFO:Uploading model into container now
2023-08-06 12:37:40,761:INFO:_master_model_container: 6
2023-08-06 12:37:40,761:INFO:_display_container: 2
2023-08-06 12:37:40,761:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1935, solver='auto', tol=0.001)
2023-08-06 12:37:40,761:INFO:create_model() successfully completed......................................
2023-08-06 12:37:40,903:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:40,903:INFO:Creating metrics dataframe
2023-08-06 12:37:40,919:INFO:Initializing Random Forest Classifier
2023-08-06 12:37:40,919:INFO:Total runtime is 0.2828259785970052 minutes
2023-08-06 12:37:40,935:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:40,935:INFO:Initializing create_model()
2023-08-06 12:37:40,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:40,935:INFO:Checking exceptions
2023-08-06 12:37:40,935:INFO:Importing libraries
2023-08-06 12:37:40,935:INFO:Copying training dataset
2023-08-06 12:37:40,950:INFO:Defining folds
2023-08-06 12:37:40,950:INFO:Declaring metric variables
2023-08-06 12:37:40,950:INFO:Importing untrained model
2023-08-06 12:37:40,950:INFO:Random Forest Classifier Imported successfully
2023-08-06 12:37:40,975:INFO:Starting cross validation
2023-08-06 12:37:40,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:43,549:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:43,549:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:43,580:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:43,592:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:43,643:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:43,769:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:43,786:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:45,370:INFO:Calculating mean and std
2023-08-06 12:37:45,370:INFO:Creating metrics dataframe
2023-08-06 12:37:45,382:INFO:Uploading results into container
2023-08-06 12:37:45,382:INFO:Uploading model into container now
2023-08-06 12:37:45,387:INFO:_master_model_container: 7
2023-08-06 12:37:45,387:INFO:_display_container: 2
2023-08-06 12:37:45,387:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-08-06 12:37:45,387:INFO:create_model() successfully completed......................................
2023-08-06 12:37:45,512:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:45,512:INFO:Creating metrics dataframe
2023-08-06 12:37:45,512:INFO:Initializing Quadratic Discriminant Analysis
2023-08-06 12:37:45,512:INFO:Total runtime is 0.3593817631403605 minutes
2023-08-06 12:37:45,528:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:45,528:INFO:Initializing create_model()
2023-08-06 12:37:45,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:45,528:INFO:Checking exceptions
2023-08-06 12:37:45,528:INFO:Importing libraries
2023-08-06 12:37:45,528:INFO:Copying training dataset
2023-08-06 12:37:45,528:INFO:Defining folds
2023-08-06 12:37:45,528:INFO:Declaring metric variables
2023-08-06 12:37:45,544:INFO:Importing untrained model
2023-08-06 12:37:45,544:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-06 12:37:45,561:INFO:Starting cross validation
2023-08-06 12:37:45,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:45,942:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:45,982:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:45,989:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:46,005:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:46,005:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:46,020:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:46,020:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:46,067:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:46,862:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:46,884:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-06 12:37:47,175:INFO:Calculating mean and std
2023-08-06 12:37:47,175:INFO:Creating metrics dataframe
2023-08-06 12:37:47,185:INFO:Uploading results into container
2023-08-06 12:37:47,185:INFO:Uploading model into container now
2023-08-06 12:37:47,185:INFO:_master_model_container: 8
2023-08-06 12:37:47,185:INFO:_display_container: 2
2023-08-06 12:37:47,185:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-06 12:37:47,185:INFO:create_model() successfully completed......................................
2023-08-06 12:37:47,325:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:47,325:INFO:Creating metrics dataframe
2023-08-06 12:37:47,341:INFO:Initializing Ada Boost Classifier
2023-08-06 12:37:47,341:INFO:Total runtime is 0.3898640076319377 minutes
2023-08-06 12:37:47,349:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:47,349:INFO:Initializing create_model()
2023-08-06 12:37:47,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:47,349:INFO:Checking exceptions
2023-08-06 12:37:47,349:INFO:Importing libraries
2023-08-06 12:37:47,349:INFO:Copying training dataset
2023-08-06 12:37:47,357:INFO:Defining folds
2023-08-06 12:37:47,357:INFO:Declaring metric variables
2023-08-06 12:37:47,365:INFO:Importing untrained model
2023-08-06 12:37:47,365:INFO:Ada Boost Classifier Imported successfully
2023-08-06 12:37:47,373:INFO:Starting cross validation
2023-08-06 12:37:47,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:50,237:INFO:Calculating mean and std
2023-08-06 12:37:50,237:INFO:Creating metrics dataframe
2023-08-06 12:37:50,237:INFO:Uploading results into container
2023-08-06 12:37:50,237:INFO:Uploading model into container now
2023-08-06 12:37:50,237:INFO:_master_model_container: 9
2023-08-06 12:37:50,237:INFO:_display_container: 2
2023-08-06 12:37:50,237:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1935)
2023-08-06 12:37:50,237:INFO:create_model() successfully completed......................................
2023-08-06 12:37:50,397:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:50,397:INFO:Creating metrics dataframe
2023-08-06 12:37:50,421:INFO:Initializing Gradient Boosting Classifier
2023-08-06 12:37:50,421:INFO:Total runtime is 0.44118938446044925 minutes
2023-08-06 12:37:50,429:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:50,429:INFO:Initializing create_model()
2023-08-06 12:37:50,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:50,437:INFO:Checking exceptions
2023-08-06 12:37:50,437:INFO:Importing libraries
2023-08-06 12:37:50,437:INFO:Copying training dataset
2023-08-06 12:37:50,445:INFO:Defining folds
2023-08-06 12:37:50,445:INFO:Declaring metric variables
2023-08-06 12:37:50,445:INFO:Importing untrained model
2023-08-06 12:37:50,453:INFO:Gradient Boosting Classifier Imported successfully
2023-08-06 12:37:50,469:INFO:Starting cross validation
2023-08-06 12:37:50,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:52,398:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:52,430:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:52,482:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:52,490:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:52,527:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:52,614:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:52,839:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:52,975:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:53,892:INFO:Calculating mean and std
2023-08-06 12:37:53,899:INFO:Creating metrics dataframe
2023-08-06 12:37:53,907:INFO:Uploading results into container
2023-08-06 12:37:53,907:INFO:Uploading model into container now
2023-08-06 12:37:53,907:INFO:_master_model_container: 10
2023-08-06 12:37:53,907:INFO:_display_container: 2
2023-08-06 12:37:53,907:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-06 12:37:53,907:INFO:create_model() successfully completed......................................
2023-08-06 12:37:54,067:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:54,067:INFO:Creating metrics dataframe
2023-08-06 12:37:54,100:INFO:Initializing Linear Discriminant Analysis
2023-08-06 12:37:54,100:INFO:Total runtime is 0.5025031884511312 minutes
2023-08-06 12:37:54,108:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:54,108:INFO:Initializing create_model()
2023-08-06 12:37:54,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:54,108:INFO:Checking exceptions
2023-08-06 12:37:54,108:INFO:Importing libraries
2023-08-06 12:37:54,108:INFO:Copying training dataset
2023-08-06 12:37:54,116:INFO:Defining folds
2023-08-06 12:37:54,116:INFO:Declaring metric variables
2023-08-06 12:37:54,124:INFO:Importing untrained model
2023-08-06 12:37:54,124:INFO:Linear Discriminant Analysis Imported successfully
2023-08-06 12:37:54,140:INFO:Starting cross validation
2023-08-06 12:37:54,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:55,864:INFO:Calculating mean and std
2023-08-06 12:37:55,864:INFO:Creating metrics dataframe
2023-08-06 12:37:55,864:INFO:Uploading results into container
2023-08-06 12:37:55,872:INFO:Uploading model into container now
2023-08-06 12:37:55,872:INFO:_master_model_container: 11
2023-08-06 12:37:55,872:INFO:_display_container: 2
2023-08-06 12:37:55,872:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-06 12:37:55,872:INFO:create_model() successfully completed......................................
2023-08-06 12:37:56,017:INFO:SubProcess create_model() end ==================================
2023-08-06 12:37:56,017:INFO:Creating metrics dataframe
2023-08-06 12:37:56,033:INFO:Initializing Extra Trees Classifier
2023-08-06 12:37:56,033:INFO:Total runtime is 0.534729790687561 minutes
2023-08-06 12:37:56,041:INFO:SubProcess create_model() called ==================================
2023-08-06 12:37:56,041:INFO:Initializing create_model()
2023-08-06 12:37:56,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:37:56,041:INFO:Checking exceptions
2023-08-06 12:37:56,041:INFO:Importing libraries
2023-08-06 12:37:56,041:INFO:Copying training dataset
2023-08-06 12:37:56,049:INFO:Defining folds
2023-08-06 12:37:56,049:INFO:Declaring metric variables
2023-08-06 12:37:56,057:INFO:Importing untrained model
2023-08-06 12:37:56,057:INFO:Extra Trees Classifier Imported successfully
2023-08-06 12:37:56,065:INFO:Starting cross validation
2023-08-06 12:37:56,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:37:58,282:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:58,307:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:58,323:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:58,483:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:58,587:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:58,764:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:58,908:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:37:58,989:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-06 12:38:00,308:INFO:Calculating mean and std
2023-08-06 12:38:00,308:INFO:Creating metrics dataframe
2023-08-06 12:38:00,316:INFO:Uploading results into container
2023-08-06 12:38:00,316:INFO:Uploading model into container now
2023-08-06 12:38:00,316:INFO:_master_model_container: 12
2023-08-06 12:38:00,316:INFO:_display_container: 2
2023-08-06 12:38:00,316:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-08-06 12:38:00,316:INFO:create_model() successfully completed......................................
2023-08-06 12:38:00,461:INFO:SubProcess create_model() end ==================================
2023-08-06 12:38:00,461:INFO:Creating metrics dataframe
2023-08-06 12:38:00,477:INFO:Initializing Extreme Gradient Boosting
2023-08-06 12:38:00,477:INFO:Total runtime is 0.6087976574897765 minutes
2023-08-06 12:38:00,485:INFO:SubProcess create_model() called ==================================
2023-08-06 12:38:00,485:INFO:Initializing create_model()
2023-08-06 12:38:00,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:38:00,485:INFO:Checking exceptions
2023-08-06 12:38:00,485:INFO:Importing libraries
2023-08-06 12:38:00,485:INFO:Copying training dataset
2023-08-06 12:38:00,493:INFO:Defining folds
2023-08-06 12:38:00,493:INFO:Declaring metric variables
2023-08-06 12:38:00,493:INFO:Importing untrained model
2023-08-06 12:38:00,503:INFO:Extreme Gradient Boosting Imported successfully
2023-08-06 12:38:00,518:INFO:Starting cross validation
2023-08-06 12:38:00,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:38:02,753:INFO:Calculating mean and std
2023-08-06 12:38:02,761:INFO:Creating metrics dataframe
2023-08-06 12:38:02,761:INFO:Uploading results into container
2023-08-06 12:38:02,761:INFO:Uploading model into container now
2023-08-06 12:38:02,769:INFO:_master_model_container: 13
2023-08-06 12:38:02,769:INFO:_display_container: 2
2023-08-06 12:38:02,769:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-06 12:38:02,769:INFO:create_model() successfully completed......................................
2023-08-06 12:38:02,906:INFO:SubProcess create_model() end ==================================
2023-08-06 12:38:02,906:INFO:Creating metrics dataframe
2023-08-06 12:38:02,911:INFO:Initializing Light Gradient Boosting Machine
2023-08-06 12:38:02,911:INFO:Total runtime is 0.6493660728136698 minutes
2023-08-06 12:38:02,927:INFO:SubProcess create_model() called ==================================
2023-08-06 12:38:02,927:INFO:Initializing create_model()
2023-08-06 12:38:02,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:38:02,927:INFO:Checking exceptions
2023-08-06 12:38:02,927:INFO:Importing libraries
2023-08-06 12:38:02,927:INFO:Copying training dataset
2023-08-06 12:38:02,927:INFO:Defining folds
2023-08-06 12:38:02,927:INFO:Declaring metric variables
2023-08-06 12:38:02,943:INFO:Importing untrained model
2023-08-06 12:38:02,943:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-06 12:38:02,958:INFO:Starting cross validation
2023-08-06 12:38:02,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:38:07,881:INFO:Calculating mean and std
2023-08-06 12:38:07,881:INFO:Creating metrics dataframe
2023-08-06 12:38:07,889:INFO:Uploading results into container
2023-08-06 12:38:07,889:INFO:Uploading model into container now
2023-08-06 12:38:07,889:INFO:_master_model_container: 14
2023-08-06 12:38:07,889:INFO:_display_container: 2
2023-08-06 12:38:07,889:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-06 12:38:07,889:INFO:create_model() successfully completed......................................
2023-08-06 12:38:08,058:INFO:SubProcess create_model() end ==================================
2023-08-06 12:38:08,058:INFO:Creating metrics dataframe
2023-08-06 12:38:08,074:INFO:Initializing Dummy Classifier
2023-08-06 12:38:08,074:INFO:Total runtime is 0.7354106426239013 minutes
2023-08-06 12:38:08,090:INFO:SubProcess create_model() called ==================================
2023-08-06 12:38:08,090:INFO:Initializing create_model()
2023-08-06 12:38:08,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F8FC7DCBE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:38:08,090:INFO:Checking exceptions
2023-08-06 12:38:08,090:INFO:Importing libraries
2023-08-06 12:38:08,090:INFO:Copying training dataset
2023-08-06 12:38:08,090:INFO:Defining folds
2023-08-06 12:38:08,090:INFO:Declaring metric variables
2023-08-06 12:38:08,105:INFO:Importing untrained model
2023-08-06 12:38:08,105:INFO:Dummy Classifier Imported successfully
2023-08-06 12:38:08,122:INFO:Starting cross validation
2023-08-06 12:38:08,122:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-06 12:38:09,097:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,097:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,097:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,112:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,113:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,120:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,160:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,175:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,855:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,855:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-06 12:38:09,855:INFO:Calculating mean and std
2023-08-06 12:38:09,855:INFO:Creating metrics dataframe
2023-08-06 12:38:09,855:INFO:Uploading results into container
2023-08-06 12:38:09,871:INFO:Uploading model into container now
2023-08-06 12:38:09,871:INFO:_master_model_container: 15
2023-08-06 12:38:09,871:INFO:_display_container: 2
2023-08-06 12:38:09,871:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-08-06 12:38:09,871:INFO:create_model() successfully completed......................................
2023-08-06 12:38:10,016:INFO:SubProcess create_model() end ==================================
2023-08-06 12:38:10,016:INFO:Creating metrics dataframe
2023-08-06 12:38:10,060:INFO:Initializing create_model()
2023-08-06 12:38:10,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F8FA3B6BE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-06 12:38:10,075:INFO:Checking exceptions
2023-08-06 12:38:10,078:INFO:Importing libraries
2023-08-06 12:38:10,078:INFO:Copying training dataset
2023-08-06 12:38:10,078:INFO:Defining folds
2023-08-06 12:38:10,078:INFO:Declaring metric variables
2023-08-06 12:38:10,078:INFO:Importing untrained model
2023-08-06 12:38:10,078:INFO:Declaring custom model
2023-08-06 12:38:10,078:INFO:Random Forest Classifier Imported successfully
2023-08-06 12:38:10,078:INFO:Cross validation set to False
2023-08-06 12:38:10,078:INFO:Fitting Model
2023-08-06 12:38:10,608:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-08-06 12:38:10,608:INFO:create_model() successfully completed......................................
2023-08-06 12:38:10,775:INFO:_master_model_container: 15
2023-08-06 12:38:10,775:INFO:_display_container: 2
2023-08-06 12:38:10,775:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-08-06 12:38:10,775:INFO:compare_models() successfully completed......................................
2023-08-13 10:56:42,603:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 10:56:42,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 10:56:42,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 10:56:42,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 10:56:44,603:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-08-13 11:44:13,542:INFO:PyCaret ClassificationExperiment
2023-08-13 11:44:13,550:INFO:Logging name: EXP_01_WANDA_2023
2023-08-13 11:44:13,550:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-13 11:44:13,550:INFO:version 3.0.0.rc9
2023-08-13 11:44:13,550:INFO:Initializing setup()
2023-08-13 11:44:13,550:INFO:self.USI: 291c
2023-08-13 11:44:13,558:INFO:self._variable_keys: {'X_test', 'is_multiclass', 'y_train', '_ml_usecase', 'log_plots_param', 'gpu_n_jobs_param', 'logging_param', 'X_train', 'seed', 'fold_groups_param', 'USI', 'gpu_param', 'fold_generator', 'X', '_available_plots', 'fix_imbalance', 'y_test', 'y', 'target_param', 'exp_id', 'data', 'n_jobs_param', 'fold_shuffle_param', 'pipeline', 'exp_name_log', 'memory', 'html_param', 'idx'}
2023-08-13 11:44:13,560:INFO:Checking environment
2023-08-13 11:44:13,560:INFO:python_version: 3.9.13
2023-08-13 11:44:13,560:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-13 11:44:13,566:INFO:machine: AMD64
2023-08-13 11:44:13,568:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-13 11:44:13,574:INFO:Memory: svmem(total=8266518528, available=1117732864, percent=86.5, used=7148785664, free=1117732864)
2023-08-13 11:44:13,574:INFO:Physical Core: 4
2023-08-13 11:44:13,574:INFO:Logical Core: 8
2023-08-13 11:44:13,574:INFO:Checking libraries
2023-08-13 11:44:13,574:INFO:System:
2023-08-13 11:44:13,574:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-13 11:44:13,574:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-08-13 11:44:13,574:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-13 11:44:13,574:INFO:PyCaret required dependencies:
2023-08-13 11:44:13,582:INFO:                 pip: 22.2.2
2023-08-13 11:44:13,582:INFO:          setuptools: 63.4.1
2023-08-13 11:44:13,582:INFO:             pycaret: 3.0.0rc9
2023-08-13 11:44:13,582:INFO:             IPython: 7.31.1
2023-08-13 11:44:13,582:INFO:          ipywidgets: 7.6.5
2023-08-13 11:44:13,582:INFO:                tqdm: 4.64.1
2023-08-13 11:44:13,582:INFO:               numpy: 1.21.5
2023-08-13 11:44:13,582:INFO:              pandas: 1.4.4
2023-08-13 11:44:13,582:INFO:              jinja2: 3.0.3
2023-08-13 11:44:13,582:INFO:               scipy: 1.9.1
2023-08-13 11:44:13,582:INFO:              joblib: 1.2.0
2023-08-13 11:44:13,582:INFO:             sklearn: 1.0.2
2023-08-13 11:44:13,582:INFO:                pyod: 1.0.7
2023-08-13 11:44:13,582:INFO:            imblearn: 0.10.1
2023-08-13 11:44:13,582:INFO:   category_encoders: 2.6.0
2023-08-13 11:44:13,582:INFO:            lightgbm: 3.3.5
2023-08-13 11:44:13,582:INFO:               numba: 0.55.1
2023-08-13 11:44:13,582:INFO:            requests: 2.28.1
2023-08-13 11:44:13,582:INFO:          matplotlib: 3.5.2
2023-08-13 11:44:13,582:INFO:          scikitplot: 0.3.7
2023-08-13 11:44:13,582:INFO:         yellowbrick: 1.5
2023-08-13 11:44:13,582:INFO:              plotly: 5.9.0
2023-08-13 11:44:13,582:INFO:             kaleido: 0.2.1
2023-08-13 11:44:13,582:INFO:         statsmodels: 0.13.2
2023-08-13 11:44:13,582:INFO:              sktime: 0.16.1
2023-08-13 11:44:13,582:INFO:               tbats: 1.1.2
2023-08-13 11:44:13,582:INFO:            pmdarima: 2.0.2
2023-08-13 11:44:13,582:INFO:              psutil: 5.9.0
2023-08-13 11:44:13,582:INFO:PyCaret optional dependencies:
2023-08-13 11:44:13,632:INFO:                shap: Not installed
2023-08-13 11:44:13,632:INFO:           interpret: Not installed
2023-08-13 11:44:13,632:INFO:                umap: Not installed
2023-08-13 11:44:13,632:INFO:    pandas_profiling: 4.3.1
2023-08-13 11:44:13,632:INFO:  explainerdashboard: Not installed
2023-08-13 11:44:13,632:INFO:             autoviz: 0.1.720
2023-08-13 11:44:13,632:INFO:           fairlearn: Not installed
2023-08-13 11:44:13,632:INFO:             xgboost: 1.7.5
2023-08-13 11:44:13,632:INFO:            catboost: Not installed
2023-08-13 11:44:13,632:INFO:              kmodes: Not installed
2023-08-13 11:44:13,632:INFO:             mlxtend: Not installed
2023-08-13 11:44:13,632:INFO:       statsforecast: Not installed
2023-08-13 11:44:13,639:INFO:        tune_sklearn: Not installed
2023-08-13 11:44:13,639:INFO:                 ray: Not installed
2023-08-13 11:44:13,639:INFO:            hyperopt: Not installed
2023-08-13 11:44:13,639:INFO:              optuna: Not installed
2023-08-13 11:44:13,639:INFO:               skopt: Not installed
2023-08-13 11:44:13,639:INFO:              mlflow: Not installed
2023-08-13 11:44:13,639:INFO:              gradio: Not installed
2023-08-13 11:44:13,639:INFO:             fastapi: Not installed
2023-08-13 11:44:13,639:INFO:             uvicorn: Not installed
2023-08-13 11:44:13,639:INFO:              m2cgen: Not installed
2023-08-13 11:44:13,639:INFO:           evidently: Not installed
2023-08-13 11:44:13,639:INFO:               fugue: Not installed
2023-08-13 11:44:13,639:INFO:           streamlit: Not installed
2023-08-13 11:44:13,639:INFO:             prophet: Not installed
2023-08-13 11:44:13,639:INFO:None
2023-08-13 11:44:13,640:INFO:Set up data.
2023-08-13 11:44:13,779:INFO:Set up train/test split.
2023-08-13 11:44:13,823:INFO:Set up index.
2023-08-13 11:44:13,827:INFO:Set up folding strategy.
2023-08-13 11:44:13,829:INFO:Assigning column types.
2023-08-13 11:44:13,830:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-13 11:44:13,965:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 11:44:14,003:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 11:44:14,101:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:14,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:14,552:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 11:44:14,552:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 11:44:14,625:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:14,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:14,633:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-13 11:44:14,751:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 11:44:14,824:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:14,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:14,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 11:44:15,019:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:15,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:15,028:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-13 11:44:15,215:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:15,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:15,399:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:15,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:15,429:INFO:Preparing preprocessing pipeline...
2023-08-13 11:44:15,435:INFO:Set up simple imputation.
2023-08-13 11:44:15,444:INFO:Set up encoding of ordinal features.
2023-08-13 11:44:15,452:INFO:Set up encoding of categorical features.
2023-08-13 11:44:15,452:INFO:Set up feature normalization.
2023-08-13 11:44:15,841:INFO:Finished creating preprocessing pipeline.
2023-08-13 11:44:15,951:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_valu...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-13 11:44:15,951:INFO:Creating final display dataframe.
2023-08-13 11:44:17,011:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               291c
2023-08-13 11:44:17,254:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:17,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:17,458:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 11:44:17,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 11:44:17,470:INFO:setup() successfully completed in 4.06s...............
2023-08-13 11:56:02,653:INFO:Initializing get_config()
2023-08-13 11:56:02,658:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213205843D0>, variable=X_train)
2023-08-13 11:56:02,661:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-08-13 11:56:02,669:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 11:56:02,747:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  
0                        3.0  LEVEL_7  
1                        0.0  LEVEL_3  
2                        2.0  LEVEL_7  
3                        0.0  LEVEL_7  
4                        1.0  LEVEL_7  
..                       ...      ...  
191                      0.0  LEVEL_3  
192                      1.0  LEVEL_7  
193                      0.0  LEVEL_7  
194                      0.0  LEVEL_3  
195                      0.0  LEVEL_3  

[196 rows x 13 columns]
2023-08-13 11:56:02,749:INFO:get_config() successfully completed......................................
2023-08-13 11:56:14,466:INFO:Initializing get_config()
2023-08-13 11:56:14,466:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000213205843D0>, variable=X_train_transformed)
2023-08-13 11:56:14,557:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-08-13 11:56:14,559:INFO:get_config() successfully completed......................................
2023-08-13 12:12:15,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 12:12:15,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 12:12:15,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 12:12:15,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 12:12:17,229:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-08-13 12:12:37,348:INFO:PyCaret ClassificationExperiment
2023-08-13 12:12:37,348:INFO:Logging name: EXP_01_WANDA_2023
2023-08-13 12:12:37,348:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-13 12:12:37,348:INFO:version 3.0.0.rc9
2023-08-13 12:12:37,348:INFO:Initializing setup()
2023-08-13 12:12:37,348:INFO:self.USI: dabf
2023-08-13 12:12:37,348:INFO:self._variable_keys: {'memory', 'data', 'gpu_n_jobs_param', 'exp_name_log', 'exp_id', 'fold_shuffle_param', 'idx', '_available_plots', 'X', 'pipeline', 'seed', 'fold_generator', 'fold_groups_param', 'target_param', 'X_train', 'html_param', 'y', 'is_multiclass', 'log_plots_param', 'USI', '_ml_usecase', 'fix_imbalance', 'y_test', 'n_jobs_param', 'y_train', 'X_test', 'logging_param', 'gpu_param'}
2023-08-13 12:12:37,348:INFO:Checking environment
2023-08-13 12:12:37,348:INFO:python_version: 3.9.13
2023-08-13 12:12:37,355:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-13 12:12:37,355:INFO:machine: AMD64
2023-08-13 12:12:37,355:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-13 12:12:37,355:INFO:Memory: svmem(total=8266518528, available=1038295040, percent=87.4, used=7228223488, free=1038295040)
2023-08-13 12:12:37,355:INFO:Physical Core: 4
2023-08-13 12:12:37,355:INFO:Logical Core: 8
2023-08-13 12:12:37,355:INFO:Checking libraries
2023-08-13 12:12:37,355:INFO:System:
2023-08-13 12:12:37,355:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-13 12:12:37,355:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-08-13 12:12:37,360:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-13 12:12:37,360:INFO:PyCaret required dependencies:
2023-08-13 12:12:37,360:INFO:                 pip: 22.2.2
2023-08-13 12:12:37,360:INFO:          setuptools: 63.4.1
2023-08-13 12:12:37,360:INFO:             pycaret: 3.0.0rc9
2023-08-13 12:12:37,360:INFO:             IPython: 7.31.1
2023-08-13 12:12:37,360:INFO:          ipywidgets: 7.6.5
2023-08-13 12:12:37,360:INFO:                tqdm: 4.64.1
2023-08-13 12:12:37,360:INFO:               numpy: 1.21.5
2023-08-13 12:12:37,360:INFO:              pandas: 1.4.4
2023-08-13 12:12:37,360:INFO:              jinja2: 3.0.3
2023-08-13 12:12:37,360:INFO:               scipy: 1.9.1
2023-08-13 12:12:37,360:INFO:              joblib: 1.2.0
2023-08-13 12:12:37,360:INFO:             sklearn: 1.0.2
2023-08-13 12:12:37,360:INFO:                pyod: 1.0.7
2023-08-13 12:12:37,360:INFO:            imblearn: 0.10.1
2023-08-13 12:12:37,360:INFO:   category_encoders: 2.6.0
2023-08-13 12:12:37,360:INFO:            lightgbm: 3.3.5
2023-08-13 12:12:37,360:INFO:               numba: 0.55.1
2023-08-13 12:12:37,360:INFO:            requests: 2.28.1
2023-08-13 12:12:37,360:INFO:          matplotlib: 3.5.2
2023-08-13 12:12:37,360:INFO:          scikitplot: 0.3.7
2023-08-13 12:12:37,360:INFO:         yellowbrick: 1.5
2023-08-13 12:12:37,360:INFO:              plotly: 5.9.0
2023-08-13 12:12:37,360:INFO:             kaleido: 0.2.1
2023-08-13 12:12:37,360:INFO:         statsmodels: 0.13.2
2023-08-13 12:12:37,360:INFO:              sktime: 0.16.1
2023-08-13 12:12:37,360:INFO:               tbats: 1.1.2
2023-08-13 12:12:37,360:INFO:            pmdarima: 2.0.2
2023-08-13 12:12:37,360:INFO:              psutil: 5.9.0
2023-08-13 12:12:37,360:INFO:PyCaret optional dependencies:
2023-08-13 12:12:37,398:INFO:                shap: Not installed
2023-08-13 12:12:37,398:INFO:           interpret: Not installed
2023-08-13 12:12:37,398:INFO:                umap: Not installed
2023-08-13 12:12:37,398:INFO:    pandas_profiling: 4.3.1
2023-08-13 12:12:37,398:INFO:  explainerdashboard: Not installed
2023-08-13 12:12:37,398:INFO:             autoviz: 0.1.720
2023-08-13 12:12:37,398:INFO:           fairlearn: Not installed
2023-08-13 12:12:37,398:INFO:             xgboost: 1.7.5
2023-08-13 12:12:37,398:INFO:            catboost: Not installed
2023-08-13 12:12:37,398:INFO:              kmodes: Not installed
2023-08-13 12:12:37,398:INFO:             mlxtend: Not installed
2023-08-13 12:12:37,398:INFO:       statsforecast: Not installed
2023-08-13 12:12:37,398:INFO:        tune_sklearn: Not installed
2023-08-13 12:12:37,398:INFO:                 ray: Not installed
2023-08-13 12:12:37,398:INFO:            hyperopt: Not installed
2023-08-13 12:12:37,398:INFO:              optuna: Not installed
2023-08-13 12:12:37,398:INFO:               skopt: Not installed
2023-08-13 12:12:37,398:INFO:              mlflow: Not installed
2023-08-13 12:12:37,398:INFO:              gradio: Not installed
2023-08-13 12:12:37,398:INFO:             fastapi: Not installed
2023-08-13 12:12:37,398:INFO:             uvicorn: Not installed
2023-08-13 12:12:37,398:INFO:              m2cgen: Not installed
2023-08-13 12:12:37,398:INFO:           evidently: Not installed
2023-08-13 12:12:37,398:INFO:               fugue: Not installed
2023-08-13 12:12:37,398:INFO:           streamlit: Not installed
2023-08-13 12:12:37,398:INFO:             prophet: Not installed
2023-08-13 12:12:37,398:INFO:None
2023-08-13 12:12:37,398:INFO:Set up data.
2023-08-13 12:12:37,422:INFO:Set up train/test split.
2023-08-13 12:12:37,449:INFO:Set up index.
2023-08-13 12:12:37,454:INFO:Set up folding strategy.
2023-08-13 12:12:37,454:INFO:Assigning column types.
2023-08-13 12:12:37,454:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-13 12:12:37,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 12:12:37,658:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:12:37,737:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:37,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:38,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 12:12:38,035:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:12:38,114:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:38,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:38,114:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-13 12:12:38,255:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:12:38,333:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:38,333:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:38,454:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:12:38,532:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:38,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:38,548:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-13 12:12:38,754:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:38,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:38,974:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:38,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:39,005:INFO:Preparing preprocessing pipeline...
2023-08-13 12:12:39,005:INFO:Set up simple imputation.
2023-08-13 12:12:39,021:INFO:Set up encoding of ordinal features.
2023-08-13 12:12:39,021:INFO:Set up encoding of categorical features.
2023-08-13 12:12:39,021:INFO:Set up feature normalization.
2023-08-13 12:12:39,319:INFO:Finished creating preprocessing pipeline.
2023-08-13 12:12:39,438:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_valu...
                                    transformer=LeaveOneOutEncoder(cols=['Chest_pain',
                                                                         'Resting_ECG',
                                                                         'Peak_exercise_ST_segment',
                                                                         'Thal'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=1935,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-13 12:12:39,438:INFO:Creating final display dataframe.
2023-08-13 12:12:40,460:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 14)
5   Transformed train set shape          (196, 14)
6    Transformed test set shape          (107, 14)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                  0
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               dabf
2023-08-13 12:12:40,667:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:40,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:40,920:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:12:40,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:12:40,936:INFO:setup() successfully completed in 3.59s...............
2023-08-13 12:12:47,269:INFO:Initializing get_config()
2023-08-13 12:12:47,269:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4E6366A0>, variable=X_train)
2023-08-13 12:12:47,269:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-08-13 12:12:47,274:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:12:47,290:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  
0                        3.0  LEVEL_7  
1                        0.0  LEVEL_3  
2                        2.0  LEVEL_7  
3                        0.0  LEVEL_7  
4                        1.0  LEVEL_7  
..                       ...      ...  
191                      0.0  LEVEL_3  
192                      1.0  LEVEL_7  
193                      0.0  LEVEL_7  
194                      0.0  LEVEL_3  
195                      0.0  LEVEL_3  

[196 rows x 13 columns]
2023-08-13 12:12:47,290:INFO:get_config() successfully completed......................................
2023-08-13 12:12:49,457:INFO:Initializing get_config()
2023-08-13 12:12:49,458:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4E6366A0>, variable=X_train_transformed)
2023-08-13 12:12:49,498:INFO:Variable: X_train returned as           Age       Sex  Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0   -0.631355  0.704403   -1.078073               -0.643981         -1.071874   
1   -1.804298 -1.419642   -1.007780                0.383128         -0.477305   
2   -0.279472  0.704403    1.032278               -0.358673         -0.625947   
3   -1.569709  0.704403    1.032278               -1.214598         -1.369159   
4    0.307000  0.704403    1.032278                1.181991          0.526031   
..        ...       ...         ...                     ...               ...   
191 -0.983238 -1.419642    1.073218                0.383128         -0.049958   
192  0.307000  0.704403    1.032278               -1.214598          1.659429   
193  0.072411  0.704403    1.032278                0.497251         -0.533046   
194  1.010766 -1.419642   -1.007780                0.211943          0.117264   
195 -0.631355 -1.419642    1.073218               -0.073365          0.433129   

     Fasting_blood_sugar  Resting_ECG  Max_heart_rate_achieved  \
0               0.441726    -1.065719                -0.422276   
1               0.441726    -0.970946                 0.150652   
2               0.441726    -1.065719                 0.855796   
3               0.441726     0.800740                 0.415081   
4               0.441726    -1.065719                -2.669920   
..                   ...          ...                      ...   
191             0.441726     0.889711                 0.150652   
192             0.441726    -1.065719                -0.245991   
193             0.441726    -1.065719                -1.656277   
194             0.441726     0.889711                 1.032081   
195             0.441726    -0.970946                 0.635438   

     Exercise_induced_angina  ST_depression  Peak_exercise_ST_segment  \
0                  -0.728869       0.758256                  0.910047   
1                  -0.728869      -0.910673                  0.958360   
2                  -0.728869      -0.076209                 -1.145727   
3                  -0.728869      -0.910673                 -1.145727   
4                   1.371989       0.090684                  0.910047   
..                       ...            ...                       ...   
191                 1.371989      -0.910673                  0.958360   
192                 1.371989       1.592720                  0.910047   
193                 1.371989       3.762328                  0.563809   
194                -0.728869      -0.910673                 -1.093528   
195                -0.728869      -0.910673                 -1.093528   

     Number_of_major_vessels      Thal  
0                   2.610225  1.151535  
1                  -0.735922 -0.878652  
2                   1.494842  1.151535  
3                  -0.735922  1.151535  
4                   0.379460  1.151535  
..                       ...       ...  
191                -0.735922 -0.878652  
192                 0.379460  1.151535  
193                -0.735922  1.151535  
194                -0.735922 -0.878652  
195                -0.735922 -0.878652  

[196 rows x 13 columns]
2023-08-13 12:12:49,498:INFO:get_config() successfully completed......................................
2023-08-13 12:14:52,781:INFO:PyCaret ClassificationExperiment
2023-08-13 12:14:52,781:INFO:Logging name: EXP_01_WANDA_2023
2023-08-13 12:14:52,781:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-13 12:14:52,781:INFO:version 3.0.0.rc9
2023-08-13 12:14:52,783:INFO:Initializing setup()
2023-08-13 12:14:52,783:INFO:self.USI: ca19
2023-08-13 12:14:52,783:INFO:self._variable_keys: {'memory', 'data', 'gpu_n_jobs_param', 'exp_name_log', 'exp_id', 'fold_shuffle_param', 'idx', '_available_plots', 'X', 'pipeline', 'seed', 'fold_generator', 'fold_groups_param', 'target_param', 'X_train', 'html_param', 'y', 'is_multiclass', 'log_plots_param', 'USI', '_ml_usecase', 'fix_imbalance', 'y_test', 'n_jobs_param', 'y_train', 'X_test', 'logging_param', 'gpu_param'}
2023-08-13 12:14:52,783:INFO:Checking environment
2023-08-13 12:14:52,783:INFO:python_version: 3.9.13
2023-08-13 12:14:52,783:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-13 12:14:52,785:INFO:machine: AMD64
2023-08-13 12:14:52,785:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-13 12:14:52,785:INFO:Memory: svmem(total=8266518528, available=1031913472, percent=87.5, used=7234605056, free=1031913472)
2023-08-13 12:14:52,785:INFO:Physical Core: 4
2023-08-13 12:14:52,785:INFO:Logical Core: 8
2023-08-13 12:14:52,785:INFO:Checking libraries
2023-08-13 12:14:52,785:INFO:System:
2023-08-13 12:14:52,785:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-13 12:14:52,785:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-08-13 12:14:52,785:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-13 12:14:52,785:INFO:PyCaret required dependencies:
2023-08-13 12:14:52,785:INFO:                 pip: 22.2.2
2023-08-13 12:14:52,785:INFO:          setuptools: 63.4.1
2023-08-13 12:14:52,785:INFO:             pycaret: 3.0.0rc9
2023-08-13 12:14:52,785:INFO:             IPython: 7.31.1
2023-08-13 12:14:52,785:INFO:          ipywidgets: 7.6.5
2023-08-13 12:14:52,785:INFO:                tqdm: 4.64.1
2023-08-13 12:14:52,785:INFO:               numpy: 1.21.5
2023-08-13 12:14:52,785:INFO:              pandas: 1.4.4
2023-08-13 12:14:52,785:INFO:              jinja2: 3.0.3
2023-08-13 12:14:52,785:INFO:               scipy: 1.9.1
2023-08-13 12:14:52,785:INFO:              joblib: 1.2.0
2023-08-13 12:14:52,785:INFO:             sklearn: 1.0.2
2023-08-13 12:14:52,785:INFO:                pyod: 1.0.7
2023-08-13 12:14:52,785:INFO:            imblearn: 0.10.1
2023-08-13 12:14:52,785:INFO:   category_encoders: 2.6.0
2023-08-13 12:14:52,785:INFO:            lightgbm: 3.3.5
2023-08-13 12:14:52,785:INFO:               numba: 0.55.1
2023-08-13 12:14:52,790:INFO:            requests: 2.28.1
2023-08-13 12:14:52,790:INFO:          matplotlib: 3.5.2
2023-08-13 12:14:52,790:INFO:          scikitplot: 0.3.7
2023-08-13 12:14:52,790:INFO:         yellowbrick: 1.5
2023-08-13 12:14:52,790:INFO:              plotly: 5.9.0
2023-08-13 12:14:52,790:INFO:             kaleido: 0.2.1
2023-08-13 12:14:52,790:INFO:         statsmodels: 0.13.2
2023-08-13 12:14:52,790:INFO:              sktime: 0.16.1
2023-08-13 12:14:52,790:INFO:               tbats: 1.1.2
2023-08-13 12:14:52,790:INFO:            pmdarima: 2.0.2
2023-08-13 12:14:52,790:INFO:              psutil: 5.9.0
2023-08-13 12:14:52,790:INFO:PyCaret optional dependencies:
2023-08-13 12:14:52,790:INFO:                shap: Not installed
2023-08-13 12:14:52,790:INFO:           interpret: Not installed
2023-08-13 12:14:52,790:INFO:                umap: Not installed
2023-08-13 12:14:52,790:INFO:    pandas_profiling: 4.3.1
2023-08-13 12:14:52,790:INFO:  explainerdashboard: Not installed
2023-08-13 12:14:52,790:INFO:             autoviz: 0.1.720
2023-08-13 12:14:52,790:INFO:           fairlearn: Not installed
2023-08-13 12:14:52,790:INFO:             xgboost: 1.7.5
2023-08-13 12:14:52,790:INFO:            catboost: Not installed
2023-08-13 12:14:52,790:INFO:              kmodes: Not installed
2023-08-13 12:14:52,790:INFO:             mlxtend: Not installed
2023-08-13 12:14:52,790:INFO:       statsforecast: Not installed
2023-08-13 12:14:52,790:INFO:        tune_sklearn: Not installed
2023-08-13 12:14:52,790:INFO:                 ray: Not installed
2023-08-13 12:14:52,790:INFO:            hyperopt: Not installed
2023-08-13 12:14:52,790:INFO:              optuna: Not installed
2023-08-13 12:14:52,790:INFO:               skopt: Not installed
2023-08-13 12:14:52,790:INFO:              mlflow: Not installed
2023-08-13 12:14:52,790:INFO:              gradio: Not installed
2023-08-13 12:14:52,791:INFO:             fastapi: Not installed
2023-08-13 12:14:52,791:INFO:             uvicorn: Not installed
2023-08-13 12:14:52,791:INFO:              m2cgen: Not installed
2023-08-13 12:14:52,791:INFO:           evidently: Not installed
2023-08-13 12:14:52,791:INFO:               fugue: Not installed
2023-08-13 12:14:52,791:INFO:           streamlit: Not installed
2023-08-13 12:14:52,791:INFO:             prophet: Not installed
2023-08-13 12:14:52,791:INFO:None
2023-08-13 12:14:52,791:INFO:Set up data.
2023-08-13 12:14:52,801:INFO:Set up train/test split.
2023-08-13 12:14:52,801:INFO:Set up index.
2023-08-13 12:14:52,801:INFO:Set up folding strategy.
2023-08-13 12:14:52,801:INFO:Assigning column types.
2023-08-13 12:14:52,818:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-13 12:14:52,942:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 12:14:52,942:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:14:53,025:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:53,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:53,156:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 12:14:53,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:14:53,210:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:53,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:53,225:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-13 12:14:53,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:14:53,398:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:53,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:53,508:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 12:14:53,586:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:53,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:53,595:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-13 12:14:53,786:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:53,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:54,000:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:54,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:54,000:INFO:Preparing preprocessing pipeline...
2023-08-13 12:14:54,016:INFO:Set up simple imputation.
2023-08-13 12:14:54,020:INFO:Set up encoding of ordinal features.
2023-08-13 12:14:54,020:INFO:Set up encoding of categorical features.
2023-08-13 12:14:54,020:INFO:Set up feature normalization.
2023-08-13 12:14:54,356:INFO:Finished creating preprocessing pipeline.
2023-08-13 12:14:54,465:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_valu...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-13 12:14:54,465:INFO:Creating final display dataframe.
2023-08-13 12:14:54,910:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               ca19
2023-08-13 12:14:55,117:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:55,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:55,354:INFO:Soft dependency imported: xgboost: 1.7.5
2023-08-13 12:14:55,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 12:14:55,369:INFO:setup() successfully completed in 2.59s...............
2023-08-13 12:15:00,400:INFO:Initializing get_config()
2023-08-13 12:15:00,400:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X_train)
2023-08-13 12:15:00,400:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-08-13 12:15:00,400:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:15:00,417:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  
0                        3.0  LEVEL_7  
1                        0.0  LEVEL_3  
2                        2.0  LEVEL_7  
3                        0.0  LEVEL_7  
4                        1.0  LEVEL_7  
..                       ...      ...  
191                      0.0  LEVEL_3  
192                      1.0  LEVEL_7  
193                      0.0  LEVEL_7  
194                      0.0  LEVEL_3  
195                      0.0  LEVEL_3  

[196 rows x 13 columns]
2023-08-13 12:15:00,417:INFO:get_config() successfully completed......................................
2023-08-13 12:15:03,124:INFO:Initializing get_config()
2023-08-13 12:15:03,124:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X_train_transformed)
2023-08-13 12:15:03,180:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-08-13 12:15:03,180:INFO:get_config() successfully completed......................................
2023-08-13 12:16:04,815:INFO:Initializing get_config()
2023-08-13 12:16:04,819:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X_test_transformed)
2023-08-13 12:16:04,872:INFO:Variable: X_test returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
196  1.597237  0.704403            1.621613           -0.940540   
197  0.893472 -1.419642           -0.616670            1.063219   
198  0.776177 -1.419642           -0.616670            1.063219   
199 -1.921592  0.704403            1.621613           -0.940540   
200 -0.162177 -1.419642           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
298 -0.748649  0.704403           -0.616670           -0.940540   
299 -1.804298  0.704403            1.621613           -0.940540   
300  1.362649  0.704403           -0.616670            1.063219   
301  1.479943  0.704403           -0.616670            1.063219   
302  0.658883  0.704403           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
196           -0.298142           -0.458123               -0.758105   
197           -0.298142           -0.458123                0.497251   
198           -0.298142           -0.458123               -0.073365   
199           -0.298142           -0.458123                0.383128   
200           -0.298142           -0.458123               -0.073365   
..                  ...                 ...                     ...   
298           -0.298142            2.182821               -1.214598   
299           -0.298142           -0.458123                0.497251   
300           -0.298142           -0.458123               -1.100474   
301           -0.298142           -0.458123               -0.643981   
302           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
196          0.581772             0.441726             1.052391  ...   
197          2.755666             0.441726            -0.950217  ...   
198          1.566527             0.441726            -0.950217  ...   
199         -1.313418             0.441726             1.052391  ...   
200          0.340228             0.441726            -0.950217  ...   
..                ...                  ...                  ...  ...   
298         -0.310082             0.441726             1.052391  ...   
299          1.399304             0.441726            -0.950217  ...   
300         -0.625947             0.441726            -0.950217  ...   
301         -0.161440             0.441726             1.052391  ...   
302         -0.737429             0.441726            -0.950217  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
196                 0.106581                -0.728869      -0.076209   
197                 0.371010                -0.728869       0.090684   
198                 0.899867                -0.728869      -0.910673   
199                 1.076153                -0.728869      -0.910673   
200                -0.245991                -0.728869      -0.576888   
..                       ...                      ...            ...   
298                 0.855796                -0.728869      -0.076209   
299                 1.472796                -0.728869      -0.910673   
300                -0.730777                 1.371989      -0.827227   
301                -3.419135                -0.728869      -0.076209   
302                -0.730777                 1.371989       1.092042   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
196                         -0.969842                          1.107823   
197                          1.031095                         -0.902671   
198                         -0.969842                          1.107823   
199                         -0.969842                          1.107823   
200                          1.031095                         -0.902671   
..                                ...                               ...   
298                         -0.969842                         -0.902671   
299                         -0.969842                          1.107823   
300                         -0.969842                          1.107823   
301                          1.031095                         -0.902671   
302                          1.031095                         -0.902671   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
196                         -0.266530                 0.379460      1.256562   
197                         -0.266530                -0.735922     -0.795822   
198                         -0.266530                -0.735922     -0.795822   
199                         -0.266530                 0.000000     -0.795822   
200                         -0.266530                -0.735922     -0.795822   
..                                ...                      ...           ...   
298                          3.751923                -0.735922      1.256562   
299                         -0.266530                -0.735922     -0.795822   
300                         -0.266530                 0.379460     -0.795822   
301                         -0.266530                -0.735922     -0.795822   
302                         -0.266530                 1.494842      1.256562   

     Thal_LEVEL_3  Thal_LEVEL_6  
196     -1.119318     -0.243843  
197      0.893401     -0.243843  
198      0.893401     -0.243843  
199      0.893401     -0.243843  
200      0.893401     -0.243843  
..            ...           ...  
298     -1.119318     -0.243843  
299      0.893401     -0.243843  
300      0.893401     -0.243843  
301      0.893401     -0.243843  
302     -1.119318     -0.243843  

[107 rows x 22 columns]
2023-08-13 12:16:04,872:INFO:get_config() successfully completed......................................
2023-08-13 12:16:13,428:INFO:Initializing get_config()
2023-08-13 12:16:13,428:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X_test)
2023-08-13 12:16:13,428:INFO:Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
2023-08-13 12:16:13,428:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:16:13,448:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  
196                      1.0  LEVEL_7  
197                      0.0  LEVEL_3  
198                      0.0  LEVEL_3  
199                      NaN  LEVEL_3  
200                      0.0  LEVEL_3  
..                       ...      ...  
298                      0.0  LEVEL_7  
299                      0.0  LEVEL_3  
300                      1.0  LEVEL_3  
301                      0.0  LEVEL_3  
302                      2.0  LEVEL_7  

[107 rows x 13 columns]
2023-08-13 12:16:13,448:INFO:get_config() successfully completed......................................
2023-08-13 12:16:19,721:INFO:Initializing get_config()
2023-08-13 12:16:19,721:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X_test_transformed)
2023-08-13 12:16:19,771:INFO:Variable: X_test returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
196  1.597237  0.704403            1.621613           -0.940540   
197  0.893472 -1.419642           -0.616670            1.063219   
198  0.776177 -1.419642           -0.616670            1.063219   
199 -1.921592  0.704403            1.621613           -0.940540   
200 -0.162177 -1.419642           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
298 -0.748649  0.704403           -0.616670           -0.940540   
299 -1.804298  0.704403            1.621613           -0.940540   
300  1.362649  0.704403           -0.616670            1.063219   
301  1.479943  0.704403           -0.616670            1.063219   
302  0.658883  0.704403           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
196           -0.298142           -0.458123               -0.758105   
197           -0.298142           -0.458123                0.497251   
198           -0.298142           -0.458123               -0.073365   
199           -0.298142           -0.458123                0.383128   
200           -0.298142           -0.458123               -0.073365   
..                  ...                 ...                     ...   
298           -0.298142            2.182821               -1.214598   
299           -0.298142           -0.458123                0.497251   
300           -0.298142           -0.458123               -1.100474   
301           -0.298142           -0.458123               -0.643981   
302           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
196          0.581772             0.441726             1.052391  ...   
197          2.755666             0.441726            -0.950217  ...   
198          1.566527             0.441726            -0.950217  ...   
199         -1.313418             0.441726             1.052391  ...   
200          0.340228             0.441726            -0.950217  ...   
..                ...                  ...                  ...  ...   
298         -0.310082             0.441726             1.052391  ...   
299          1.399304             0.441726            -0.950217  ...   
300         -0.625947             0.441726            -0.950217  ...   
301         -0.161440             0.441726             1.052391  ...   
302         -0.737429             0.441726            -0.950217  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
196                 0.106581                -0.728869      -0.076209   
197                 0.371010                -0.728869       0.090684   
198                 0.899867                -0.728869      -0.910673   
199                 1.076153                -0.728869      -0.910673   
200                -0.245991                -0.728869      -0.576888   
..                       ...                      ...            ...   
298                 0.855796                -0.728869      -0.076209   
299                 1.472796                -0.728869      -0.910673   
300                -0.730777                 1.371989      -0.827227   
301                -3.419135                -0.728869      -0.076209   
302                -0.730777                 1.371989       1.092042   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
196                         -0.969842                          1.107823   
197                          1.031095                         -0.902671   
198                         -0.969842                          1.107823   
199                         -0.969842                          1.107823   
200                          1.031095                         -0.902671   
..                                ...                               ...   
298                         -0.969842                         -0.902671   
299                         -0.969842                          1.107823   
300                         -0.969842                          1.107823   
301                          1.031095                         -0.902671   
302                          1.031095                         -0.902671   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
196                         -0.266530                 0.379460      1.256562   
197                         -0.266530                -0.735922     -0.795822   
198                         -0.266530                -0.735922     -0.795822   
199                         -0.266530                 0.000000     -0.795822   
200                         -0.266530                -0.735922     -0.795822   
..                                ...                      ...           ...   
298                          3.751923                -0.735922      1.256562   
299                         -0.266530                -0.735922     -0.795822   
300                         -0.266530                 0.379460     -0.795822   
301                         -0.266530                -0.735922     -0.795822   
302                         -0.266530                 1.494842      1.256562   

     Thal_LEVEL_3  Thal_LEVEL_6  
196     -1.119318     -0.243843  
197      0.893401     -0.243843  
198      0.893401     -0.243843  
199      0.893401     -0.243843  
200      0.893401     -0.243843  
..            ...           ...  
298     -1.119318     -0.243843  
299      0.893401     -0.243843  
300      0.893401     -0.243843  
301      0.893401     -0.243843  
302     -1.119318     -0.243843  

[107 rows x 22 columns]
2023-08-13 12:16:19,771:INFO:get_config() successfully completed......................................
2023-08-13 12:16:23,245:INFO:Initializing get_config()
2023-08-13 12:16:23,245:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=y_train)
2023-08-13 12:16:23,245:INFO:Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
2023-08-13 12:16:23,245:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'y_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:16:23,247:INFO:Variable:  returned as 0      1
1      0
2      1
3      1
4      1
      ..
191    0
192    1
193    1
194    0
195    0
Name: ALVO, Length: 196, dtype: int8
2023-08-13 12:16:23,247:INFO:get_config() successfully completed......................................
2023-08-13 12:16:49,881:INFO:Initializing get_config()
2023-08-13 12:16:49,881:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=y_test)
2023-08-13 12:16:49,888:INFO:Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
2023-08-13 12:16:49,888:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'y_test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'y_test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:16:49,889:INFO:Variable:  returned as 196    0
197    0
198    1
199    0
200    0
      ..
298    1
299    0
300    1
301    1
302    1
Name: ALVO, Length: 107, dtype: int8
2023-08-13 12:16:49,889:INFO:get_config() successfully completed......................................
2023-08-13 12:20:44,191:INFO:Initializing get_config()
2023-08-13 12:20:44,191:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X)
2023-08-13 12:20:44,211:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  
0                        3.0  LEVEL_7  
1                        0.0  LEVEL_3  
2                        2.0  LEVEL_7  
3                        0.0  LEVEL_7  
4                        1.0  LEVEL_7  
..                       ...      ...  
298                      0.0  LEVEL_7  
299                      0.0  LEVEL_3  
300                      1.0  LEVEL_3  
301                      0.0  LEVEL_3  
302                      2.0  LEVEL_7  

[303 rows x 13 columns]
2023-08-13 12:20:44,211:INFO:get_config() successfully completed......................................
2023-08-13 12:32:08,304:INFO:Initializing get_config()
2023-08-13 12:32:08,310:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=test_set)
2023-08-13 12:32:43,489:INFO:Initializing get_config()
2023-08-13 12:32:43,489:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=test)
2023-08-13 12:32:43,489:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-08-13 12:32:43,489:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:32:43,512:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  ALVO  
196                      1.0  LEVEL_7     0  
197                      0.0  LEVEL_3     0  
198                      0.0  LEVEL_3     1  
199                      NaN  LEVEL_3     0  
200                      0.0  LEVEL_3     0  
..                       ...      ...   ...  
298                      0.0  LEVEL_7     1  
299                      0.0  LEVEL_3     0  
300                      1.0  LEVEL_3     1  
301                      0.0  LEVEL_3     1  
302                      2.0  LEVEL_7     1  

[107 rows x 14 columns]
2023-08-13 12:32:43,513:INFO:get_config() successfully completed......................................
2023-08-13 12:33:07,267:INFO:Initializing get_config()
2023-08-13 12:33:07,267:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=train)
2023-08-13 12:33:07,267:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-08-13 12:33:07,267:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:33:07,287:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-08-13 12:33:07,287:INFO:get_config() successfully completed......................................
2023-08-13 12:33:58,809:INFO:Initializing get_config()
2023-08-13 12:33:58,812:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=train)
2023-08-13 12:33:58,813:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-08-13 12:33:58,814:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:33:58,834:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-08-13 12:33:58,835:INFO:get_config() successfully completed......................................
2023-08-13 12:34:27,289:INFO:Initializing get_config()
2023-08-13 12:34:27,289:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=train)
2023-08-13 12:34:27,289:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-08-13 12:34:27,289:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:34:27,305:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-08-13 12:34:27,305:INFO:get_config() successfully completed......................................
2023-08-13 12:34:57,037:INFO:Initializing get_config()
2023-08-13 12:34:57,037:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=test)
2023-08-13 12:34:57,037:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-08-13 12:34:57,037:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:34:57,045:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  ALVO  
196                      1.0  LEVEL_7     0  
197                      0.0  LEVEL_3     0  
198                      0.0  LEVEL_3     1  
199                      NaN  LEVEL_3     0  
200                      0.0  LEVEL_3     0  
..                       ...      ...   ...  
298                      0.0  LEVEL_7     1  
299                      0.0  LEVEL_3     0  
300                      1.0  LEVEL_3     1  
301                      0.0  LEVEL_3     1  
302                      2.0  LEVEL_7     1  

[107 rows x 14 columns]
2023-08-13 12:34:57,051:INFO:get_config() successfully completed......................................
2023-08-13 12:37:19,904:INFO:Initializing get_config()
2023-08-13 12:37:19,904:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X_train_transformed)
2023-08-13 12:37:19,994:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-08-13 12:37:19,995:INFO:get_config() successfully completed......................................
2023-08-13 12:38:01,385:INFO:Initializing get_config()
2023-08-13 12:38:01,391:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, variable=X_train)
2023-08-13 12:38:01,391:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-08-13 12:38:01,391:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-08-13 12:38:01,403:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  
0                        3.0  LEVEL_7  
1                        0.0  LEVEL_3  
2                        2.0  LEVEL_7  
3                        0.0  LEVEL_7  
4                        1.0  LEVEL_7  
..                       ...      ...  
191                      0.0  LEVEL_3  
192                      1.0  LEVEL_7  
193                      0.0  LEVEL_7  
194                      0.0  LEVEL_3  
195                      0.0  LEVEL_3  

[196 rows x 13 columns]
2023-08-13 12:38:01,404:INFO:get_config() successfully completed......................................
2023-08-13 12:46:46,488:INFO:Initializing compare_models()
2023-08-13 12:46:46,495:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-13 12:46:46,495:INFO:Checking exceptions
2023-08-13 12:46:46,504:INFO:Preparing display monitor
2023-08-13 12:46:46,626:INFO:Initializing Logistic Regression
2023-08-13 12:46:46,626:INFO:Total runtime is 0.0 minutes
2023-08-13 12:46:46,635:INFO:SubProcess create_model() called ==================================
2023-08-13 12:46:46,637:INFO:Initializing create_model()
2023-08-13 12:46:46,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:46:46,637:INFO:Checking exceptions
2023-08-13 12:46:46,637:INFO:Importing libraries
2023-08-13 12:46:46,637:INFO:Copying training dataset
2023-08-13 12:46:46,642:INFO:Defining folds
2023-08-13 12:46:46,642:INFO:Declaring metric variables
2023-08-13 12:46:46,650:INFO:Importing untrained model
2023-08-13 12:46:46,656:INFO:Logistic Regression Imported successfully
2023-08-13 12:46:46,674:INFO:Starting cross validation
2023-08-13 12:46:46,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:46:55,712:INFO:Calculating mean and std
2023-08-13 12:46:55,712:INFO:Creating metrics dataframe
2023-08-13 12:46:55,724:INFO:Uploading results into container
2023-08-13 12:46:55,724:INFO:Uploading model into container now
2023-08-13 12:46:55,730:INFO:_master_model_container: 1
2023-08-13 12:46:55,730:INFO:_display_container: 2
2023-08-13 12:46:55,730:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-13 12:46:55,730:INFO:create_model() successfully completed......................................
2023-08-13 12:46:55,957:INFO:SubProcess create_model() end ==================================
2023-08-13 12:46:55,957:INFO:Creating metrics dataframe
2023-08-13 12:46:55,981:INFO:Initializing K Neighbors Classifier
2023-08-13 12:46:55,981:INFO:Total runtime is 0.15591620604197184 minutes
2023-08-13 12:46:55,981:INFO:SubProcess create_model() called ==================================
2023-08-13 12:46:55,996:INFO:Initializing create_model()
2023-08-13 12:46:55,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:46:55,996:INFO:Checking exceptions
2023-08-13 12:46:55,996:INFO:Importing libraries
2023-08-13 12:46:55,996:INFO:Copying training dataset
2023-08-13 12:46:56,005:INFO:Defining folds
2023-08-13 12:46:56,005:INFO:Declaring metric variables
2023-08-13 12:46:56,013:INFO:Importing untrained model
2023-08-13 12:46:56,027:INFO:K Neighbors Classifier Imported successfully
2023-08-13 12:46:56,041:INFO:Starting cross validation
2023-08-13 12:46:56,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:46:57,051:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:57,051:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:57,170:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:57,170:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:57,175:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:57,190:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:57,214:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:57,218:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:58,089:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:58,120:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-13 12:46:58,199:INFO:Calculating mean and std
2023-08-13 12:46:58,199:INFO:Creating metrics dataframe
2023-08-13 12:46:58,207:INFO:Uploading results into container
2023-08-13 12:46:58,215:INFO:Uploading model into container now
2023-08-13 12:46:58,215:INFO:_master_model_container: 2
2023-08-13 12:46:58,215:INFO:_display_container: 2
2023-08-13 12:46:58,215:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-13 12:46:58,215:INFO:create_model() successfully completed......................................
2023-08-13 12:46:58,396:INFO:SubProcess create_model() end ==================================
2023-08-13 12:46:58,396:INFO:Creating metrics dataframe
2023-08-13 12:46:58,420:INFO:Initializing Naive Bayes
2023-08-13 12:46:58,420:INFO:Total runtime is 0.19657319386800132 minutes
2023-08-13 12:46:58,431:INFO:SubProcess create_model() called ==================================
2023-08-13 12:46:58,431:INFO:Initializing create_model()
2023-08-13 12:46:58,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:46:58,431:INFO:Checking exceptions
2023-08-13 12:46:58,431:INFO:Importing libraries
2023-08-13 12:46:58,431:INFO:Copying training dataset
2023-08-13 12:46:58,436:INFO:Defining folds
2023-08-13 12:46:58,436:INFO:Declaring metric variables
2023-08-13 12:46:58,451:INFO:Importing untrained model
2023-08-13 12:46:58,458:INFO:Naive Bayes Imported successfully
2023-08-13 12:46:58,474:INFO:Starting cross validation
2023-08-13 12:46:58,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:00,733:INFO:Calculating mean and std
2023-08-13 12:47:00,733:INFO:Creating metrics dataframe
2023-08-13 12:47:00,742:INFO:Uploading results into container
2023-08-13 12:47:00,742:INFO:Uploading model into container now
2023-08-13 12:47:00,750:INFO:_master_model_container: 3
2023-08-13 12:47:00,750:INFO:_display_container: 2
2023-08-13 12:47:00,750:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-13 12:47:00,750:INFO:create_model() successfully completed......................................
2023-08-13 12:47:00,941:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:00,941:INFO:Creating metrics dataframe
2023-08-13 12:47:00,967:INFO:Initializing Decision Tree Classifier
2023-08-13 12:47:00,967:INFO:Total runtime is 0.2390241305033366 minutes
2023-08-13 12:47:00,967:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:00,967:INFO:Initializing create_model()
2023-08-13 12:47:00,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:00,967:INFO:Checking exceptions
2023-08-13 12:47:00,967:INFO:Importing libraries
2023-08-13 12:47:00,967:INFO:Copying training dataset
2023-08-13 12:47:00,983:INFO:Defining folds
2023-08-13 12:47:00,983:INFO:Declaring metric variables
2023-08-13 12:47:00,991:INFO:Importing untrained model
2023-08-13 12:47:00,991:INFO:Decision Tree Classifier Imported successfully
2023-08-13 12:47:01,010:INFO:Starting cross validation
2023-08-13 12:47:01,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:03,185:INFO:Calculating mean and std
2023-08-13 12:47:03,185:INFO:Creating metrics dataframe
2023-08-13 12:47:03,195:INFO:Uploading results into container
2023-08-13 12:47:03,195:INFO:Uploading model into container now
2023-08-13 12:47:03,195:INFO:_master_model_container: 4
2023-08-13 12:47:03,195:INFO:_display_container: 2
2023-08-13 12:47:03,203:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-08-13 12:47:03,203:INFO:create_model() successfully completed......................................
2023-08-13 12:47:03,401:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:03,401:INFO:Creating metrics dataframe
2023-08-13 12:47:03,416:INFO:Initializing SVM - Linear Kernel
2023-08-13 12:47:03,416:INFO:Total runtime is 0.27984296083450316 minutes
2023-08-13 12:47:03,437:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:03,437:INFO:Initializing create_model()
2023-08-13 12:47:03,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:03,437:INFO:Checking exceptions
2023-08-13 12:47:03,437:INFO:Importing libraries
2023-08-13 12:47:03,437:INFO:Copying training dataset
2023-08-13 12:47:03,440:INFO:Defining folds
2023-08-13 12:47:03,440:INFO:Declaring metric variables
2023-08-13 12:47:03,448:INFO:Importing untrained model
2023-08-13 12:47:03,453:INFO:SVM - Linear Kernel Imported successfully
2023-08-13 12:47:03,464:INFO:Starting cross validation
2023-08-13 12:47:03,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:05,554:INFO:Calculating mean and std
2023-08-13 12:47:05,554:INFO:Creating metrics dataframe
2023-08-13 12:47:05,570:INFO:Uploading results into container
2023-08-13 12:47:05,570:INFO:Uploading model into container now
2023-08-13 12:47:05,570:INFO:_master_model_container: 5
2023-08-13 12:47:05,570:INFO:_display_container: 2
2023-08-13 12:47:05,570:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-13 12:47:05,570:INFO:create_model() successfully completed......................................
2023-08-13 12:47:05,776:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:05,776:INFO:Creating metrics dataframe
2023-08-13 12:47:05,792:INFO:Initializing Ridge Classifier
2023-08-13 12:47:05,792:INFO:Total runtime is 0.31944754521052043 minutes
2023-08-13 12:47:05,809:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:05,809:INFO:Initializing create_model()
2023-08-13 12:47:05,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:05,809:INFO:Checking exceptions
2023-08-13 12:47:05,809:INFO:Importing libraries
2023-08-13 12:47:05,809:INFO:Copying training dataset
2023-08-13 12:47:05,816:INFO:Defining folds
2023-08-13 12:47:05,816:INFO:Declaring metric variables
2023-08-13 12:47:05,825:INFO:Importing untrained model
2023-08-13 12:47:05,833:INFO:Ridge Classifier Imported successfully
2023-08-13 12:47:05,850:INFO:Starting cross validation
2023-08-13 12:47:05,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:07,819:INFO:Calculating mean and std
2023-08-13 12:47:07,819:INFO:Creating metrics dataframe
2023-08-13 12:47:07,834:INFO:Uploading results into container
2023-08-13 12:47:07,834:INFO:Uploading model into container now
2023-08-13 12:47:07,844:INFO:_master_model_container: 6
2023-08-13 12:47:07,844:INFO:_display_container: 2
2023-08-13 12:47:07,844:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1935, solver='auto', tol=0.001)
2023-08-13 12:47:07,844:INFO:create_model() successfully completed......................................
2023-08-13 12:47:08,025:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:08,025:INFO:Creating metrics dataframe
2023-08-13 12:47:08,057:INFO:Initializing Random Forest Classifier
2023-08-13 12:47:08,057:INFO:Total runtime is 0.3571850895881653 minutes
2023-08-13 12:47:08,068:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:08,068:INFO:Initializing create_model()
2023-08-13 12:47:08,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:08,068:INFO:Checking exceptions
2023-08-13 12:47:08,068:INFO:Importing libraries
2023-08-13 12:47:08,068:INFO:Copying training dataset
2023-08-13 12:47:08,083:INFO:Defining folds
2023-08-13 12:47:08,083:INFO:Declaring metric variables
2023-08-13 12:47:08,089:INFO:Importing untrained model
2023-08-13 12:47:08,090:INFO:Random Forest Classifier Imported successfully
2023-08-13 12:47:08,107:INFO:Starting cross validation
2023-08-13 12:47:08,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:09,753:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:09,754:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:09,754:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:09,786:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:09,792:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:09,822:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:09,853:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:11,706:INFO:Calculating mean and std
2023-08-13 12:47:11,706:INFO:Creating metrics dataframe
2023-08-13 12:47:11,727:INFO:Uploading results into container
2023-08-13 12:47:11,727:INFO:Uploading model into container now
2023-08-13 12:47:11,727:INFO:_master_model_container: 7
2023-08-13 12:47:11,727:INFO:_display_container: 2
2023-08-13 12:47:11,727:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-08-13 12:47:11,727:INFO:create_model() successfully completed......................................
2023-08-13 12:47:11,931:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:11,931:INFO:Creating metrics dataframe
2023-08-13 12:47:11,946:INFO:Initializing Quadratic Discriminant Analysis
2023-08-13 12:47:11,946:INFO:Total runtime is 0.4220101594924927 minutes
2023-08-13 12:47:11,968:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:11,968:INFO:Initializing create_model()
2023-08-13 12:47:11,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:11,970:INFO:Checking exceptions
2023-08-13 12:47:11,970:INFO:Importing libraries
2023-08-13 12:47:11,970:INFO:Copying training dataset
2023-08-13 12:47:11,978:INFO:Defining folds
2023-08-13 12:47:11,978:INFO:Declaring metric variables
2023-08-13 12:47:11,986:INFO:Importing untrained model
2023-08-13 12:47:11,988:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-13 12:47:12,000:INFO:Starting cross validation
2023-08-13 12:47:12,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:12,496:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:12,507:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:12,507:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:12,515:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:12,546:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:12,562:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:12,594:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:12,597:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:13,569:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:13,617:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-13 12:47:14,041:INFO:Calculating mean and std
2023-08-13 12:47:14,041:INFO:Creating metrics dataframe
2023-08-13 12:47:14,057:INFO:Uploading results into container
2023-08-13 12:47:14,057:INFO:Uploading model into container now
2023-08-13 12:47:14,060:INFO:_master_model_container: 8
2023-08-13 12:47:14,060:INFO:_display_container: 2
2023-08-13 12:47:14,060:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-13 12:47:14,060:INFO:create_model() successfully completed......................................
2023-08-13 12:47:14,248:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:14,248:INFO:Creating metrics dataframe
2023-08-13 12:47:14,279:INFO:Initializing Ada Boost Classifier
2023-08-13 12:47:14,279:INFO:Total runtime is 0.46088831822077436 minutes
2023-08-13 12:47:14,290:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:14,290:INFO:Initializing create_model()
2023-08-13 12:47:14,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:14,290:INFO:Checking exceptions
2023-08-13 12:47:14,290:INFO:Importing libraries
2023-08-13 12:47:14,290:INFO:Copying training dataset
2023-08-13 12:47:14,301:INFO:Defining folds
2023-08-13 12:47:14,301:INFO:Declaring metric variables
2023-08-13 12:47:14,301:INFO:Importing untrained model
2023-08-13 12:47:14,306:INFO:Ada Boost Classifier Imported successfully
2023-08-13 12:47:14,316:INFO:Starting cross validation
2023-08-13 12:47:14,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:17,415:INFO:Calculating mean and std
2023-08-13 12:47:17,415:INFO:Creating metrics dataframe
2023-08-13 12:47:17,430:INFO:Uploading results into container
2023-08-13 12:47:17,438:INFO:Uploading model into container now
2023-08-13 12:47:17,438:INFO:_master_model_container: 9
2023-08-13 12:47:17,438:INFO:_display_container: 2
2023-08-13 12:47:17,438:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1935)
2023-08-13 12:47:17,438:INFO:create_model() successfully completed......................................
2023-08-13 12:47:17,615:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:17,615:INFO:Creating metrics dataframe
2023-08-13 12:47:17,647:INFO:Initializing Gradient Boosting Classifier
2023-08-13 12:47:17,647:INFO:Total runtime is 0.5170202970504761 minutes
2023-08-13 12:47:17,665:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:17,665:INFO:Initializing create_model()
2023-08-13 12:47:17,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:17,665:INFO:Checking exceptions
2023-08-13 12:47:17,665:INFO:Importing libraries
2023-08-13 12:47:17,665:INFO:Copying training dataset
2023-08-13 12:47:17,671:INFO:Defining folds
2023-08-13 12:47:17,671:INFO:Declaring metric variables
2023-08-13 12:47:17,679:INFO:Importing untrained model
2023-08-13 12:47:17,687:INFO:Gradient Boosting Classifier Imported successfully
2023-08-13 12:47:17,700:INFO:Starting cross validation
2023-08-13 12:47:17,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:19,172:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:20,871:INFO:Calculating mean and std
2023-08-13 12:47:20,886:INFO:Creating metrics dataframe
2023-08-13 12:47:20,886:INFO:Uploading results into container
2023-08-13 12:47:20,886:INFO:Uploading model into container now
2023-08-13 12:47:20,900:INFO:_master_model_container: 10
2023-08-13 12:47:20,900:INFO:_display_container: 2
2023-08-13 12:47:20,900:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-13 12:47:20,900:INFO:create_model() successfully completed......................................
2023-08-13 12:47:21,097:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:21,097:INFO:Creating metrics dataframe
2023-08-13 12:47:21,116:INFO:Initializing Linear Discriminant Analysis
2023-08-13 12:47:21,116:INFO:Total runtime is 0.5748471816380819 minutes
2023-08-13 12:47:21,134:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:21,134:INFO:Initializing create_model()
2023-08-13 12:47:21,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:21,134:INFO:Checking exceptions
2023-08-13 12:47:21,134:INFO:Importing libraries
2023-08-13 12:47:21,134:INFO:Copying training dataset
2023-08-13 12:47:21,145:INFO:Defining folds
2023-08-13 12:47:21,145:INFO:Declaring metric variables
2023-08-13 12:47:21,152:INFO:Importing untrained model
2023-08-13 12:47:21,164:INFO:Linear Discriminant Analysis Imported successfully
2023-08-13 12:47:21,171:INFO:Starting cross validation
2023-08-13 12:47:21,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:22,922:INFO:Calculating mean and std
2023-08-13 12:47:22,922:INFO:Creating metrics dataframe
2023-08-13 12:47:22,938:INFO:Uploading results into container
2023-08-13 12:47:22,938:INFO:Uploading model into container now
2023-08-13 12:47:22,938:INFO:_master_model_container: 11
2023-08-13 12:47:22,938:INFO:_display_container: 2
2023-08-13 12:47:22,938:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-13 12:47:22,938:INFO:create_model() successfully completed......................................
2023-08-13 12:47:23,138:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:23,138:INFO:Creating metrics dataframe
2023-08-13 12:47:23,167:INFO:Initializing Extra Trees Classifier
2023-08-13 12:47:23,167:INFO:Total runtime is 0.6090275247891744 minutes
2023-08-13 12:47:23,181:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:23,181:INFO:Initializing create_model()
2023-08-13 12:47:23,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:23,181:INFO:Checking exceptions
2023-08-13 12:47:23,181:INFO:Importing libraries
2023-08-13 12:47:23,181:INFO:Copying training dataset
2023-08-13 12:47:23,195:INFO:Defining folds
2023-08-13 12:47:23,195:INFO:Declaring metric variables
2023-08-13 12:47:23,198:INFO:Importing untrained model
2023-08-13 12:47:23,204:INFO:Extra Trees Classifier Imported successfully
2023-08-13 12:47:23,221:INFO:Starting cross validation
2023-08-13 12:47:23,221:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:24,844:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:24,864:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:24,901:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:24,950:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:24,951:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 12:47:26,324:INFO:Calculating mean and std
2023-08-13 12:47:26,333:INFO:Creating metrics dataframe
2023-08-13 12:47:26,346:INFO:Uploading results into container
2023-08-13 12:47:26,346:INFO:Uploading model into container now
2023-08-13 12:47:26,346:INFO:_master_model_container: 12
2023-08-13 12:47:26,346:INFO:_display_container: 2
2023-08-13 12:47:26,346:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-08-13 12:47:26,346:INFO:create_model() successfully completed......................................
2023-08-13 12:47:26,532:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:26,532:INFO:Creating metrics dataframe
2023-08-13 12:47:26,565:INFO:Initializing Extreme Gradient Boosting
2023-08-13 12:47:26,565:INFO:Total runtime is 0.6656491796175639 minutes
2023-08-13 12:47:26,573:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:26,573:INFO:Initializing create_model()
2023-08-13 12:47:26,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:26,573:INFO:Checking exceptions
2023-08-13 12:47:26,573:INFO:Importing libraries
2023-08-13 12:47:26,573:INFO:Copying training dataset
2023-08-13 12:47:26,582:INFO:Defining folds
2023-08-13 12:47:26,582:INFO:Declaring metric variables
2023-08-13 12:47:26,592:INFO:Importing untrained model
2023-08-13 12:47:26,598:INFO:Extreme Gradient Boosting Imported successfully
2023-08-13 12:47:26,605:INFO:Starting cross validation
2023-08-13 12:47:26,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:28,528:INFO:Calculating mean and std
2023-08-13 12:47:28,531:INFO:Creating metrics dataframe
2023-08-13 12:47:28,531:INFO:Uploading results into container
2023-08-13 12:47:28,531:INFO:Uploading model into container now
2023-08-13 12:47:28,542:INFO:_master_model_container: 13
2023-08-13 12:47:28,542:INFO:_display_container: 2
2023-08-13 12:47:28,547:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-13 12:47:28,547:INFO:create_model() successfully completed......................................
2023-08-13 12:47:28,746:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:28,746:INFO:Creating metrics dataframe
2023-08-13 12:47:28,762:INFO:Initializing Light Gradient Boosting Machine
2023-08-13 12:47:28,762:INFO:Total runtime is 0.7022721330324808 minutes
2023-08-13 12:47:28,784:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:28,786:INFO:Initializing create_model()
2023-08-13 12:47:28,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:28,786:INFO:Checking exceptions
2023-08-13 12:47:28,786:INFO:Importing libraries
2023-08-13 12:47:28,786:INFO:Copying training dataset
2023-08-13 12:47:28,794:INFO:Defining folds
2023-08-13 12:47:28,794:INFO:Declaring metric variables
2023-08-13 12:47:28,803:INFO:Importing untrained model
2023-08-13 12:47:28,813:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-13 12:47:28,820:INFO:Starting cross validation
2023-08-13 12:47:28,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:32,832:INFO:Calculating mean and std
2023-08-13 12:47:32,832:INFO:Creating metrics dataframe
2023-08-13 12:47:32,849:INFO:Uploading results into container
2023-08-13 12:47:32,854:INFO:Uploading model into container now
2023-08-13 12:47:32,854:INFO:_master_model_container: 14
2023-08-13 12:47:32,854:INFO:_display_container: 2
2023-08-13 12:47:32,854:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-13 12:47:32,854:INFO:create_model() successfully completed......................................
2023-08-13 12:47:33,045:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:33,045:INFO:Creating metrics dataframe
2023-08-13 12:47:33,076:INFO:Initializing Dummy Classifier
2023-08-13 12:47:33,076:INFO:Total runtime is 0.7741786003112793 minutes
2023-08-13 12:47:33,092:INFO:SubProcess create_model() called ==================================
2023-08-13 12:47:33,100:INFO:Initializing create_model()
2023-08-13 12:47:33,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027F50A43940>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:33,100:INFO:Checking exceptions
2023-08-13 12:47:33,100:INFO:Importing libraries
2023-08-13 12:47:33,100:INFO:Copying training dataset
2023-08-13 12:47:33,108:INFO:Defining folds
2023-08-13 12:47:33,108:INFO:Declaring metric variables
2023-08-13 12:47:33,108:INFO:Importing untrained model
2023-08-13 12:47:33,116:INFO:Dummy Classifier Imported successfully
2023-08-13 12:47:33,125:INFO:Starting cross validation
2023-08-13 12:47:33,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:47:33,776:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:33,809:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:33,865:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:33,867:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:33,897:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:33,899:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:34,179:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:34,195:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:34,605:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:34,652:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 12:47:34,652:INFO:Calculating mean and std
2023-08-13 12:47:34,652:INFO:Creating metrics dataframe
2023-08-13 12:47:34,667:INFO:Uploading results into container
2023-08-13 12:47:34,667:INFO:Uploading model into container now
2023-08-13 12:47:34,681:INFO:_master_model_container: 15
2023-08-13 12:47:34,681:INFO:_display_container: 2
2023-08-13 12:47:34,681:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-08-13 12:47:34,681:INFO:create_model() successfully completed......................................
2023-08-13 12:47:34,878:INFO:SubProcess create_model() end ==================================
2023-08-13 12:47:34,878:INFO:Creating metrics dataframe
2023-08-13 12:47:34,928:INFO:Initializing create_model()
2023-08-13 12:47:34,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:47:34,928:INFO:Checking exceptions
2023-08-13 12:47:34,937:INFO:Importing libraries
2023-08-13 12:47:34,937:INFO:Copying training dataset
2023-08-13 12:47:34,937:INFO:Defining folds
2023-08-13 12:47:34,946:INFO:Declaring metric variables
2023-08-13 12:47:34,946:INFO:Importing untrained model
2023-08-13 12:47:34,946:INFO:Declaring custom model
2023-08-13 12:47:34,946:INFO:Random Forest Classifier Imported successfully
2023-08-13 12:47:34,946:INFO:Cross validation set to False
2023-08-13 12:47:34,946:INFO:Fitting Model
2023-08-13 12:47:35,306:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-08-13 12:47:35,306:INFO:create_model() successfully completed......................................
2023-08-13 12:47:35,595:INFO:_master_model_container: 15
2023-08-13 12:47:35,602:INFO:_display_container: 2
2023-08-13 12:47:35,602:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-08-13 12:47:35,602:INFO:compare_models() successfully completed......................................
2023-08-13 12:50:59,114:INFO:Initializing create_model()
2023-08-13 12:50:59,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-13 12:50:59,116:INFO:Checking exceptions
2023-08-13 12:50:59,170:INFO:Importing libraries
2023-08-13 12:50:59,170:INFO:Copying training dataset
2023-08-13 12:50:59,177:INFO:Defining folds
2023-08-13 12:50:59,177:INFO:Declaring metric variables
2023-08-13 12:50:59,185:INFO:Importing untrained model
2023-08-13 12:50:59,193:INFO:Logistic Regression Imported successfully
2023-08-13 12:50:59,211:INFO:Starting cross validation
2023-08-13 12:50:59,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 12:51:00,655:INFO:Calculating mean and std
2023-08-13 12:51:00,663:INFO:Creating metrics dataframe
2023-08-13 12:51:00,675:INFO:Finalizing model
2023-08-13 12:51:01,015:INFO:Uploading results into container
2023-08-13 12:51:01,015:INFO:Uploading model into container now
2023-08-13 12:51:01,036:INFO:_master_model_container: 16
2023-08-13 12:51:01,037:INFO:_display_container: 3
2023-08-13 12:51:01,037:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-13 12:51:01,037:INFO:create_model() successfully completed......................................
2023-08-13 12:51:09,488:INFO:Initializing predict_model()
2023-08-13 12:51:09,489:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4ED8E940>)
2023-08-13 12:51:09,489:INFO:Checking exceptions
2023-08-13 12:51:09,489:INFO:Preloading libraries
2023-08-13 12:55:58,875:INFO:Initializing predict_model()
2023-08-13 12:55:58,891:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4E9C3820>)
2023-08-13 12:55:58,891:INFO:Checking exceptions
2023-08-13 12:55:58,891:INFO:Preloading libraries
2023-08-13 12:55:58,964:INFO:Set up data.
2023-08-13 12:55:59,037:INFO:Set up index.
2023-08-13 12:56:22,021:INFO:Initializing predict_model()
2023-08-13 12:56:22,022:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4E9C39D0>)
2023-08-13 12:56:22,022:INFO:Checking exceptions
2023-08-13 12:56:22,022:INFO:Preloading libraries
2023-08-13 12:56:22,024:INFO:Set up data.
2023-08-13 12:56:22,035:INFO:Set up index.
2023-08-13 12:56:30,846:INFO:Initializing predict_model()
2023-08-13 12:56:30,846:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4EEB1CA0>)
2023-08-13 12:56:30,846:INFO:Checking exceptions
2023-08-13 12:56:30,846:INFO:Preloading libraries
2023-08-13 12:56:42,531:INFO:Initializing predict_model()
2023-08-13 12:56:42,531:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4EA8D280>)
2023-08-13 12:56:42,531:INFO:Checking exceptions
2023-08-13 12:56:42,531:INFO:Preloading libraries
2023-08-13 12:56:42,540:INFO:Set up data.
2023-08-13 12:56:42,550:INFO:Set up index.
2023-08-13 12:56:48,025:INFO:Initializing predict_model()
2023-08-13 12:56:48,025:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4E99ADC0>)
2023-08-13 12:56:48,025:INFO:Checking exceptions
2023-08-13 12:56:48,025:INFO:Preloading libraries
2023-08-13 13:00:53,493:INFO:Initializing predict_model()
2023-08-13 13:00:53,493:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4EFB0EE0>)
2023-08-13 13:00:53,493:INFO:Checking exceptions
2023-08-13 13:00:53,493:INFO:Preloading libraries
2023-08-13 13:00:53,499:INFO:Set up data.
2023-08-13 13:00:53,508:INFO:Set up index.
2023-08-13 13:01:56,002:INFO:Initializing create_model()
2023-08-13 13:01:56,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-13 13:01:56,004:INFO:Checking exceptions
2023-08-13 13:01:56,046:INFO:Importing libraries
2023-08-13 13:01:56,046:INFO:Copying training dataset
2023-08-13 13:01:56,053:INFO:Defining folds
2023-08-13 13:01:56,053:INFO:Declaring metric variables
2023-08-13 13:01:56,053:INFO:Importing untrained model
2023-08-13 13:01:56,076:INFO:Extreme Gradient Boosting Imported successfully
2023-08-13 13:01:56,091:INFO:Starting cross validation
2023-08-13 13:01:56,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 13:02:04,205:INFO:Calculating mean and std
2023-08-13 13:02:04,214:INFO:Creating metrics dataframe
2023-08-13 13:02:04,223:INFO:Finalizing model
2023-08-13 13:02:04,785:INFO:Uploading results into container
2023-08-13 13:02:04,785:INFO:Uploading model into container now
2023-08-13 13:02:04,804:INFO:_master_model_container: 17
2023-08-13 13:02:04,804:INFO:_display_container: 11
2023-08-13 13:02:04,804:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-13 13:02:04,811:INFO:create_model() successfully completed......................................
2023-08-13 13:02:14,068:INFO:Initializing predict_model()
2023-08-13 13:02:14,068:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F4EA6EA60>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027F4E99ADC0>)
2023-08-13 13:02:14,068:INFO:Checking exceptions
2023-08-13 13:02:14,068:INFO:Preloading libraries
2023-08-13 13:02:14,073:INFO:Set up data.
2023-08-13 13:02:14,083:INFO:Set up index.
2023-09-03 10:44:17,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 10:44:17,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 10:44:17,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 10:44:17,937:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 10:44:18,842:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-09-03 10:44:58,041:INFO:PyCaret ClassificationExperiment
2023-09-03 10:44:58,041:INFO:Logging name: EXP_01_WANDA_2023
2023-09-03 10:44:58,041:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-03 10:44:58,041:INFO:version 3.0.0.rc9
2023-09-03 10:44:58,041:INFO:Initializing setup()
2023-09-03 10:44:58,041:INFO:self.USI: d22e
2023-09-03 10:44:58,041:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'memory', 'fix_imbalance', 'y', 'X', 'html_param', 'gpu_param', 'log_plots_param', 'exp_id', 'fold_shuffle_param', 'X_test', 'data', 'idx', 'is_multiclass', 'X_train', '_available_plots', 'seed', 'pipeline', 'logging_param', '_ml_usecase', 'n_jobs_param', 'target_param', 'y_train', 'fold_generator', 'USI', 'fold_groups_param', 'y_test'}
2023-09-03 10:44:58,041:INFO:Checking environment
2023-09-03 10:44:58,041:INFO:python_version: 3.9.13
2023-09-03 10:44:58,041:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-09-03 10:44:58,041:INFO:machine: AMD64
2023-09-03 10:44:58,041:INFO:platform: Windows-10-10.0.22621-SP0
2023-09-03 10:44:58,041:INFO:Memory: svmem(total=8266518528, available=520982528, percent=93.7, used=7745536000, free=520982528)
2023-09-03 10:44:58,041:INFO:Physical Core: 4
2023-09-03 10:44:58,041:INFO:Logical Core: 8
2023-09-03 10:44:58,041:INFO:Checking libraries
2023-09-03 10:44:58,041:INFO:System:
2023-09-03 10:44:58,041:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-09-03 10:44:58,041:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-09-03 10:44:58,041:INFO:   machine: Windows-10-10.0.22621-SP0
2023-09-03 10:44:58,041:INFO:PyCaret required dependencies:
2023-09-03 10:44:58,041:INFO:                 pip: 22.2.2
2023-09-03 10:44:58,041:INFO:          setuptools: 63.4.1
2023-09-03 10:44:58,041:INFO:             pycaret: 3.0.0rc9
2023-09-03 10:44:58,041:INFO:             IPython: 7.31.1
2023-09-03 10:44:58,041:INFO:          ipywidgets: 7.6.5
2023-09-03 10:44:58,041:INFO:                tqdm: 4.64.1
2023-09-03 10:44:58,041:INFO:               numpy: 1.21.5
2023-09-03 10:44:58,041:INFO:              pandas: 1.4.4
2023-09-03 10:44:58,041:INFO:              jinja2: 3.0.3
2023-09-03 10:44:58,041:INFO:               scipy: 1.9.1
2023-09-03 10:44:58,041:INFO:              joblib: 1.2.0
2023-09-03 10:44:58,041:INFO:             sklearn: 1.0.2
2023-09-03 10:44:58,041:INFO:                pyod: 1.0.7
2023-09-03 10:44:58,041:INFO:            imblearn: 0.10.1
2023-09-03 10:44:58,041:INFO:   category_encoders: 2.6.0
2023-09-03 10:44:58,041:INFO:            lightgbm: 3.3.5
2023-09-03 10:44:58,041:INFO:               numba: 0.55.1
2023-09-03 10:44:58,041:INFO:            requests: 2.28.1
2023-09-03 10:44:58,041:INFO:          matplotlib: 3.5.2
2023-09-03 10:44:58,041:INFO:          scikitplot: 0.3.7
2023-09-03 10:44:58,041:INFO:         yellowbrick: 1.5
2023-09-03 10:44:58,041:INFO:              plotly: 5.9.0
2023-09-03 10:44:58,041:INFO:             kaleido: 0.2.1
2023-09-03 10:44:58,041:INFO:         statsmodels: 0.13.2
2023-09-03 10:44:58,041:INFO:              sktime: 0.16.1
2023-09-03 10:44:58,041:INFO:               tbats: 1.1.2
2023-09-03 10:44:58,041:INFO:            pmdarima: 2.0.2
2023-09-03 10:44:58,041:INFO:              psutil: 5.9.0
2023-09-03 10:44:58,041:INFO:PyCaret optional dependencies:
2023-09-03 10:44:58,057:INFO:                shap: Not installed
2023-09-03 10:44:58,057:INFO:           interpret: Not installed
2023-09-03 10:44:58,057:INFO:                umap: Not installed
2023-09-03 10:44:58,057:INFO:    pandas_profiling: 4.3.1
2023-09-03 10:44:58,057:INFO:  explainerdashboard: Not installed
2023-09-03 10:44:58,057:INFO:             autoviz: 0.1.720
2023-09-03 10:44:58,057:INFO:           fairlearn: Not installed
2023-09-03 10:44:58,057:INFO:             xgboost: 1.7.5
2023-09-03 10:44:58,057:INFO:            catboost: 1.2
2023-09-03 10:44:58,057:INFO:              kmodes: Not installed
2023-09-03 10:44:58,057:INFO:             mlxtend: Not installed
2023-09-03 10:44:58,057:INFO:       statsforecast: Not installed
2023-09-03 10:44:58,057:INFO:        tune_sklearn: Not installed
2023-09-03 10:44:58,057:INFO:                 ray: Not installed
2023-09-03 10:44:58,057:INFO:            hyperopt: Not installed
2023-09-03 10:44:58,057:INFO:              optuna: Not installed
2023-09-03 10:44:58,057:INFO:               skopt: Not installed
2023-09-03 10:44:58,057:INFO:              mlflow: Not installed
2023-09-03 10:44:58,057:INFO:              gradio: Not installed
2023-09-03 10:44:58,057:INFO:             fastapi: Not installed
2023-09-03 10:44:58,057:INFO:             uvicorn: Not installed
2023-09-03 10:44:58,057:INFO:              m2cgen: Not installed
2023-09-03 10:44:58,057:INFO:           evidently: Not installed
2023-09-03 10:44:58,057:INFO:               fugue: Not installed
2023-09-03 10:44:58,057:INFO:           streamlit: Not installed
2023-09-03 10:44:58,057:INFO:             prophet: Not installed
2023-09-03 10:44:58,059:INFO:None
2023-09-03 10:44:58,059:INFO:Set up data.
2023-09-03 10:44:58,060:INFO:Set up train/test split.
2023-09-03 10:44:58,083:INFO:Set up index.
2023-09-03 10:44:58,083:INFO:Set up folding strategy.
2023-09-03 10:44:58,083:INFO:Assigning column types.
2023-09-03 10:44:58,083:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-03 10:44:58,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-03 10:44:58,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 10:44:58,142:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:58,268:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:58,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-03 10:44:58,450:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 10:44:58,483:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:58,483:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:58,483:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-03 10:44:58,528:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 10:44:58,560:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:58,560:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:58,607:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 10:44:58,639:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:58,639:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:58,639:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-03 10:44:58,702:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:58,702:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:58,783:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:58,783:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:58,790:INFO:Preparing preprocessing pipeline...
2023-09-03 10:44:58,790:INFO:Set up simple imputation.
2023-09-03 10:44:58,790:INFO:Set up encoding of ordinal features.
2023-09-03 10:44:58,790:INFO:Set up encoding of categorical features.
2023-09-03 10:44:58,790:INFO:Set up feature normalization.
2023-09-03 10:44:58,900:INFO:Finished creating preprocessing pipeline.
2023-09-03 10:44:58,948:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_valu...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-09-03 10:44:58,948:INFO:Creating final display dataframe.
2023-09-03 10:44:59,351:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               d22e
2023-09-03 10:44:59,423:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:59,423:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:59,490:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 10:44:59,490:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 10:44:59,490:INFO:setup() successfully completed in 1.46s...............
2023-09-03 10:45:05,374:INFO:Initializing get_config()
2023-09-03 10:45:05,374:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, variable=train)
2023-09-03 10:45:05,374:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-09-03 10:45:05,374:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-03 10:45:05,388:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-09-03 10:45:05,388:INFO:get_config() successfully completed......................................
2023-09-03 10:45:11,004:INFO:Initializing get_config()
2023-09-03 10:45:11,004:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, variable=test)
2023-09-03 10:45:11,009:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-09-03 10:45:11,009:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-03 10:45:11,019:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  ALVO  
196                      1.0  LEVEL_7     0  
197                      0.0  LEVEL_3     0  
198                      0.0  LEVEL_3     1  
199                      NaN  LEVEL_3     0  
200                      0.0  LEVEL_3     0  
..                       ...      ...   ...  
298                      0.0  LEVEL_7     1  
299                      0.0  LEVEL_3     0  
300                      1.0  LEVEL_3     1  
301                      0.0  LEVEL_3     1  
302                      2.0  LEVEL_7     1  

[107 rows x 14 columns]
2023-09-03 10:45:11,019:INFO:get_config() successfully completed......................................
2023-09-03 10:45:15,809:INFO:Initializing get_config()
2023-09-03 10:45:15,809:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, variable=X_train)
2023-09-03 10:45:15,809:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-09-03 10:45:15,809:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-03 10:45:15,817:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  
0                        3.0  LEVEL_7  
1                        0.0  LEVEL_3  
2                        2.0  LEVEL_7  
3                        0.0  LEVEL_7  
4                        1.0  LEVEL_7  
..                       ...      ...  
191                      0.0  LEVEL_3  
192                      1.0  LEVEL_7  
193                      0.0  LEVEL_7  
194                      0.0  LEVEL_3  
195                      0.0  LEVEL_3  

[196 rows x 13 columns]
2023-09-03 10:45:15,817:INFO:get_config() successfully completed......................................
2023-09-03 10:45:20,595:INFO:Initializing get_config()
2023-09-03 10:45:20,595:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, variable=X_train_transformed)
2023-09-03 10:45:20,660:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-09-03 10:45:20,660:INFO:get_config() successfully completed......................................
2023-09-03 10:45:34,901:INFO:Initializing compare_models()
2023-09-03 10:45:34,901:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-09-03 10:45:34,901:INFO:Checking exceptions
2023-09-03 10:45:34,909:INFO:Preparing display monitor
2023-09-03 10:45:34,950:INFO:Initializing Logistic Regression
2023-09-03 10:45:34,950:INFO:Total runtime is 0.0 minutes
2023-09-03 10:45:34,950:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:34,950:INFO:Initializing create_model()
2023-09-03 10:45:34,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:34,950:INFO:Checking exceptions
2023-09-03 10:45:34,950:INFO:Importing libraries
2023-09-03 10:45:34,950:INFO:Copying training dataset
2023-09-03 10:45:34,958:INFO:Defining folds
2023-09-03 10:45:34,958:INFO:Declaring metric variables
2023-09-03 10:45:34,966:INFO:Importing untrained model
2023-09-03 10:45:34,967:INFO:Logistic Regression Imported successfully
2023-09-03 10:45:34,974:INFO:Starting cross validation
2023-09-03 10:45:34,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:42,807:INFO:Calculating mean and std
2023-09-03 10:45:42,807:INFO:Creating metrics dataframe
2023-09-03 10:45:42,807:INFO:Uploading results into container
2023-09-03 10:45:42,807:INFO:Uploading model into container now
2023-09-03 10:45:42,807:INFO:_master_model_container: 1
2023-09-03 10:45:42,807:INFO:_display_container: 2
2023-09-03 10:45:42,807:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-03 10:45:42,807:INFO:create_model() successfully completed......................................
2023-09-03 10:45:42,905:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:42,905:INFO:Creating metrics dataframe
2023-09-03 10:45:42,921:INFO:Initializing K Neighbors Classifier
2023-09-03 10:45:42,921:INFO:Total runtime is 0.13284374078114827 minutes
2023-09-03 10:45:42,921:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:42,921:INFO:Initializing create_model()
2023-09-03 10:45:42,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:42,921:INFO:Checking exceptions
2023-09-03 10:45:42,921:INFO:Importing libraries
2023-09-03 10:45:42,921:INFO:Copying training dataset
2023-09-03 10:45:42,929:INFO:Defining folds
2023-09-03 10:45:42,929:INFO:Declaring metric variables
2023-09-03 10:45:42,929:INFO:Importing untrained model
2023-09-03 10:45:42,937:INFO:K Neighbors Classifier Imported successfully
2023-09-03 10:45:42,937:INFO:Starting cross validation
2023-09-03 10:45:42,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:43,381:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,381:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,384:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,384:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,384:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,504:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,504:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,563:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,784:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,784:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 10:45:43,847:INFO:Calculating mean and std
2023-09-03 10:45:43,847:INFO:Creating metrics dataframe
2023-09-03 10:45:43,847:INFO:Uploading results into container
2023-09-03 10:45:43,847:INFO:Uploading model into container now
2023-09-03 10:45:43,847:INFO:_master_model_container: 2
2023-09-03 10:45:43,847:INFO:_display_container: 2
2023-09-03 10:45:43,847:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-03 10:45:43,860:INFO:create_model() successfully completed......................................
2023-09-03 10:45:43,939:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:43,939:INFO:Creating metrics dataframe
2023-09-03 10:45:43,955:INFO:Initializing Naive Bayes
2023-09-03 10:45:43,955:INFO:Total runtime is 0.15007734298706055 minutes
2023-09-03 10:45:43,955:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:43,955:INFO:Initializing create_model()
2023-09-03 10:45:43,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:43,955:INFO:Checking exceptions
2023-09-03 10:45:43,955:INFO:Importing libraries
2023-09-03 10:45:43,955:INFO:Copying training dataset
2023-09-03 10:45:43,963:INFO:Defining folds
2023-09-03 10:45:43,963:INFO:Declaring metric variables
2023-09-03 10:45:43,963:INFO:Importing untrained model
2023-09-03 10:45:43,970:INFO:Naive Bayes Imported successfully
2023-09-03 10:45:43,970:INFO:Starting cross validation
2023-09-03 10:45:43,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:45,502:INFO:Calculating mean and std
2023-09-03 10:45:45,502:INFO:Creating metrics dataframe
2023-09-03 10:45:45,502:INFO:Uploading results into container
2023-09-03 10:45:45,502:INFO:Uploading model into container now
2023-09-03 10:45:45,502:INFO:_master_model_container: 3
2023-09-03 10:45:45,502:INFO:_display_container: 2
2023-09-03 10:45:45,518:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-03 10:45:45,518:INFO:create_model() successfully completed......................................
2023-09-03 10:45:45,652:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:45,652:INFO:Creating metrics dataframe
2023-09-03 10:45:45,665:INFO:Initializing Decision Tree Classifier
2023-09-03 10:45:45,669:INFO:Total runtime is 0.17863969802856444 minutes
2023-09-03 10:45:45,673:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:45,673:INFO:Initializing create_model()
2023-09-03 10:45:45,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:45,677:INFO:Checking exceptions
2023-09-03 10:45:45,677:INFO:Importing libraries
2023-09-03 10:45:45,677:INFO:Copying training dataset
2023-09-03 10:45:45,685:INFO:Defining folds
2023-09-03 10:45:45,685:INFO:Declaring metric variables
2023-09-03 10:45:45,700:INFO:Importing untrained model
2023-09-03 10:45:45,702:INFO:Decision Tree Classifier Imported successfully
2023-09-03 10:45:45,716:INFO:Starting cross validation
2023-09-03 10:45:45,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:46,931:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:47,152:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:47,767:INFO:Calculating mean and std
2023-09-03 10:45:47,767:INFO:Creating metrics dataframe
2023-09-03 10:45:47,777:INFO:Uploading results into container
2023-09-03 10:45:47,777:INFO:Uploading model into container now
2023-09-03 10:45:47,777:INFO:_master_model_container: 4
2023-09-03 10:45:47,781:INFO:_display_container: 2
2023-09-03 10:45:47,781:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-09-03 10:45:47,781:INFO:create_model() successfully completed......................................
2023-09-03 10:45:47,900:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:47,900:INFO:Creating metrics dataframe
2023-09-03 10:45:47,916:INFO:Initializing SVM - Linear Kernel
2023-09-03 10:45:47,916:INFO:Total runtime is 0.2160988450050354 minutes
2023-09-03 10:45:47,932:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:47,932:INFO:Initializing create_model()
2023-09-03 10:45:47,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:47,932:INFO:Checking exceptions
2023-09-03 10:45:47,932:INFO:Importing libraries
2023-09-03 10:45:47,932:INFO:Copying training dataset
2023-09-03 10:45:47,941:INFO:Defining folds
2023-09-03 10:45:47,941:INFO:Declaring metric variables
2023-09-03 10:45:47,948:INFO:Importing untrained model
2023-09-03 10:45:47,956:INFO:SVM - Linear Kernel Imported successfully
2023-09-03 10:45:47,967:INFO:Starting cross validation
2023-09-03 10:45:47,973:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:49,444:INFO:Calculating mean and std
2023-09-03 10:45:49,444:INFO:Creating metrics dataframe
2023-09-03 10:45:49,452:INFO:Uploading results into container
2023-09-03 10:45:49,452:INFO:Uploading model into container now
2023-09-03 10:45:49,452:INFO:_master_model_container: 5
2023-09-03 10:45:49,452:INFO:_display_container: 2
2023-09-03 10:45:49,452:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-03 10:45:49,452:INFO:create_model() successfully completed......................................
2023-09-03 10:45:49,570:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:49,570:INFO:Creating metrics dataframe
2023-09-03 10:45:49,592:INFO:Initializing Ridge Classifier
2023-09-03 10:45:49,592:INFO:Total runtime is 0.2440340280532837 minutes
2023-09-03 10:45:49,600:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:49,600:INFO:Initializing create_model()
2023-09-03 10:45:49,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:49,600:INFO:Checking exceptions
2023-09-03 10:45:49,600:INFO:Importing libraries
2023-09-03 10:45:49,600:INFO:Copying training dataset
2023-09-03 10:45:49,608:INFO:Defining folds
2023-09-03 10:45:49,608:INFO:Declaring metric variables
2023-09-03 10:45:49,621:INFO:Importing untrained model
2023-09-03 10:45:49,621:INFO:Ridge Classifier Imported successfully
2023-09-03 10:45:49,641:INFO:Starting cross validation
2023-09-03 10:45:49,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:51,260:INFO:Calculating mean and std
2023-09-03 10:45:51,260:INFO:Creating metrics dataframe
2023-09-03 10:45:51,274:INFO:Uploading results into container
2023-09-03 10:45:51,274:INFO:Uploading model into container now
2023-09-03 10:45:51,274:INFO:_master_model_container: 6
2023-09-03 10:45:51,274:INFO:_display_container: 2
2023-09-03 10:45:51,274:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1935, solver='auto', tol=0.001)
2023-09-03 10:45:51,274:INFO:create_model() successfully completed......................................
2023-09-03 10:45:51,386:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:51,386:INFO:Creating metrics dataframe
2023-09-03 10:45:51,411:INFO:Initializing Random Forest Classifier
2023-09-03 10:45:51,411:INFO:Total runtime is 0.27434850533803307 minutes
2023-09-03 10:45:51,416:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:51,416:INFO:Initializing create_model()
2023-09-03 10:45:51,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:51,416:INFO:Checking exceptions
2023-09-03 10:45:51,416:INFO:Importing libraries
2023-09-03 10:45:51,416:INFO:Copying training dataset
2023-09-03 10:45:51,427:INFO:Defining folds
2023-09-03 10:45:51,427:INFO:Declaring metric variables
2023-09-03 10:45:51,435:INFO:Importing untrained model
2023-09-03 10:45:51,443:INFO:Random Forest Classifier Imported successfully
2023-09-03 10:45:51,462:INFO:Starting cross validation
2023-09-03 10:45:51,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:54,182:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:54,210:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:54,215:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:54,215:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:54,310:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:54,361:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:54,484:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:54,484:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:45:56,293:INFO:Calculating mean and std
2023-09-03 10:45:56,299:INFO:Creating metrics dataframe
2023-09-03 10:45:56,299:INFO:Uploading results into container
2023-09-03 10:45:56,299:INFO:Uploading model into container now
2023-09-03 10:45:56,299:INFO:_master_model_container: 7
2023-09-03 10:45:56,307:INFO:_display_container: 2
2023-09-03 10:45:56,307:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-03 10:45:56,307:INFO:create_model() successfully completed......................................
2023-09-03 10:45:56,402:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:56,402:INFO:Creating metrics dataframe
2023-09-03 10:45:56,418:INFO:Initializing Quadratic Discriminant Analysis
2023-09-03 10:45:56,418:INFO:Total runtime is 0.35779854853947957 minutes
2023-09-03 10:45:56,436:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:56,436:INFO:Initializing create_model()
2023-09-03 10:45:56,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:56,436:INFO:Checking exceptions
2023-09-03 10:45:56,436:INFO:Importing libraries
2023-09-03 10:45:56,436:INFO:Copying training dataset
2023-09-03 10:45:56,442:INFO:Defining folds
2023-09-03 10:45:56,442:INFO:Declaring metric variables
2023-09-03 10:45:56,456:INFO:Importing untrained model
2023-09-03 10:45:56,459:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-03 10:45:56,468:INFO:Starting cross validation
2023-09-03 10:45:56,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:45:56,793:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:56,848:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:56,861:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:56,881:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:56,889:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:56,898:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:56,929:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:56,980:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:57,726:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:57,757:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 10:45:58,135:INFO:Calculating mean and std
2023-09-03 10:45:58,135:INFO:Creating metrics dataframe
2023-09-03 10:45:58,151:INFO:Uploading results into container
2023-09-03 10:45:58,151:INFO:Uploading model into container now
2023-09-03 10:45:58,151:INFO:_master_model_container: 8
2023-09-03 10:45:58,151:INFO:_display_container: 2
2023-09-03 10:45:58,151:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-03 10:45:58,151:INFO:create_model() successfully completed......................................
2023-09-03 10:45:58,269:INFO:SubProcess create_model() end ==================================
2023-09-03 10:45:58,269:INFO:Creating metrics dataframe
2023-09-03 10:45:58,285:INFO:Initializing Ada Boost Classifier
2023-09-03 10:45:58,285:INFO:Total runtime is 0.38892070452372235 minutes
2023-09-03 10:45:58,293:INFO:SubProcess create_model() called ==================================
2023-09-03 10:45:58,293:INFO:Initializing create_model()
2023-09-03 10:45:58,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:45:58,293:INFO:Checking exceptions
2023-09-03 10:45:58,293:INFO:Importing libraries
2023-09-03 10:45:58,293:INFO:Copying training dataset
2023-09-03 10:45:58,301:INFO:Defining folds
2023-09-03 10:45:58,301:INFO:Declaring metric variables
2023-09-03 10:45:58,309:INFO:Importing untrained model
2023-09-03 10:45:58,319:INFO:Ada Boost Classifier Imported successfully
2023-09-03 10:45:58,331:INFO:Starting cross validation
2023-09-03 10:45:58,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:01,286:INFO:Calculating mean and std
2023-09-03 10:46:01,302:INFO:Creating metrics dataframe
2023-09-03 10:46:01,308:INFO:Uploading results into container
2023-09-03 10:46:01,308:INFO:Uploading model into container now
2023-09-03 10:46:01,308:INFO:_master_model_container: 9
2023-09-03 10:46:01,308:INFO:_display_container: 2
2023-09-03 10:46:01,308:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1935)
2023-09-03 10:46:01,308:INFO:create_model() successfully completed......................................
2023-09-03 10:46:01,415:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:01,415:INFO:Creating metrics dataframe
2023-09-03 10:46:01,431:INFO:Initializing Gradient Boosting Classifier
2023-09-03 10:46:01,431:INFO:Total runtime is 0.4413496335347494 minutes
2023-09-03 10:46:01,431:INFO:SubProcess create_model() called ==================================
2023-09-03 10:46:01,431:INFO:Initializing create_model()
2023-09-03 10:46:01,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:01,431:INFO:Checking exceptions
2023-09-03 10:46:01,431:INFO:Importing libraries
2023-09-03 10:46:01,431:INFO:Copying training dataset
2023-09-03 10:46:01,448:INFO:Defining folds
2023-09-03 10:46:01,448:INFO:Declaring metric variables
2023-09-03 10:46:01,455:INFO:Importing untrained model
2023-09-03 10:46:01,455:INFO:Gradient Boosting Classifier Imported successfully
2023-09-03 10:46:01,471:INFO:Starting cross validation
2023-09-03 10:46:01,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:04,459:INFO:Calculating mean and std
2023-09-03 10:46:04,459:INFO:Creating metrics dataframe
2023-09-03 10:46:04,459:INFO:Uploading results into container
2023-09-03 10:46:04,459:INFO:Uploading model into container now
2023-09-03 10:46:04,459:INFO:_master_model_container: 10
2023-09-03 10:46:04,459:INFO:_display_container: 2
2023-09-03 10:46:04,459:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-03 10:46:04,459:INFO:create_model() successfully completed......................................
2023-09-03 10:46:04,568:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:04,568:INFO:Creating metrics dataframe
2023-09-03 10:46:04,598:INFO:Initializing Linear Discriminant Analysis
2023-09-03 10:46:04,598:INFO:Total runtime is 0.49413820107777917 minutes
2023-09-03 10:46:04,603:INFO:SubProcess create_model() called ==================================
2023-09-03 10:46:04,603:INFO:Initializing create_model()
2023-09-03 10:46:04,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:04,603:INFO:Checking exceptions
2023-09-03 10:46:04,603:INFO:Importing libraries
2023-09-03 10:46:04,603:INFO:Copying training dataset
2023-09-03 10:46:04,603:INFO:Defining folds
2023-09-03 10:46:04,603:INFO:Declaring metric variables
2023-09-03 10:46:04,617:INFO:Importing untrained model
2023-09-03 10:46:04,622:INFO:Linear Discriminant Analysis Imported successfully
2023-09-03 10:46:04,630:INFO:Starting cross validation
2023-09-03 10:46:04,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:05,993:INFO:Calculating mean and std
2023-09-03 10:46:05,993:INFO:Creating metrics dataframe
2023-09-03 10:46:05,993:INFO:Uploading results into container
2023-09-03 10:46:05,993:INFO:Uploading model into container now
2023-09-03 10:46:05,993:INFO:_master_model_container: 11
2023-09-03 10:46:05,993:INFO:_display_container: 2
2023-09-03 10:46:06,008:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-03 10:46:06,008:INFO:create_model() successfully completed......................................
2023-09-03 10:46:06,103:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:06,103:INFO:Creating metrics dataframe
2023-09-03 10:46:06,119:INFO:Initializing Extra Trees Classifier
2023-09-03 10:46:06,119:INFO:Total runtime is 0.5194796363512675 minutes
2023-09-03 10:46:06,135:INFO:SubProcess create_model() called ==================================
2023-09-03 10:46:06,135:INFO:Initializing create_model()
2023-09-03 10:46:06,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:06,135:INFO:Checking exceptions
2023-09-03 10:46:06,135:INFO:Importing libraries
2023-09-03 10:46:06,135:INFO:Copying training dataset
2023-09-03 10:46:06,143:INFO:Defining folds
2023-09-03 10:46:06,143:INFO:Declaring metric variables
2023-09-03 10:46:06,151:INFO:Importing untrained model
2023-09-03 10:46:06,160:INFO:Extra Trees Classifier Imported successfully
2023-09-03 10:46:06,167:INFO:Starting cross validation
2023-09-03 10:46:06,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:08,197:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:46:08,351:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:46:08,440:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:46:09,756:INFO:Calculating mean and std
2023-09-03 10:46:09,771:INFO:Creating metrics dataframe
2023-09-03 10:46:09,771:INFO:Uploading results into container
2023-09-03 10:46:09,778:INFO:Uploading model into container now
2023-09-03 10:46:09,778:INFO:_master_model_container: 12
2023-09-03 10:46:09,778:INFO:_display_container: 2
2023-09-03 10:46:09,780:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-09-03 10:46:09,780:INFO:create_model() successfully completed......................................
2023-09-03 10:46:09,897:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:09,897:INFO:Creating metrics dataframe
2023-09-03 10:46:09,908:INFO:Initializing Extreme Gradient Boosting
2023-09-03 10:46:09,908:INFO:Total runtime is 0.5826292594273885 minutes
2023-09-03 10:46:09,925:INFO:SubProcess create_model() called ==================================
2023-09-03 10:46:09,925:INFO:Initializing create_model()
2023-09-03 10:46:09,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:09,925:INFO:Checking exceptions
2023-09-03 10:46:09,925:INFO:Importing libraries
2023-09-03 10:46:09,925:INFO:Copying training dataset
2023-09-03 10:46:09,940:INFO:Defining folds
2023-09-03 10:46:09,940:INFO:Declaring metric variables
2023-09-03 10:46:09,940:INFO:Importing untrained model
2023-09-03 10:46:09,948:INFO:Extreme Gradient Boosting Imported successfully
2023-09-03 10:46:09,965:INFO:Starting cross validation
2023-09-03 10:46:09,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:12,174:INFO:Calculating mean and std
2023-09-03 10:46:12,174:INFO:Creating metrics dataframe
2023-09-03 10:46:12,181:INFO:Uploading results into container
2023-09-03 10:46:12,181:INFO:Uploading model into container now
2023-09-03 10:46:12,181:INFO:_master_model_container: 13
2023-09-03 10:46:12,181:INFO:_display_container: 2
2023-09-03 10:46:12,181:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-03 10:46:12,181:INFO:create_model() successfully completed......................................
2023-09-03 10:46:12,297:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:12,297:INFO:Creating metrics dataframe
2023-09-03 10:46:12,314:INFO:Initializing Light Gradient Boosting Machine
2023-09-03 10:46:12,314:INFO:Total runtime is 0.6227293213208517 minutes
2023-09-03 10:46:12,314:INFO:SubProcess create_model() called ==================================
2023-09-03 10:46:12,314:INFO:Initializing create_model()
2023-09-03 10:46:12,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:12,314:INFO:Checking exceptions
2023-09-03 10:46:12,314:INFO:Importing libraries
2023-09-03 10:46:12,314:INFO:Copying training dataset
2023-09-03 10:46:12,329:INFO:Defining folds
2023-09-03 10:46:12,329:INFO:Declaring metric variables
2023-09-03 10:46:12,332:INFO:Importing untrained model
2023-09-03 10:46:12,340:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-03 10:46:12,348:INFO:Starting cross validation
2023-09-03 10:46:12,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:16,348:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-03 10:46:17,012:INFO:Calculating mean and std
2023-09-03 10:46:17,020:INFO:Creating metrics dataframe
2023-09-03 10:46:17,020:INFO:Uploading results into container
2023-09-03 10:46:17,020:INFO:Uploading model into container now
2023-09-03 10:46:17,020:INFO:_master_model_container: 14
2023-09-03 10:46:17,020:INFO:_display_container: 2
2023-09-03 10:46:17,020:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-09-03 10:46:17,031:INFO:create_model() successfully completed......................................
2023-09-03 10:46:17,151:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:17,151:INFO:Creating metrics dataframe
2023-09-03 10:46:17,166:INFO:Initializing CatBoost Classifier
2023-09-03 10:46:17,166:INFO:Total runtime is 0.7036036411921184 minutes
2023-09-03 10:46:17,179:INFO:SubProcess create_model() called ==================================
2023-09-03 10:46:17,179:INFO:Initializing create_model()
2023-09-03 10:46:17,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:17,179:INFO:Checking exceptions
2023-09-03 10:46:17,179:INFO:Importing libraries
2023-09-03 10:46:17,179:INFO:Copying training dataset
2023-09-03 10:46:17,187:INFO:Defining folds
2023-09-03 10:46:17,187:INFO:Declaring metric variables
2023-09-03 10:46:17,195:INFO:Importing untrained model
2023-09-03 10:46:17,195:INFO:CatBoost Classifier Imported successfully
2023-09-03 10:46:17,211:INFO:Starting cross validation
2023-09-03 10:46:17,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:30,299:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:372: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\zaian\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 680, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 252, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\zaian\anaconda3\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 369, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 280, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\zaian\anaconda3\lib\site-packages\catboost\core.py", line 5131, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\zaian\anaconda3\lib\site-packages\catboost\core.py", line 2357, in _fit
    self._train(
  File "C:\Users\zaian\anaconda3\lib\site-packages\catboost\core.py", line 1761, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4624, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4673, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-09-03 10:46:30,299:INFO:Calculating mean and std
2023-09-03 10:46:30,304:INFO:Creating metrics dataframe
2023-09-03 10:46:30,304:INFO:Uploading results into container
2023-09-03 10:46:30,312:INFO:Uploading model into container now
2023-09-03 10:46:30,312:INFO:_master_model_container: 15
2023-09-03 10:46:30,312:INFO:_display_container: 2
2023-09-03 10:46:30,312:INFO:<catboost.core.CatBoostClassifier object at 0x000001BBDB245430>
2023-09-03 10:46:30,312:INFO:create_model() successfully completed......................................
2023-09-03 10:46:30,448:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x000001BBDB245430> raised an exception or returned all 0.0, trying without fit_kwargs:
2023-09-03 10:46:30,456:WARNING:Traceback (most recent call last):
  File "C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 796, in compare_models
    assert (
AssertionError

2023-09-03 10:46:30,456:INFO:Initializing create_model()
2023-09-03 10:46:30,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:30,456:INFO:Checking exceptions
2023-09-03 10:46:30,456:INFO:Importing libraries
2023-09-03 10:46:30,456:INFO:Copying training dataset
2023-09-03 10:46:30,472:INFO:Defining folds
2023-09-03 10:46:30,472:INFO:Declaring metric variables
2023-09-03 10:46:30,478:INFO:Importing untrained model
2023-09-03 10:46:30,478:INFO:CatBoost Classifier Imported successfully
2023-09-03 10:46:30,495:INFO:Starting cross validation
2023-09-03 10:46:30,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:35,581:INFO:Calculating mean and std
2023-09-03 10:46:35,581:INFO:Creating metrics dataframe
2023-09-03 10:46:35,591:INFO:Uploading results into container
2023-09-03 10:46:35,593:INFO:Uploading model into container now
2023-09-03 10:46:35,593:INFO:_master_model_container: 16
2023-09-03 10:46:35,593:INFO:_display_container: 2
2023-09-03 10:46:35,593:INFO:<catboost.core.CatBoostClassifier object at 0x000001BBDB0A33D0>
2023-09-03 10:46:35,593:INFO:create_model() successfully completed......................................
2023-09-03 10:46:35,699:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:35,699:INFO:Creating metrics dataframe
2023-09-03 10:46:35,723:INFO:Initializing Dummy Classifier
2023-09-03 10:46:35,723:INFO:Total runtime is 1.0128827770551045 minutes
2023-09-03 10:46:35,731:INFO:SubProcess create_model() called ==================================
2023-09-03 10:46:35,731:INFO:Initializing create_model()
2023-09-03 10:46:35,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BBDAF0DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:35,731:INFO:Checking exceptions
2023-09-03 10:46:35,731:INFO:Importing libraries
2023-09-03 10:46:35,731:INFO:Copying training dataset
2023-09-03 10:46:35,739:INFO:Defining folds
2023-09-03 10:46:35,739:INFO:Declaring metric variables
2023-09-03 10:46:35,747:INFO:Importing untrained model
2023-09-03 10:46:35,755:INFO:Dummy Classifier Imported successfully
2023-09-03 10:46:35,763:INFO:Starting cross validation
2023-09-03 10:46:35,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 10:46:36,621:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:36,630:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:36,645:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:36,661:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:36,692:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:36,708:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:36,708:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:36,740:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:37,134:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:37,261:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 10:46:37,261:INFO:Calculating mean and std
2023-09-03 10:46:37,275:INFO:Creating metrics dataframe
2023-09-03 10:46:37,280:INFO:Uploading results into container
2023-09-03 10:46:37,283:INFO:Uploading model into container now
2023-09-03 10:46:37,283:INFO:_master_model_container: 17
2023-09-03 10:46:37,284:INFO:_display_container: 2
2023-09-03 10:46:37,284:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-09-03 10:46:37,284:INFO:create_model() successfully completed......................................
2023-09-03 10:46:37,387:INFO:SubProcess create_model() end ==================================
2023-09-03 10:46:37,387:INFO:Creating metrics dataframe
2023-09-03 10:46:37,427:INFO:Initializing create_model()
2023-09-03 10:46:37,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BBDA906670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-03 10:46:37,435:INFO:Checking exceptions
2023-09-03 10:46:37,435:INFO:Importing libraries
2023-09-03 10:46:37,435:INFO:Copying training dataset
2023-09-03 10:46:37,444:INFO:Defining folds
2023-09-03 10:46:37,444:INFO:Declaring metric variables
2023-09-03 10:46:37,444:INFO:Importing untrained model
2023-09-03 10:46:37,444:INFO:Declaring custom model
2023-09-03 10:46:37,447:INFO:Random Forest Classifier Imported successfully
2023-09-03 10:46:37,447:INFO:Cross validation set to False
2023-09-03 10:46:37,447:INFO:Fitting Model
2023-09-03 10:46:37,975:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-03 10:46:37,975:INFO:create_model() successfully completed......................................
2023-09-03 10:46:38,101:INFO:_master_model_container: 17
2023-09-03 10:46:38,101:INFO:_display_container: 2
2023-09-03 10:46:38,116:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-03 10:46:38,116:INFO:compare_models() successfully completed......................................
2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_8b045c478e924e0e8bec11488ba64f0f
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_343d7291fdc845eb94d8f513b8e7003e_5de647d97ce34745b183d8889973bac7
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_203cf8e2c2ef4140a5fa399ac491d38b
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_3af412876c6b429793d63385bd08e1db_3a2b64089d7c464691697e6ba18b91db
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_691ebd599b3246b69bc849b7a6bb4fae
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_482d638331014abba894c9187f01e496_fc950d80f37f4796817af6e4e6b1b539
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_db74af6eac724c4587f2eba6ab7a06a7
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_a1323df13b6a4c7e89d883d750c6188e_e3ed3520be1442c4a5113d6f5fac9212
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_76013d23460b48569bdd056fa1d2f6c2
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_6c59ff4f7e2c48abb3c0559af9217772_411462b81ae5481f9d142d517d14132a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_b6bef6e34f10437881c8ac09a24bad8e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_ccfc80b8e42a460aabcae7fd6fb2bf47_4eea7feead0740868e96a780edcbc88e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_5371e0086d904c2eab656d227e9e997a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_33c0638577354e9f89a8bcfe99fa7120_a21753cbf976465ca44120fdc6932740
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_8a068a47d545479e9188dbcc27895cb1
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_57ba48087b614b11bc8e2447036cf229_de34c5351e614f5790c3277e6d02461c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_e947cf932f9c483ea2c3b68aca2406b5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_b93ff685c8a94d84898be28f421553d8_49e44aa9d2cc48b6aeed2e85da6861c6
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_94076b9a962242e88f5a48acdd7a7c33
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2c7577e6ead54ee2b22f0ca838d520e8_360560789df34c929e45687ac28984f7
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_1dd7a68b958b4a35b3b335c2768d40dd
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_8a0778220e6748c3b6dcb9b7acb56cf6_d06e584d0a3d4c0ca1b3c017d186fc0c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_30cad07ca1694eb798ccbe2abda7104a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_0ff079dfa936480b9ce6c23efe09f5b7_df3433328b284b45a954fdbc2213b8f1
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_9e3dc4fef5aa446ebc1f8b02a6c5c25a
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_67af4cbab8a848dab199c20fc1317069_e11f592c748f4b40a3308df3f7c6dccc
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_0cbc20e5a90c422a85a3835f2159a313
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_b77d7d2a228d4a75b2446b26047a1c4d_d77c76a854ff4d2f8d202eb408f2a8c2
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_bf1b35f02eed45eebc7c841b36cfaaa5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_26a0ee36e16549d9af37d020879cc7b1_38a0fd9bc83a41848e60494614a87ed4
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_173c95333d8d48d48c4da336b8759407
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_47bd8772efbb4019989ba89aface75ed_94a9ba5dd73e4a8a8b315162fea1ff3c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_d46ca640213e47098a92bcb96d9c3cce
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 11:01:45,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\Users\zaian\AppData\Local\Temp\joblib_memmapping_folder_18768_2f5d153e43104cd99cc11917cc2d04d0_955af97743e249b999cd8d9e78d5e3fd
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-03 12:35:46,496:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 12:35:46,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 12:35:46,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 12:35:46,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 12:35:48,314:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-09-03 14:29:52,758:INFO:PyCaret ClassificationExperiment
2023-09-03 14:29:52,758:INFO:Logging name: EXP_01_WANDA_2023
2023-09-03 14:29:52,758:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-03 14:29:52,758:INFO:version 3.0.0.rc9
2023-09-03 14:29:52,758:INFO:Initializing setup()
2023-09-03 14:29:52,758:INFO:self.USI: 6ff5
2023-09-03 14:29:52,758:INFO:self._variable_keys: {'_ml_usecase', 'y_test', 'X', 'gpu_n_jobs_param', 'gpu_param', 'logging_param', '_available_plots', 'html_param', 'is_multiclass', 'n_jobs_param', 'X_test', 'exp_name_log', 'fold_shuffle_param', 'y_train', 'USI', 'data', 'X_train', 'pipeline', 'fold_groups_param', 'y', 'idx', 'seed', 'target_param', 'exp_id', 'log_plots_param', 'fix_imbalance', 'memory', 'fold_generator'}
2023-09-03 14:29:52,758:INFO:Checking environment
2023-09-03 14:29:52,758:INFO:python_version: 3.9.13
2023-09-03 14:29:52,758:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-09-03 14:29:52,758:INFO:machine: AMD64
2023-09-03 14:29:52,758:INFO:platform: Windows-10-10.0.22621-SP0
2023-09-03 14:29:52,758:INFO:Memory: svmem(total=8266518528, available=818913280, percent=90.1, used=7447605248, free=818913280)
2023-09-03 14:29:52,758:INFO:Physical Core: 4
2023-09-03 14:29:52,758:INFO:Logical Core: 8
2023-09-03 14:29:52,758:INFO:Checking libraries
2023-09-03 14:29:52,758:INFO:System:
2023-09-03 14:29:52,773:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-09-03 14:29:52,773:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-09-03 14:29:52,773:INFO:   machine: Windows-10-10.0.22621-SP0
2023-09-03 14:29:52,773:INFO:PyCaret required dependencies:
2023-09-03 14:29:52,773:INFO:                 pip: 22.2.2
2023-09-03 14:29:52,773:INFO:          setuptools: 63.4.1
2023-09-03 14:29:52,773:INFO:             pycaret: 3.0.0rc9
2023-09-03 14:29:52,773:INFO:             IPython: 7.31.1
2023-09-03 14:29:52,773:INFO:          ipywidgets: 7.6.5
2023-09-03 14:29:52,773:INFO:                tqdm: 4.64.1
2023-09-03 14:29:52,773:INFO:               numpy: 1.21.5
2023-09-03 14:29:52,773:INFO:              pandas: 1.4.4
2023-09-03 14:29:52,773:INFO:              jinja2: 3.0.3
2023-09-03 14:29:52,773:INFO:               scipy: 1.9.1
2023-09-03 14:29:52,773:INFO:              joblib: 1.2.0
2023-09-03 14:29:52,773:INFO:             sklearn: 1.0.2
2023-09-03 14:29:52,773:INFO:                pyod: 1.0.7
2023-09-03 14:29:52,773:INFO:            imblearn: 0.10.1
2023-09-03 14:29:52,773:INFO:   category_encoders: 2.6.0
2023-09-03 14:29:52,773:INFO:            lightgbm: 3.3.5
2023-09-03 14:29:52,773:INFO:               numba: 0.55.1
2023-09-03 14:29:52,773:INFO:            requests: 2.28.1
2023-09-03 14:29:52,773:INFO:          matplotlib: 3.5.2
2023-09-03 14:29:52,773:INFO:          scikitplot: 0.3.7
2023-09-03 14:29:52,773:INFO:         yellowbrick: 1.5
2023-09-03 14:29:52,773:INFO:              plotly: 5.9.0
2023-09-03 14:29:52,773:INFO:             kaleido: 0.2.1
2023-09-03 14:29:52,773:INFO:         statsmodels: 0.13.2
2023-09-03 14:29:52,773:INFO:              sktime: 0.16.1
2023-09-03 14:29:52,773:INFO:               tbats: 1.1.2
2023-09-03 14:29:52,773:INFO:            pmdarima: 2.0.2
2023-09-03 14:29:52,773:INFO:              psutil: 5.9.0
2023-09-03 14:29:52,773:INFO:PyCaret optional dependencies:
2023-09-03 14:29:52,788:INFO:                shap: Not installed
2023-09-03 14:29:52,788:INFO:           interpret: Not installed
2023-09-03 14:29:52,788:INFO:                umap: Not installed
2023-09-03 14:29:52,788:INFO:    pandas_profiling: 4.3.1
2023-09-03 14:29:52,788:INFO:  explainerdashboard: Not installed
2023-09-03 14:29:52,788:INFO:             autoviz: 0.1.720
2023-09-03 14:29:52,788:INFO:           fairlearn: Not installed
2023-09-03 14:29:52,788:INFO:             xgboost: 1.7.5
2023-09-03 14:29:52,788:INFO:            catboost: 1.2
2023-09-03 14:29:52,788:INFO:              kmodes: Not installed
2023-09-03 14:29:52,788:INFO:             mlxtend: Not installed
2023-09-03 14:29:52,788:INFO:       statsforecast: Not installed
2023-09-03 14:29:52,788:INFO:        tune_sklearn: Not installed
2023-09-03 14:29:52,788:INFO:                 ray: Not installed
2023-09-03 14:29:52,788:INFO:            hyperopt: Not installed
2023-09-03 14:29:52,788:INFO:              optuna: Not installed
2023-09-03 14:29:52,788:INFO:               skopt: Not installed
2023-09-03 14:29:52,788:INFO:              mlflow: Not installed
2023-09-03 14:29:52,788:INFO:              gradio: Not installed
2023-09-03 14:29:52,788:INFO:             fastapi: Not installed
2023-09-03 14:29:52,788:INFO:             uvicorn: Not installed
2023-09-03 14:29:52,788:INFO:              m2cgen: Not installed
2023-09-03 14:29:52,788:INFO:           evidently: Not installed
2023-09-03 14:29:52,788:INFO:               fugue: Not installed
2023-09-03 14:29:52,788:INFO:           streamlit: Not installed
2023-09-03 14:29:52,788:INFO:             prophet: Not installed
2023-09-03 14:29:52,788:INFO:None
2023-09-03 14:29:52,804:INFO:Set up data.
2023-09-03 14:29:52,882:INFO:Set up train/test split.
2023-09-03 14:29:52,914:INFO:Set up index.
2023-09-03 14:29:52,929:INFO:Set up folding strategy.
2023-09-03 14:29:52,929:INFO:Assigning column types.
2023-09-03 14:29:52,929:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-03 14:29:53,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-03 14:29:53,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:29:53,102:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:53,344:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:53,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-03 14:29:53,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:29:53,545:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:53,549:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:53,549:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-03 14:29:53,609:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:29:53,649:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:53,653:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:53,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:29:53,748:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:53,750:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:53,751:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-03 14:29:53,828:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:53,833:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:53,915:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:53,918:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:53,930:INFO:Preparing preprocessing pipeline...
2023-09-03 14:29:53,933:INFO:Set up simple imputation.
2023-09-03 14:29:53,938:INFO:Set up encoding of ordinal features.
2023-09-03 14:29:53,941:INFO:Set up encoding of categorical features.
2023-09-03 14:29:53,942:INFO:Set up feature normalization.
2023-09-03 14:29:54,101:INFO:Finished creating preprocessing pipeline.
2023-09-03 14:29:54,137:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_valu...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-09-03 14:29:54,137:INFO:Creating final display dataframe.
2023-09-03 14:29:54,725:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               6ff5
2023-09-03 14:29:54,860:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:54,867:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:54,945:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:29:54,948:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:29:54,950:INFO:setup() successfully completed in 2.27s...............
2023-09-03 14:51:08,962:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 14:51:08,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 14:51:08,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 14:51:08,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-03 14:51:09,775:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-09-03 14:52:05,406:INFO:PyCaret ClassificationExperiment
2023-09-03 14:52:05,407:INFO:Logging name: EXP_01_WANDA_2023
2023-09-03 14:52:05,408:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-03 14:52:05,408:INFO:version 3.0.0.rc9
2023-09-03 14:52:05,408:INFO:Initializing setup()
2023-09-03 14:52:05,408:INFO:self.USI: 9ac3
2023-09-03 14:52:05,409:INFO:self._variable_keys: {'fix_imbalance', 'log_plots_param', '_available_plots', 'html_param', 'gpu_n_jobs_param', 'USI', 'gpu_param', 'y', 'fold_generator', 'data', 'logging_param', 'y_test', 'X', 'seed', 'exp_name_log', 'X_test', 'memory', 'idx', 'is_multiclass', 'n_jobs_param', 'target_param', 'X_train', 'pipeline', 'y_train', 'fold_groups_param', 'exp_id', 'fold_shuffle_param', '_ml_usecase'}
2023-09-03 14:52:05,409:INFO:Checking environment
2023-09-03 14:52:05,409:INFO:python_version: 3.9.13
2023-09-03 14:52:05,409:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-09-03 14:52:05,409:INFO:machine: AMD64
2023-09-03 14:52:05,409:INFO:platform: Windows-10-10.0.22621-SP0
2023-09-03 14:52:05,410:INFO:Memory: svmem(total=8266518528, available=817999872, percent=90.1, used=7448518656, free=817999872)
2023-09-03 14:52:05,410:INFO:Physical Core: 4
2023-09-03 14:52:05,410:INFO:Logical Core: 8
2023-09-03 14:52:05,410:INFO:Checking libraries
2023-09-03 14:52:05,411:INFO:System:
2023-09-03 14:52:05,411:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-09-03 14:52:05,411:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-09-03 14:52:05,411:INFO:   machine: Windows-10-10.0.22621-SP0
2023-09-03 14:52:05,411:INFO:PyCaret required dependencies:
2023-09-03 14:52:05,411:INFO:                 pip: 22.2.2
2023-09-03 14:52:05,412:INFO:          setuptools: 63.4.1
2023-09-03 14:52:05,412:INFO:             pycaret: 3.0.0rc9
2023-09-03 14:52:05,412:INFO:             IPython: 7.31.1
2023-09-03 14:52:05,412:INFO:          ipywidgets: 7.6.5
2023-09-03 14:52:05,412:INFO:                tqdm: 4.64.1
2023-09-03 14:52:05,412:INFO:               numpy: 1.21.5
2023-09-03 14:52:05,412:INFO:              pandas: 1.4.4
2023-09-03 14:52:05,413:INFO:              jinja2: 3.0.3
2023-09-03 14:52:05,413:INFO:               scipy: 1.9.1
2023-09-03 14:52:05,413:INFO:              joblib: 1.2.0
2023-09-03 14:52:05,413:INFO:             sklearn: 1.0.2
2023-09-03 14:52:05,413:INFO:                pyod: 1.0.7
2023-09-03 14:52:05,414:INFO:            imblearn: 0.10.1
2023-09-03 14:52:05,414:INFO:   category_encoders: 2.6.0
2023-09-03 14:52:05,414:INFO:            lightgbm: 3.3.5
2023-09-03 14:52:05,414:INFO:               numba: 0.55.1
2023-09-03 14:52:05,414:INFO:            requests: 2.28.1
2023-09-03 14:52:05,415:INFO:          matplotlib: 3.5.2
2023-09-03 14:52:05,415:INFO:          scikitplot: 0.3.7
2023-09-03 14:52:05,415:INFO:         yellowbrick: 1.5
2023-09-03 14:52:05,415:INFO:              plotly: 5.9.0
2023-09-03 14:52:05,415:INFO:             kaleido: 0.2.1
2023-09-03 14:52:05,416:INFO:         statsmodels: 0.13.2
2023-09-03 14:52:05,416:INFO:              sktime: 0.16.1
2023-09-03 14:52:05,416:INFO:               tbats: 1.1.2
2023-09-03 14:52:05,416:INFO:            pmdarima: 2.0.2
2023-09-03 14:52:05,416:INFO:              psutil: 5.9.0
2023-09-03 14:52:05,416:INFO:PyCaret optional dependencies:
2023-09-03 14:52:05,426:INFO:                shap: Not installed
2023-09-03 14:52:05,427:INFO:           interpret: Not installed
2023-09-03 14:52:05,427:INFO:                umap: Not installed
2023-09-03 14:52:05,427:INFO:    pandas_profiling: 4.3.1
2023-09-03 14:52:05,427:INFO:  explainerdashboard: Not installed
2023-09-03 14:52:05,427:INFO:             autoviz: 0.1.720
2023-09-03 14:52:05,427:INFO:           fairlearn: Not installed
2023-09-03 14:52:05,427:INFO:             xgboost: 1.7.5
2023-09-03 14:52:05,427:INFO:            catboost: 1.2
2023-09-03 14:52:05,427:INFO:              kmodes: Not installed
2023-09-03 14:52:05,427:INFO:             mlxtend: Not installed
2023-09-03 14:52:05,427:INFO:       statsforecast: Not installed
2023-09-03 14:52:05,428:INFO:        tune_sklearn: Not installed
2023-09-03 14:52:05,428:INFO:                 ray: Not installed
2023-09-03 14:52:05,428:INFO:            hyperopt: Not installed
2023-09-03 14:52:05,428:INFO:              optuna: Not installed
2023-09-03 14:52:05,428:INFO:               skopt: Not installed
2023-09-03 14:52:05,428:INFO:              mlflow: Not installed
2023-09-03 14:52:05,428:INFO:              gradio: Not installed
2023-09-03 14:52:05,428:INFO:             fastapi: Not installed
2023-09-03 14:52:05,428:INFO:             uvicorn: Not installed
2023-09-03 14:52:05,428:INFO:              m2cgen: Not installed
2023-09-03 14:52:05,428:INFO:           evidently: Not installed
2023-09-03 14:52:05,428:INFO:               fugue: Not installed
2023-09-03 14:52:05,428:INFO:           streamlit: Not installed
2023-09-03 14:52:05,428:INFO:             prophet: Not installed
2023-09-03 14:52:05,428:INFO:None
2023-09-03 14:52:05,428:INFO:Set up data.
2023-09-03 14:52:05,438:INFO:Set up train/test split.
2023-09-03 14:52:05,445:INFO:Set up index.
2023-09-03 14:52:05,445:INFO:Set up folding strategy.
2023-09-03 14:52:05,445:INFO:Assigning column types.
2023-09-03 14:52:05,448:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-03 14:52:05,504:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-03 14:52:05,508:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:52:05,564:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:05,655:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:05,798:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-03 14:52:05,799:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:52:05,830:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:05,832:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:05,833:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-03 14:52:05,877:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:52:05,905:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:05,908:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:05,955:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-03 14:52:05,987:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:05,992:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:05,993:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-03 14:52:06,095:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:06,098:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:06,208:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:06,213:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:06,219:INFO:Preparing preprocessing pipeline...
2023-09-03 14:52:06,222:INFO:Set up simple imputation.
2023-09-03 14:52:06,223:INFO:Set up feature normalization.
2023-09-03 14:52:06,257:INFO:Finished creating preprocessing pipeline.
2023-09-03 14:52:06,263:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels',
                                             'Chest_pain_LEVEL_1',
                                             'Chest_pain_LEVEL_2',
                                             'Chest_pain_LEVEL_3',
                                             'Chest_pain_LEVEL_4', '...
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-09-03 14:52:06,263:INFO:Creating final display dataframe.
2023-09-03 14:52:06,392:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 26)
4        Transformed data shape          (303, 26)
5   Transformed train set shape          (196, 26)
6    Transformed test set shape          (107, 26)
7              Numeric features                 25
8      Rows with missing values               1.3%
9                    Preprocess               True
10              Imputation type             simple
11           Numeric imputation               mean
12       Categorical imputation               mode
13                    Normalize               True
14             Normalize method             zscore
15               Fold Generator    StratifiedKFold
16                  Fold Number                 10
17                     CPU Jobs                 -1
18                      Use GPU              False
19               Log Experiment              False
20              Experiment Name  EXP_01_WANDA_2023
21                          USI               9ac3
2023-09-03 14:52:06,490:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:06,493:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:06,585:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-03 14:52:06,588:INFO:Soft dependency imported: catboost: 1.2
2023-09-03 14:52:06,589:INFO:setup() successfully completed in 1.19s...............
2023-09-03 14:52:42,072:INFO:Initializing get_config()
2023-09-03 14:52:42,072:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, variable=train)
2023-09-03 14:52:42,073:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-09-03 14:52:42,075:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-03 14:52:42,084:INFO:Variable:  returned as      Age  Resting_blood_pressure  Serum_cholestrol  Max_heart_rate_achieved  \
0     49                     120               188                      139   
1     39                     138               220                      152   
2     52                     125               212                      168   
3     41                     110               172                      158   
4     57                     152               274                       88   
..   ...                     ...               ...                      ...   
191   46                     138               243                      152   
192   57                     110               335                      143   
193   55                     140               217                      111   
194   63                     135               252                      172   
195   49                     130               269                      163   

     ST_depression  Number_of_major_vessels  Chest_pain_LEVEL_1  \
0              2.0                      3.0                   0   
1              0.0                      0.0                   0   
2              1.0                      2.0                   0   
3              0.0                      0.0                   0   
4              1.2                      1.0                   0   
..             ...                      ...                 ...   
191            0.0                      0.0                   0   
192            3.0                      1.0                   0   
193            5.6                      0.0                   0   
194            0.0                      0.0                   0   
195            0.0                      0.0                   0   

     Chest_pain_LEVEL_2  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  ...  \
0                     0                   1                   0  ...   
1                     0                   1                   0  ...   
2                     0                   0                   1  ...   
3                     0                   0                   1  ...   
4                     0                   0                   1  ...   
..                  ...                 ...                 ...  ...   
191                   0                   0                   1  ...   
192                   0                   0                   1  ...   
193                   0                   0                   1  ...   
194                   0                   1                   0  ...   
195                   0                   0                   1  ...   

     Resting_ECG_LEVEL_2  Exercise_induced_angina_NO_PAIN  \
0                      0                                1   
1                      0                                1   
2                      0                                1   
3                      1                                1   
4                      0                                0   
..                   ...                              ...   
191                    1                                0   
192                    0                                0   
193                    0                                0   
194                    1                                1   
195                    0                                1   

     Exercise_induced_angina_PAIN  Peak_exercise_ST_segment_LEVEL_1  \
0                               0                                 0   
1                               0                                 0   
2                               0                                 1   
3                               0                                 1   
4                               1                                 0   
..                            ...                               ...   
191                             1                                 0   
192                             1                                 0   
193                             1                                 0   
194                             0                                 1   
195                             0                                 1   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_3  \
0                                   1                                 0   
1                                   1                                 0   
2                                   0                                 0   
3                                   0                                 0   
4                                   1                                 0   
..                                ...                               ...   
191                                 1                                 0   
192                                 1                                 0   
193                                 0                                 1   
194                                 0                                 0   
195                                 0                                 0   

     Thal_LEVEL_3  Thal_LEVEL_6  Thal_LEVEL_7  ALVO  
0               0             0             1     1  
1               1             0             0     0  
2               0             0             1     1  
3               0             0             1     1  
4               0             0             1     1  
..            ...           ...           ...   ...  
191             1             0             0     0  
192             0             0             1     1  
193             0             0             1     1  
194             1             0             0     0  
195             1             0             0     0  

[196 rows x 26 columns]
2023-09-03 14:52:42,085:INFO:get_config() successfully completed......................................
2023-09-03 14:53:15,994:INFO:Initializing get_config()
2023-09-03 14:53:15,994:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, variable=test)
2023-09-03 14:53:15,994:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-09-03 14:53:15,994:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-03 14:53:16,002:INFO:Variable:  returned as      Age  Resting_blood_pressure  Serum_cholestrol  Max_heart_rate_achieved  \
196   68                     118               277                      151   
197   62                     140               394                      157   
198   61                     130               330                      169   
199   38                     138               175                      173   
200   53                     130               264                      143   
..   ...                     ...               ...                      ...   
298   48                     110               229                      168   
299   39                     140               321                      182   
300   66                     112               212                      132   
301   67                     120               237                       71   
302   60                     130               206                      132   

     ST_depression  Number_of_major_vessels  Chest_pain_LEVEL_1  \
196            1.0                      1.0                   0   
197            1.2                      0.0                   0   
198            0.0                      0.0                   0   
199            0.0                      NaN                   0   
200            0.4                      0.0                   0   
..             ...                      ...                 ...   
298            1.0                      0.0                   0   
299            0.0                      0.0                   0   
300            0.1                      1.0                   0   
301            1.0                      0.0                   0   
302            2.4                      2.0                   0   

     Chest_pain_LEVEL_2  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  ...  \
196                   0                   1                   0  ...   
197                   0                   0                   1  ...   
198                   0                   0                   1  ...   
199                   0                   1                   0  ...   
200                   0                   0                   1  ...   
..                  ...                 ...                 ...  ...   
298                   1                   0                   0  ...   
299                   0                   1                   0  ...   
300                   0                   0                   1  ...   
301                   0                   0                   1  ...   
302                   0                   0                   1  ...   

     Resting_ECG_LEVEL_2  Exercise_induced_angina_NO_PAIN  \
196                    0                                1   
197                    1                                1   
198                    1                                1   
199                    0                                1   
200                    1                                1   
..                   ...                              ...   
298                    0                                1   
299                    1                                1   
300                    1                                0   
301                    0                                1   
302                    1                                0   

     Exercise_induced_angina_PAIN  Peak_exercise_ST_segment_LEVEL_1  \
196                             0                                 1   
197                             0                                 0   
198                             0                                 1   
199                             0                                 1   
200                             0                                 0   
..                            ...                               ...   
298                             0                                 0   
299                             0                                 1   
300                             1                                 1   
301                             0                                 0   
302                             1                                 0   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_3  \
196                                 0                                 0   
197                                 1                                 0   
198                                 0                                 0   
199                                 0                                 0   
200                                 1                                 0   
..                                ...                               ...   
298                                 0                                 1   
299                                 0                                 0   
300                                 0                                 0   
301                                 1                                 0   
302                                 1                                 0   

     Thal_LEVEL_3  Thal_LEVEL_6  Thal_LEVEL_7  ALVO  
196             0             0             1     0  
197             1             0             0     0  
198             1             0             0     1  
199             1             0             0     0  
200             1             0             0     0  
..            ...           ...           ...   ...  
298             0             0             1     1  
299             1             0             0     0  
300             1             0             0     1  
301             1             0             0     1  
302             0             0             1     1  

[107 rows x 26 columns]
2023-09-03 14:53:16,003:INFO:get_config() successfully completed......................................
2023-09-03 14:53:32,185:INFO:Initializing get_config()
2023-09-03 14:53:32,186:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, variable=X_train)
2023-09-03 14:53:32,186:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-09-03 14:53:32,186:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-03 14:53:32,194:INFO:Variable:  returned as      Age  Resting_blood_pressure  Serum_cholestrol  Max_heart_rate_achieved  \
0     49                     120               188                      139   
1     39                     138               220                      152   
2     52                     125               212                      168   
3     41                     110               172                      158   
4     57                     152               274                       88   
..   ...                     ...               ...                      ...   
191   46                     138               243                      152   
192   57                     110               335                      143   
193   55                     140               217                      111   
194   63                     135               252                      172   
195   49                     130               269                      163   

     ST_depression  Number_of_major_vessels  Chest_pain_LEVEL_1  \
0              2.0                      3.0                   0   
1              0.0                      0.0                   0   
2              1.0                      2.0                   0   
3              0.0                      0.0                   0   
4              1.2                      1.0                   0   
..             ...                      ...                 ...   
191            0.0                      0.0                   0   
192            3.0                      1.0                   0   
193            5.6                      0.0                   0   
194            0.0                      0.0                   0   
195            0.0                      0.0                   0   

     Chest_pain_LEVEL_2  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  ...  \
0                     0                   1                   0  ...   
1                     0                   1                   0  ...   
2                     0                   0                   1  ...   
3                     0                   0                   1  ...   
4                     0                   0                   1  ...   
..                  ...                 ...                 ...  ...   
191                   0                   0                   1  ...   
192                   0                   0                   1  ...   
193                   0                   0                   1  ...   
194                   0                   1                   0  ...   
195                   0                   0                   1  ...   

     Resting_ECG_LEVEL_1  Resting_ECG_LEVEL_2  \
0                      0                    0   
1                      0                    0   
2                      0                    0   
3                      0                    1   
4                      0                    0   
..                   ...                  ...   
191                    0                    1   
192                    0                    0   
193                    0                    0   
194                    0                    1   
195                    0                    0   

     Exercise_induced_angina_NO_PAIN  Exercise_induced_angina_PAIN  \
0                                  1                             0   
1                                  1                             0   
2                                  1                             0   
3                                  1                             0   
4                                  0                             1   
..                               ...                           ...   
191                                0                             1   
192                                0                             1   
193                                0                             1   
194                                1                             0   
195                                1                             0   

     Peak_exercise_ST_segment_LEVEL_1  Peak_exercise_ST_segment_LEVEL_2  \
0                                   0                                 1   
1                                   0                                 1   
2                                   1                                 0   
3                                   1                                 0   
4                                   0                                 1   
..                                ...                               ...   
191                                 0                                 1   
192                                 0                                 1   
193                                 0                                 0   
194                                 1                                 0   
195                                 1                                 0   

     Peak_exercise_ST_segment_LEVEL_3  Thal_LEVEL_3  Thal_LEVEL_6  \
0                                   0             0             0   
1                                   0             1             0   
2                                   0             0             0   
3                                   0             0             0   
4                                   0             0             0   
..                                ...           ...           ...   
191                                 0             1             0   
192                                 0             0             0   
193                                 1             0             0   
194                                 0             1             0   
195                                 0             1             0   

     Thal_LEVEL_7  
0               1  
1               0  
2               1  
3               1  
4               1  
..            ...  
191             0  
192             1  
193             1  
194             0  
195             0  

[196 rows x 25 columns]
2023-09-03 14:53:32,194:INFO:get_config() successfully completed......................................
2023-09-03 14:53:45,532:INFO:Initializing get_config()
2023-09-03 14:53:45,533:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, variable=X_train_transformed)
2023-09-03 14:53:45,562:INFO:Variable: X_train returned as           Age  Resting_blood_pressure  Serum_cholestrol  \
0   -0.631355               -0.643981         -1.071874   
1   -1.804298                0.383128         -0.477305   
2   -0.279472               -0.358673         -0.625947   
3   -1.569709               -1.214598         -1.369159   
4    0.307000                1.181991          0.526031   
..        ...                     ...               ...   
191 -0.983238                0.383128         -0.049958   
192  0.307000               -1.214598          1.659429   
193  0.072411                0.497251         -0.533046   
194  1.010766                0.211943          0.117264   
195 -0.631355               -0.073365          0.433129   

     Max_heart_rate_achieved  ST_depression  Number_of_major_vessels  \
0                  -0.422276       0.758256                 2.610225   
1                   0.150652      -0.910673                -0.735922   
2                   0.855796      -0.076209                 1.494842   
3                   0.415081      -0.910673                -0.735922   
4                  -2.669920       0.090684                 0.379460   
..                       ...            ...                      ...   
191                 0.150652      -0.910673                -0.735922   
192                -0.245991       1.592720                 0.379460   
193                -1.656277       3.762328                -0.735922   
194                 1.032081      -0.910673                -0.735922   
195                 0.635438      -0.910673                -0.735922   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Chest_pain_LEVEL_3  \
0             -0.298142           -0.458123            1.621613   
1             -0.298142           -0.458123            1.621613   
2             -0.298142           -0.458123           -0.616670   
3             -0.298142           -0.458123           -0.616670   
4             -0.298142           -0.458123           -0.616670   
..                  ...                 ...                 ...   
191           -0.298142           -0.458123           -0.616670   
192           -0.298142           -0.458123           -0.616670   
193           -0.298142           -0.458123           -0.616670   
194           -0.298142           -0.458123            1.621613   
195           -0.298142           -0.458123           -0.616670   

     Chest_pain_LEVEL_4  ...  Resting_ECG_LEVEL_1  Resting_ECG_LEVEL_2  \
0             -0.940540  ...            -0.144338            -1.010257   
1             -0.940540  ...            -0.144338            -1.010257   
2              1.063219  ...            -0.144338            -1.010257   
3              1.063219  ...            -0.144338             0.989847   
4              1.063219  ...            -0.144338            -1.010257   
..                  ...  ...                  ...                  ...   
191            1.063219  ...            -0.144338             0.989847   
192            1.063219  ...            -0.144338            -1.010257   
193            1.063219  ...            -0.144338            -1.010257   
194           -0.940540  ...            -0.144338             0.989847   
195            1.063219  ...            -0.144338            -1.010257   

     Exercise_induced_angina_NO_PAIN  Exercise_induced_angina_PAIN  \
0                           0.728869                     -0.728869   
1                           0.728869                     -0.728869   
2                           0.728869                     -0.728869   
3                           0.728869                     -0.728869   
4                          -1.371989                      1.371989   
..                               ...                           ...   
191                        -1.371989                      1.371989   
192                        -1.371989                      1.371989   
193                        -1.371989                      1.371989   
194                         0.728869                     -0.728869   
195                         0.728869                     -0.728869   

     Peak_exercise_ST_segment_LEVEL_1  Peak_exercise_ST_segment_LEVEL_2  \
0                           -0.902671                          1.031095   
1                           -0.902671                          1.031095   
2                            1.107823                         -0.969842   
3                            1.107823                         -0.969842   
4                           -0.902671                          1.031095   
..                                ...                               ...   
191                         -0.902671                          1.031095   
192                         -0.902671                          1.031095   
193                         -0.902671                         -0.969842   
194                          1.107823                         -0.969842   
195                          1.107823                         -0.969842   

     Peak_exercise_ST_segment_LEVEL_3  Thal_LEVEL_3  Thal_LEVEL_6  \
0                           -0.266530     -1.096470     -0.243843   
1                           -0.266530      0.912017     -0.243843   
2                           -0.266530     -1.096470     -0.243843   
3                           -0.266530     -1.096470     -0.243843   
4                           -0.266530     -1.096470     -0.243843   
..                                ...           ...           ...   
191                         -0.266530      0.912017     -0.243843   
192                         -0.266530     -1.096470     -0.243843   
193                          3.751923     -1.096470     -0.243843   
194                         -0.266530      0.912017     -0.243843   
195                         -0.266530      0.912017     -0.243843   

     Thal_LEVEL_7  
0        1.256562  
1       -0.795822  
2        1.256562  
3        1.256562  
4        1.256562  
..            ...  
191     -0.795822  
192      1.256562  
193      1.256562  
194     -0.795822  
195     -0.795822  

[196 rows x 25 columns]
2023-09-03 14:53:45,563:INFO:get_config() successfully completed......................................
2023-09-03 15:08:59,616:INFO:Initializing compare_models()
2023-09-03 15:08:59,618:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-09-03 15:08:59,619:INFO:Checking exceptions
2023-09-03 15:08:59,636:INFO:Preparing display monitor
2023-09-03 15:08:59,792:INFO:Initializing Logistic Regression
2023-09-03 15:08:59,792:INFO:Total runtime is 1.4428297678629557e-05 minutes
2023-09-03 15:08:59,795:INFO:SubProcess create_model() called ==================================
2023-09-03 15:08:59,802:INFO:Initializing create_model()
2023-09-03 15:08:59,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:08:59,803:INFO:Checking exceptions
2023-09-03 15:08:59,803:INFO:Importing libraries
2023-09-03 15:08:59,803:INFO:Copying training dataset
2023-09-03 15:08:59,808:INFO:Defining folds
2023-09-03 15:08:59,808:INFO:Declaring metric variables
2023-09-03 15:08:59,812:INFO:Importing untrained model
2023-09-03 15:08:59,820:INFO:Logistic Regression Imported successfully
2023-09-03 15:08:59,828:INFO:Starting cross validation
2023-09-03 15:08:59,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:07,998:INFO:Calculating mean and std
2023-09-03 15:09:08,004:INFO:Creating metrics dataframe
2023-09-03 15:09:08,023:INFO:Uploading results into container
2023-09-03 15:09:08,024:INFO:Uploading model into container now
2023-09-03 15:09:08,029:INFO:_master_model_container: 1
2023-09-03 15:09:08,029:INFO:_display_container: 2
2023-09-03 15:09:08,032:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-03 15:09:08,033:INFO:create_model() successfully completed......................................
2023-09-03 15:09:09,207:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:09,207:INFO:Creating metrics dataframe
2023-09-03 15:09:09,227:INFO:Initializing K Neighbors Classifier
2023-09-03 15:09:09,227:INFO:Total runtime is 0.1572744886080424 minutes
2023-09-03 15:09:09,230:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:09,230:INFO:Initializing create_model()
2023-09-03 15:09:09,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:09,231:INFO:Checking exceptions
2023-09-03 15:09:09,231:INFO:Importing libraries
2023-09-03 15:09:09,231:INFO:Copying training dataset
2023-09-03 15:09:09,238:INFO:Defining folds
2023-09-03 15:09:09,238:INFO:Declaring metric variables
2023-09-03 15:09:09,243:INFO:Importing untrained model
2023-09-03 15:09:09,246:INFO:K Neighbors Classifier Imported successfully
2023-09-03 15:09:09,255:INFO:Starting cross validation
2023-09-03 15:09:09,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:09,413:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,415:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,415:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,415:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,415:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,426:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,441:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,453:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,545:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,547:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-09-03 15:09:09,593:INFO:Calculating mean and std
2023-09-03 15:09:09,594:INFO:Creating metrics dataframe
2023-09-03 15:09:09,599:INFO:Uploading results into container
2023-09-03 15:09:09,600:INFO:Uploading model into container now
2023-09-03 15:09:09,601:INFO:_master_model_container: 2
2023-09-03 15:09:09,601:INFO:_display_container: 2
2023-09-03 15:09:09,602:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-03 15:09:09,602:INFO:create_model() successfully completed......................................
2023-09-03 15:09:09,705:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:09,706:INFO:Creating metrics dataframe
2023-09-03 15:09:09,721:INFO:Initializing Naive Bayes
2023-09-03 15:09:09,721:INFO:Total runtime is 0.16550712982813517 minutes
2023-09-03 15:09:09,726:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:09,726:INFO:Initializing create_model()
2023-09-03 15:09:09,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:09,727:INFO:Checking exceptions
2023-09-03 15:09:09,727:INFO:Importing libraries
2023-09-03 15:09:09,727:INFO:Copying training dataset
2023-09-03 15:09:09,732:INFO:Defining folds
2023-09-03 15:09:09,732:INFO:Declaring metric variables
2023-09-03 15:09:09,735:INFO:Importing untrained model
2023-09-03 15:09:09,739:INFO:Naive Bayes Imported successfully
2023-09-03 15:09:09,745:INFO:Starting cross validation
2023-09-03 15:09:09,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:10,055:INFO:Calculating mean and std
2023-09-03 15:09:10,058:INFO:Creating metrics dataframe
2023-09-03 15:09:10,063:INFO:Uploading results into container
2023-09-03 15:09:10,063:INFO:Uploading model into container now
2023-09-03 15:09:10,064:INFO:_master_model_container: 3
2023-09-03 15:09:10,064:INFO:_display_container: 2
2023-09-03 15:09:10,064:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-03 15:09:10,064:INFO:create_model() successfully completed......................................
2023-09-03 15:09:10,169:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:10,169:INFO:Creating metrics dataframe
2023-09-03 15:09:10,188:INFO:Initializing Decision Tree Classifier
2023-09-03 15:09:10,188:INFO:Total runtime is 0.17328907251358033 minutes
2023-09-03 15:09:10,195:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:10,195:INFO:Initializing create_model()
2023-09-03 15:09:10,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:10,196:INFO:Checking exceptions
2023-09-03 15:09:10,196:INFO:Importing libraries
2023-09-03 15:09:10,196:INFO:Copying training dataset
2023-09-03 15:09:10,203:INFO:Defining folds
2023-09-03 15:09:10,203:INFO:Declaring metric variables
2023-09-03 15:09:10,211:INFO:Importing untrained model
2023-09-03 15:09:10,214:INFO:Decision Tree Classifier Imported successfully
2023-09-03 15:09:10,223:INFO:Starting cross validation
2023-09-03 15:09:10,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:10,492:INFO:Calculating mean and std
2023-09-03 15:09:10,494:INFO:Creating metrics dataframe
2023-09-03 15:09:10,497:INFO:Uploading results into container
2023-09-03 15:09:10,498:INFO:Uploading model into container now
2023-09-03 15:09:10,498:INFO:_master_model_container: 4
2023-09-03 15:09:10,499:INFO:_display_container: 2
2023-09-03 15:09:10,499:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-09-03 15:09:10,499:INFO:create_model() successfully completed......................................
2023-09-03 15:09:10,631:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:10,631:INFO:Creating metrics dataframe
2023-09-03 15:09:10,648:INFO:Initializing SVM - Linear Kernel
2023-09-03 15:09:10,649:INFO:Total runtime is 0.1809647798538208 minutes
2023-09-03 15:09:10,654:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:10,654:INFO:Initializing create_model()
2023-09-03 15:09:10,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:10,654:INFO:Checking exceptions
2023-09-03 15:09:10,654:INFO:Importing libraries
2023-09-03 15:09:10,654:INFO:Copying training dataset
2023-09-03 15:09:10,663:INFO:Defining folds
2023-09-03 15:09:10,663:INFO:Declaring metric variables
2023-09-03 15:09:10,666:INFO:Importing untrained model
2023-09-03 15:09:10,672:INFO:SVM - Linear Kernel Imported successfully
2023-09-03 15:09:10,678:INFO:Starting cross validation
2023-09-03 15:09:10,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:10,890:INFO:Calculating mean and std
2023-09-03 15:09:10,891:INFO:Creating metrics dataframe
2023-09-03 15:09:10,895:INFO:Uploading results into container
2023-09-03 15:09:10,896:INFO:Uploading model into container now
2023-09-03 15:09:10,896:INFO:_master_model_container: 5
2023-09-03 15:09:10,896:INFO:_display_container: 2
2023-09-03 15:09:10,897:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-03 15:09:10,898:INFO:create_model() successfully completed......................................
2023-09-03 15:09:10,997:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:10,997:INFO:Creating metrics dataframe
2023-09-03 15:09:11,008:INFO:Initializing Ridge Classifier
2023-09-03 15:09:11,008:INFO:Total runtime is 0.18695109287897746 minutes
2023-09-03 15:09:11,011:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:11,012:INFO:Initializing create_model()
2023-09-03 15:09:11,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:11,012:INFO:Checking exceptions
2023-09-03 15:09:11,012:INFO:Importing libraries
2023-09-03 15:09:11,012:INFO:Copying training dataset
2023-09-03 15:09:11,016:INFO:Defining folds
2023-09-03 15:09:11,017:INFO:Declaring metric variables
2023-09-03 15:09:11,020:INFO:Importing untrained model
2023-09-03 15:09:11,022:INFO:Ridge Classifier Imported successfully
2023-09-03 15:09:11,028:INFO:Starting cross validation
2023-09-03 15:09:11,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:11,236:INFO:Calculating mean and std
2023-09-03 15:09:11,238:INFO:Creating metrics dataframe
2023-09-03 15:09:11,241:INFO:Uploading results into container
2023-09-03 15:09:11,241:INFO:Uploading model into container now
2023-09-03 15:09:11,242:INFO:_master_model_container: 6
2023-09-03 15:09:11,242:INFO:_display_container: 2
2023-09-03 15:09:11,242:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1935, solver='auto', tol=0.001)
2023-09-03 15:09:11,242:INFO:create_model() successfully completed......................................
2023-09-03 15:09:11,348:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:11,348:INFO:Creating metrics dataframe
2023-09-03 15:09:11,364:INFO:Initializing Random Forest Classifier
2023-09-03 15:09:11,365:INFO:Total runtime is 0.19290659427642823 minutes
2023-09-03 15:09:11,369:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:11,369:INFO:Initializing create_model()
2023-09-03 15:09:11,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:11,369:INFO:Checking exceptions
2023-09-03 15:09:11,370:INFO:Importing libraries
2023-09-03 15:09:11,370:INFO:Copying training dataset
2023-09-03 15:09:11,379:INFO:Defining folds
2023-09-03 15:09:11,379:INFO:Declaring metric variables
2023-09-03 15:09:11,384:INFO:Importing untrained model
2023-09-03 15:09:11,389:INFO:Random Forest Classifier Imported successfully
2023-09-03 15:09:11,397:INFO:Starting cross validation
2023-09-03 15:09:11,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:13,062:INFO:Calculating mean and std
2023-09-03 15:09:13,064:INFO:Creating metrics dataframe
2023-09-03 15:09:13,068:INFO:Uploading results into container
2023-09-03 15:09:13,068:INFO:Uploading model into container now
2023-09-03 15:09:13,069:INFO:_master_model_container: 7
2023-09-03 15:09:13,069:INFO:_display_container: 2
2023-09-03 15:09:13,069:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-03 15:09:13,069:INFO:create_model() successfully completed......................................
2023-09-03 15:09:13,181:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:13,181:INFO:Creating metrics dataframe
2023-09-03 15:09:13,194:INFO:Initializing Quadratic Discriminant Analysis
2023-09-03 15:09:13,194:INFO:Total runtime is 0.22338424126307171 minutes
2023-09-03 15:09:13,197:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:13,198:INFO:Initializing create_model()
2023-09-03 15:09:13,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:13,198:INFO:Checking exceptions
2023-09-03 15:09:13,198:INFO:Importing libraries
2023-09-03 15:09:13,198:INFO:Copying training dataset
2023-09-03 15:09:13,202:INFO:Defining folds
2023-09-03 15:09:13,202:INFO:Declaring metric variables
2023-09-03 15:09:13,205:INFO:Importing untrained model
2023-09-03 15:09:13,208:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-03 15:09:13,216:INFO:Starting cross validation
2023-09-03 15:09:13,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:13,300:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,300:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,303:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,305:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,305:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,314:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,354:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,367:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,452:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,463:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-03 15:09:13,539:INFO:Calculating mean and std
2023-09-03 15:09:13,542:INFO:Creating metrics dataframe
2023-09-03 15:09:13,547:INFO:Uploading results into container
2023-09-03 15:09:13,548:INFO:Uploading model into container now
2023-09-03 15:09:13,550:INFO:_master_model_container: 8
2023-09-03 15:09:13,550:INFO:_display_container: 2
2023-09-03 15:09:13,550:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-03 15:09:13,550:INFO:create_model() successfully completed......................................
2023-09-03 15:09:13,676:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:13,676:INFO:Creating metrics dataframe
2023-09-03 15:09:13,700:INFO:Initializing Ada Boost Classifier
2023-09-03 15:09:13,701:INFO:Total runtime is 0.23182907899220787 minutes
2023-09-03 15:09:13,706:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:13,706:INFO:Initializing create_model()
2023-09-03 15:09:13,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:13,706:INFO:Checking exceptions
2023-09-03 15:09:13,706:INFO:Importing libraries
2023-09-03 15:09:13,706:INFO:Copying training dataset
2023-09-03 15:09:13,714:INFO:Defining folds
2023-09-03 15:09:13,714:INFO:Declaring metric variables
2023-09-03 15:09:13,718:INFO:Importing untrained model
2023-09-03 15:09:13,724:INFO:Ada Boost Classifier Imported successfully
2023-09-03 15:09:13,732:INFO:Starting cross validation
2023-09-03 15:09:13,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:15,379:INFO:Calculating mean and std
2023-09-03 15:09:15,383:INFO:Creating metrics dataframe
2023-09-03 15:09:15,390:INFO:Uploading results into container
2023-09-03 15:09:15,390:INFO:Uploading model into container now
2023-09-03 15:09:15,391:INFO:_master_model_container: 9
2023-09-03 15:09:15,391:INFO:_display_container: 2
2023-09-03 15:09:15,391:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1935)
2023-09-03 15:09:15,391:INFO:create_model() successfully completed......................................
2023-09-03 15:09:15,539:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:15,540:INFO:Creating metrics dataframe
2023-09-03 15:09:15,558:INFO:Initializing Gradient Boosting Classifier
2023-09-03 15:09:15,558:INFO:Total runtime is 0.26278477907180786 minutes
2023-09-03 15:09:15,562:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:15,562:INFO:Initializing create_model()
2023-09-03 15:09:15,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:15,562:INFO:Checking exceptions
2023-09-03 15:09:15,563:INFO:Importing libraries
2023-09-03 15:09:15,563:INFO:Copying training dataset
2023-09-03 15:09:15,572:INFO:Defining folds
2023-09-03 15:09:15,573:INFO:Declaring metric variables
2023-09-03 15:09:15,584:INFO:Importing untrained model
2023-09-03 15:09:15,592:INFO:Gradient Boosting Classifier Imported successfully
2023-09-03 15:09:15,607:INFO:Starting cross validation
2023-09-03 15:09:15,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:17,514:INFO:Calculating mean and std
2023-09-03 15:09:17,518:INFO:Creating metrics dataframe
2023-09-03 15:09:17,523:INFO:Uploading results into container
2023-09-03 15:09:17,524:INFO:Uploading model into container now
2023-09-03 15:09:17,524:INFO:_master_model_container: 10
2023-09-03 15:09:17,524:INFO:_display_container: 2
2023-09-03 15:09:17,525:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-03 15:09:17,525:INFO:create_model() successfully completed......................................
2023-09-03 15:09:17,669:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:17,669:INFO:Creating metrics dataframe
2023-09-03 15:09:17,700:INFO:Initializing Linear Discriminant Analysis
2023-09-03 15:09:17,700:INFO:Total runtime is 0.2984839876492818 minutes
2023-09-03 15:09:17,708:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:17,708:INFO:Initializing create_model()
2023-09-03 15:09:17,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:17,709:INFO:Checking exceptions
2023-09-03 15:09:17,709:INFO:Importing libraries
2023-09-03 15:09:17,709:INFO:Copying training dataset
2023-09-03 15:09:17,716:INFO:Defining folds
2023-09-03 15:09:17,717:INFO:Declaring metric variables
2023-09-03 15:09:17,721:INFO:Importing untrained model
2023-09-03 15:09:17,728:INFO:Linear Discriminant Analysis Imported successfully
2023-09-03 15:09:17,744:INFO:Starting cross validation
2023-09-03 15:09:17,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:18,207:INFO:Calculating mean and std
2023-09-03 15:09:18,209:INFO:Creating metrics dataframe
2023-09-03 15:09:18,213:INFO:Uploading results into container
2023-09-03 15:09:18,214:INFO:Uploading model into container now
2023-09-03 15:09:18,214:INFO:_master_model_container: 11
2023-09-03 15:09:18,215:INFO:_display_container: 2
2023-09-03 15:09:18,215:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-03 15:09:18,215:INFO:create_model() successfully completed......................................
2023-09-03 15:09:18,345:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:18,346:INFO:Creating metrics dataframe
2023-09-03 15:09:18,375:INFO:Initializing Extra Trees Classifier
2023-09-03 15:09:18,376:INFO:Total runtime is 0.30974971055984496 minutes
2023-09-03 15:09:18,379:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:18,380:INFO:Initializing create_model()
2023-09-03 15:09:18,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:18,381:INFO:Checking exceptions
2023-09-03 15:09:18,381:INFO:Importing libraries
2023-09-03 15:09:18,381:INFO:Copying training dataset
2023-09-03 15:09:18,392:INFO:Defining folds
2023-09-03 15:09:18,392:INFO:Declaring metric variables
2023-09-03 15:09:18,402:INFO:Importing untrained model
2023-09-03 15:09:18,414:INFO:Extra Trees Classifier Imported successfully
2023-09-03 15:09:18,429:INFO:Starting cross validation
2023-09-03 15:09:18,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:21,935:INFO:Calculating mean and std
2023-09-03 15:09:21,939:INFO:Creating metrics dataframe
2023-09-03 15:09:21,945:INFO:Uploading results into container
2023-09-03 15:09:21,945:INFO:Uploading model into container now
2023-09-03 15:09:21,946:INFO:_master_model_container: 12
2023-09-03 15:09:21,946:INFO:_display_container: 2
2023-09-03 15:09:21,947:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-09-03 15:09:21,947:INFO:create_model() successfully completed......................................
2023-09-03 15:09:22,089:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:22,090:INFO:Creating metrics dataframe
2023-09-03 15:09:22,116:INFO:Initializing Extreme Gradient Boosting
2023-09-03 15:09:22,116:INFO:Total runtime is 0.37208231687545773 minutes
2023-09-03 15:09:22,123:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:22,123:INFO:Initializing create_model()
2023-09-03 15:09:22,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:22,123:INFO:Checking exceptions
2023-09-03 15:09:22,123:INFO:Importing libraries
2023-09-03 15:09:22,124:INFO:Copying training dataset
2023-09-03 15:09:22,132:INFO:Defining folds
2023-09-03 15:09:22,132:INFO:Declaring metric variables
2023-09-03 15:09:22,139:INFO:Importing untrained model
2023-09-03 15:09:22,146:INFO:Extreme Gradient Boosting Imported successfully
2023-09-03 15:09:22,156:INFO:Starting cross validation
2023-09-03 15:09:22,159:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:23,618:INFO:Calculating mean and std
2023-09-03 15:09:23,627:INFO:Creating metrics dataframe
2023-09-03 15:09:23,639:INFO:Uploading results into container
2023-09-03 15:09:23,641:INFO:Uploading model into container now
2023-09-03 15:09:23,641:INFO:_master_model_container: 13
2023-09-03 15:09:23,642:INFO:_display_container: 2
2023-09-03 15:09:23,644:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-03 15:09:23,645:INFO:create_model() successfully completed......................................
2023-09-03 15:09:23,832:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:23,832:INFO:Creating metrics dataframe
2023-09-03 15:09:23,865:INFO:Initializing Light Gradient Boosting Machine
2023-09-03 15:09:23,865:INFO:Total runtime is 0.40123687982559203 minutes
2023-09-03 15:09:23,875:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:23,877:INFO:Initializing create_model()
2023-09-03 15:09:23,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:23,878:INFO:Checking exceptions
2023-09-03 15:09:23,878:INFO:Importing libraries
2023-09-03 15:09:23,878:INFO:Copying training dataset
2023-09-03 15:09:23,890:INFO:Defining folds
2023-09-03 15:09:23,890:INFO:Declaring metric variables
2023-09-03 15:09:23,905:INFO:Importing untrained model
2023-09-03 15:09:23,913:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-03 15:09:23,925:INFO:Starting cross validation
2023-09-03 15:09:23,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:28,389:INFO:Calculating mean and std
2023-09-03 15:09:28,392:INFO:Creating metrics dataframe
2023-09-03 15:09:28,404:INFO:Uploading results into container
2023-09-03 15:09:28,406:INFO:Uploading model into container now
2023-09-03 15:09:28,407:INFO:_master_model_container: 14
2023-09-03 15:09:28,407:INFO:_display_container: 2
2023-09-03 15:09:28,410:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-09-03 15:09:28,410:INFO:create_model() successfully completed......................................
2023-09-03 15:09:28,576:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:28,577:INFO:Creating metrics dataframe
2023-09-03 15:09:28,615:INFO:Initializing CatBoost Classifier
2023-09-03 15:09:28,616:INFO:Total runtime is 0.4804191788037618 minutes
2023-09-03 15:09:28,626:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:28,626:INFO:Initializing create_model()
2023-09-03 15:09:28,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:28,626:INFO:Checking exceptions
2023-09-03 15:09:28,626:INFO:Importing libraries
2023-09-03 15:09:28,626:INFO:Copying training dataset
2023-09-03 15:09:28,638:INFO:Defining folds
2023-09-03 15:09:28,638:INFO:Declaring metric variables
2023-09-03 15:09:28,647:INFO:Importing untrained model
2023-09-03 15:09:28,661:INFO:CatBoost Classifier Imported successfully
2023-09-03 15:09:28,675:INFO:Starting cross validation
2023-09-03 15:09:28,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:47,401:INFO:Calculating mean and std
2023-09-03 15:09:47,408:INFO:Creating metrics dataframe
2023-09-03 15:09:47,415:INFO:Uploading results into container
2023-09-03 15:09:47,417:INFO:Uploading model into container now
2023-09-03 15:09:47,418:INFO:_master_model_container: 15
2023-09-03 15:09:47,418:INFO:_display_container: 2
2023-09-03 15:09:47,418:INFO:<catboost.core.CatBoostClassifier object at 0x0000024407A4A2E0>
2023-09-03 15:09:47,419:INFO:create_model() successfully completed......................................
2023-09-03 15:09:47,588:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:47,588:INFO:Creating metrics dataframe
2023-09-03 15:09:47,619:INFO:Initializing Dummy Classifier
2023-09-03 15:09:47,619:INFO:Total runtime is 0.797140367825826 minutes
2023-09-03 15:09:47,626:INFO:SubProcess create_model() called ==================================
2023-09-03 15:09:47,627:INFO:Initializing create_model()
2023-09-03 15:09:47,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024407A4AB80>, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:47,627:INFO:Checking exceptions
2023-09-03 15:09:47,627:INFO:Importing libraries
2023-09-03 15:09:47,627:INFO:Copying training dataset
2023-09-03 15:09:47,635:INFO:Defining folds
2023-09-03 15:09:47,636:INFO:Declaring metric variables
2023-09-03 15:09:47,642:INFO:Importing untrained model
2023-09-03 15:09:47,649:INFO:Dummy Classifier Imported successfully
2023-09-03 15:09:47,659:INFO:Starting cross validation
2023-09-03 15:09:47,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:09:47,851:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:47,864:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:47,883:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:47,884:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:47,896:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:47,902:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:47,908:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:47,935:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:48,064:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:48,086:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-03 15:09:48,091:INFO:Calculating mean and std
2023-09-03 15:09:48,094:INFO:Creating metrics dataframe
2023-09-03 15:09:48,099:INFO:Uploading results into container
2023-09-03 15:09:48,100:INFO:Uploading model into container now
2023-09-03 15:09:48,100:INFO:_master_model_container: 16
2023-09-03 15:09:48,101:INFO:_display_container: 2
2023-09-03 15:09:48,101:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-09-03 15:09:48,101:INFO:create_model() successfully completed......................................
2023-09-03 15:09:48,253:INFO:SubProcess create_model() end ==================================
2023-09-03 15:09:48,254:INFO:Creating metrics dataframe
2023-09-03 15:09:48,301:INFO:Initializing create_model()
2023-09-03 15:09:48,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000024407A4A2E0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:09:48,302:INFO:Checking exceptions
2023-09-03 15:09:48,306:INFO:Importing libraries
2023-09-03 15:09:48,306:INFO:Copying training dataset
2023-09-03 15:09:48,311:INFO:Defining folds
2023-09-03 15:09:48,312:INFO:Declaring metric variables
2023-09-03 15:09:48,312:INFO:Importing untrained model
2023-09-03 15:09:48,312:INFO:Declaring custom model
2023-09-03 15:09:48,312:INFO:CatBoost Classifier Imported successfully
2023-09-03 15:09:48,314:INFO:Cross validation set to False
2023-09-03 15:09:48,314:INFO:Fitting Model
2023-09-03 15:09:52,583:INFO:<catboost.core.CatBoostClassifier object at 0x0000024407856F10>
2023-09-03 15:09:52,584:INFO:create_model() successfully completed......................................
2023-09-03 15:09:52,821:INFO:_master_model_container: 16
2023-09-03 15:09:52,822:INFO:_display_container: 2
2023-09-03 15:09:52,822:INFO:<catboost.core.CatBoostClassifier object at 0x0000024407856F10>
2023-09-03 15:09:52,822:INFO:compare_models() successfully completed......................................
2023-09-03 15:45:52,678:INFO:Initializing create_model()
2023-09-03 15:45:52,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-03 15:45:52,692:INFO:Checking exceptions
2023-09-03 15:45:52,910:INFO:Importing libraries
2023-09-03 15:45:52,912:INFO:Copying training dataset
2023-09-03 15:45:52,935:INFO:Defining folds
2023-09-03 15:45:52,936:INFO:Declaring metric variables
2023-09-03 15:45:52,943:INFO:Importing untrained model
2023-09-03 15:45:52,958:INFO:CatBoost Classifier Imported successfully
2023-09-03 15:45:52,969:INFO:Starting cross validation
2023-09-03 15:45:52,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 15:46:03,838:INFO:Calculating mean and std
2023-09-03 15:46:03,849:INFO:Creating metrics dataframe
2023-09-03 15:46:03,894:INFO:Finalizing model
2023-09-03 15:46:04,151:INFO:Uploading results into container
2023-09-03 15:46:04,155:INFO:Uploading model into container now
2023-09-03 15:46:04,231:INFO:_master_model_container: 17
2023-09-03 15:46:04,231:INFO:_display_container: 3
2023-09-03 15:46:04,232:INFO:<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>
2023-09-03 15:46:04,232:INFO:create_model() successfully completed......................................
2023-09-03 15:48:00,147:INFO:Initializing predict_model()
2023-09-03 15:48:00,148:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024407D5E790>)
2023-09-03 15:48:00,148:INFO:Checking exceptions
2023-09-03 15:48:00,148:INFO:Preloading libraries
2023-09-03 15:48:00,154:INFO:Set up data.
2023-09-03 15:48:00,172:INFO:Set up index.
2023-09-03 16:08:41,800:INFO:Initializing create_model()
2023-09-03 16:08:41,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-03 16:08:41,840:INFO:Checking exceptions
2023-09-03 16:08:42,305:INFO:Importing libraries
2023-09-03 16:08:42,305:INFO:Copying training dataset
2023-09-03 16:08:42,365:INFO:Defining folds
2023-09-03 16:08:42,373:INFO:Declaring metric variables
2023-09-03 16:08:42,381:INFO:Importing untrained model
2023-09-03 16:08:42,405:INFO:Random Forest Classifier Imported successfully
2023-09-03 16:08:42,425:INFO:Starting cross validation
2023-09-03 16:08:42,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 16:08:52,682:INFO:Calculating mean and std
2023-09-03 16:08:52,695:INFO:Creating metrics dataframe
2023-09-03 16:08:52,751:INFO:Finalizing model
2023-09-03 16:08:53,672:INFO:Uploading results into container
2023-09-03 16:08:53,673:INFO:Uploading model into container now
2023-09-03 16:08:53,734:INFO:_master_model_container: 18
2023-09-03 16:08:53,738:INFO:_display_container: 5
2023-09-03 16:08:53,738:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-03 16:08:53,738:INFO:create_model() successfully completed......................................
2023-09-03 16:10:50,824:ERROR:
'm2cgen' is a soft dependency and not included in the pycaret installation. Please run: `pip install m2cgen` to install.
NoneType: None
2023-09-03 16:11:14,248:ERROR:
'm2cgen' is a soft dependency and not included in the pycaret installation. Please run: `pip install m2cgen` to install.
NoneType: None
2023-09-03 16:11:32,594:ERROR:
'm2cgen' is a soft dependency and not included in the pycaret installation. Please run: `pip install m2cgen` to install.
NoneType: None
2023-09-03 16:11:53,154:ERROR:
'm2cgen' is a soft dependency and not included in the pycaret installation. Please run: `pip install m2cgen` to install.
NoneType: None
2023-09-03 16:14:25,342:INFO:Initializing tune_model()
2023-09-03 16:14:25,342:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, fold=None, round=4, n_iter=50, custom_grid=None, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>)
2023-09-03 16:14:25,342:INFO:Checking exceptions
2023-09-03 16:14:25,475:INFO:Copying training dataset
2023-09-03 16:14:25,479:INFO:Checking base model
2023-09-03 16:14:25,491:INFO:Base model : CatBoost Classifier
2023-09-03 16:14:25,508:INFO:Declaring metric variables
2023-09-03 16:14:25,516:INFO:Defining Hyperparameters
2023-09-03 16:14:26,066:INFO:Tuning with n_jobs=-1
2023-09-03 16:14:26,066:INFO:Initializing RandomizedSearchCV
2023-09-03 16:16:06,010:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-03 16:16:25,950:INFO:Initializing tune_model()
2023-09-03 16:16:25,950:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>)
2023-09-03 16:16:25,950:INFO:Checking exceptions
2023-09-03 16:16:26,031:INFO:Copying training dataset
2023-09-03 16:16:26,039:INFO:Checking base model
2023-09-03 16:16:26,047:INFO:Base model : CatBoost Classifier
2023-09-03 16:16:26,060:INFO:Declaring metric variables
2023-09-03 16:16:26,063:INFO:Defining Hyperparameters
2023-09-03 16:16:26,429:INFO:Tuning with n_jobs=-1
2023-09-03 16:16:26,429:INFO:Initializing RandomizedSearchCV
2023-09-03 16:17:21,142:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 100, 'actual_estimator__eta': 0.01, 'actual_estimator__depth': 3}
2023-09-03 16:17:21,188:INFO:Hyperparameter search completed
2023-09-03 16:17:21,188:INFO:SubProcess create_model() called ==================================
2023-09-03 16:17:21,195:INFO:Initializing create_model()
2023-09-03 16:17:21,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092F89A0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002447BE9B520>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.8, 'n_estimators': 280, 'l2_leaf_reg': 100, 'eta': 0.01, 'depth': 3})
2023-09-03 16:17:21,205:INFO:Checking exceptions
2023-09-03 16:17:21,208:INFO:Importing libraries
2023-09-03 16:17:21,211:INFO:Copying training dataset
2023-09-03 16:17:21,270:INFO:Defining folds
2023-09-03 16:17:21,273:INFO:Declaring metric variables
2023-09-03 16:17:21,308:INFO:Importing untrained model
2023-09-03 16:17:21,308:INFO:Declaring custom model
2023-09-03 16:17:21,338:INFO:CatBoost Classifier Imported successfully
2023-09-03 16:17:21,362:INFO:Starting cross validation
2023-09-03 16:17:21,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 16:17:22,216:INFO:Calculating mean and std
2023-09-03 16:17:22,223:INFO:Creating metrics dataframe
2023-09-03 16:17:22,266:INFO:Finalizing model
2023-09-03 16:17:23,701:INFO:Uploading results into container
2023-09-03 16:17:23,701:INFO:Uploading model into container now
2023-09-03 16:17:23,710:INFO:_master_model_container: 19
2023-09-03 16:17:23,711:INFO:_display_container: 6
2023-09-03 16:17:23,711:INFO:<catboost.core.CatBoostClassifier object at 0x00000244092606A0>
2023-09-03 16:17:23,713:INFO:create_model() successfully completed......................................
2023-09-03 16:17:24,865:INFO:SubProcess create_model() end ==================================
2023-09-03 16:17:24,865:INFO:choose_better activated
2023-09-03 16:17:24,878:INFO:SubProcess create_model() called ==================================
2023-09-03 16:17:24,880:INFO:Initializing create_model()
2023-09-03 16:17:24,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-03 16:17:24,882:INFO:Checking exceptions
2023-09-03 16:17:24,891:INFO:Importing libraries
2023-09-03 16:17:24,891:INFO:Copying training dataset
2023-09-03 16:17:24,898:INFO:Defining folds
2023-09-03 16:17:24,898:INFO:Declaring metric variables
2023-09-03 16:17:24,898:INFO:Importing untrained model
2023-09-03 16:17:24,898:INFO:Declaring custom model
2023-09-03 16:17:24,898:INFO:CatBoost Classifier Imported successfully
2023-09-03 16:17:24,898:INFO:Starting cross validation
2023-09-03 16:17:24,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-03 16:17:25,568:INFO:Calculating mean and std
2023-09-03 16:17:25,576:INFO:Creating metrics dataframe
2023-09-03 16:17:25,576:INFO:Finalizing model
2023-09-03 16:17:25,664:INFO:Uploading results into container
2023-09-03 16:17:25,664:INFO:Uploading model into container now
2023-09-03 16:17:25,664:INFO:_master_model_container: 20
2023-09-03 16:17:25,664:INFO:_display_container: 7
2023-09-03 16:17:25,664:INFO:<catboost.core.CatBoostClassifier object at 0x0000024408BBCE80>
2023-09-03 16:17:25,664:INFO:create_model() successfully completed......................................
2023-09-03 16:17:25,857:INFO:SubProcess create_model() end ==================================
2023-09-03 16:17:25,857:INFO:<catboost.core.CatBoostClassifier object at 0x0000024408BBCE80> result for Accuracy is 0.8368
2023-09-03 16:17:25,857:INFO:<catboost.core.CatBoostClassifier object at 0x00000244092606A0> result for Accuracy is 0.8574
2023-09-03 16:17:25,857:INFO:<catboost.core.CatBoostClassifier object at 0x00000244092606A0> is best model
2023-09-03 16:17:25,857:INFO:choose_better completed
2023-09-03 16:17:25,885:INFO:_master_model_container: 20
2023-09-03 16:17:25,885:INFO:_display_container: 6
2023-09-03 16:17:25,900:INFO:<catboost.core.CatBoostClassifier object at 0x00000244092606A0>
2023-09-03 16:17:25,900:INFO:tune_model() successfully completed......................................
2023-09-03 16:18:55,759:INFO:Initializing predict_model()
2023-09-03 16:18:55,759:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024409608AF0>)
2023-09-03 16:18:55,759:INFO:Checking exceptions
2023-09-03 16:18:55,759:INFO:Preloading libraries
2023-09-03 16:19:20,231:INFO:Initializing plot_model()
2023-09-03 16:19:20,231:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:19:20,239:INFO:Checking exceptions
2023-09-03 16:19:20,239:INFO:Preloading libraries
2023-09-03 16:19:20,247:INFO:Copying training dataset
2023-09-03 16:19:20,247:INFO:Plot type: ks
2023-09-03 16:19:20,250:INFO:Generating predictions / predict_proba on X_test
2023-09-03 16:19:21,067:INFO:Visual Rendered Successfully
2023-09-03 16:19:21,256:INFO:plot_model() successfully completed......................................
2023-09-03 16:19:42,868:INFO:Initializing plot_model()
2023-09-03 16:19:42,876:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:19:42,876:INFO:Checking exceptions
2023-09-03 16:19:42,884:INFO:Preloading libraries
2023-09-03 16:19:42,887:INFO:Copying training dataset
2023-09-03 16:19:42,887:INFO:Plot type: ks
2023-09-03 16:19:42,888:INFO:Generating predictions / predict_proba on X_test
2023-09-03 16:19:43,230:INFO:Visual Rendered Successfully
2023-09-03 16:19:43,400:INFO:plot_model() successfully completed......................................
2023-09-03 16:19:53,675:INFO:Initializing plot_model()
2023-09-03 16:19:53,675:INFO:plot_model(plot=ks, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:19:53,675:INFO:Checking exceptions
2023-09-03 16:19:53,684:INFO:Preloading libraries
2023-09-03 16:19:53,684:INFO:Copying training dataset
2023-09-03 16:19:53,684:INFO:Plot type: ks
2023-09-03 16:19:53,686:INFO:Generating predictions / predict_proba on X_test
2023-09-03 16:19:54,147:INFO:Visual Rendered Successfully
2023-09-03 16:19:54,318:INFO:plot_model() successfully completed......................................
2023-09-03 16:20:51,132:INFO:Initializing predict_model()
2023-09-03 16:20:51,140:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024409236E50>)
2023-09-03 16:20:51,140:INFO:Checking exceptions
2023-09-03 16:20:51,141:INFO:Preloading libraries
2023-09-03 16:20:51,141:INFO:Set up data.
2023-09-03 16:20:51,160:INFO:Set up index.
2023-09-03 16:21:22,202:INFO:Initializing predict_model()
2023-09-03 16:21:22,202:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000244096CC040>)
2023-09-03 16:21:22,211:INFO:Checking exceptions
2023-09-03 16:21:22,211:INFO:Preloading libraries
2023-09-03 16:21:22,211:INFO:Set up data.
2023-09-03 16:21:22,226:INFO:Set up index.
2023-09-03 16:22:30,184:INFO:Initializing predict_model()
2023-09-03 16:22:30,185:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024409236820>)
2023-09-03 16:22:30,185:INFO:Checking exceptions
2023-09-03 16:22:30,185:INFO:Preloading libraries
2023-09-03 16:22:30,190:INFO:Set up data.
2023-09-03 16:22:30,202:INFO:Set up index.
2023-09-03 16:23:40,542:INFO:Initializing predict_model()
2023-09-03 16:23:40,542:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024409236C10>)
2023-09-03 16:23:40,542:INFO:Checking exceptions
2023-09-03 16:23:40,542:INFO:Preloading libraries
2023-09-03 16:24:55,211:INFO:Initializing predict_model()
2023-09-03 16:24:55,219:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000024409236C10>)
2023-09-03 16:24:55,219:INFO:Checking exceptions
2023-09-03 16:24:55,219:INFO:Preloading libraries
2023-09-03 16:24:55,223:INFO:Set up data.
2023-09-03 16:24:55,237:INFO:Set up index.
2023-09-03 16:25:03,222:INFO:Initializing predict_model()
2023-09-03 16:25:03,222:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244092606A0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000244096E2550>)
2023-09-03 16:25:03,222:INFO:Checking exceptions
2023-09-03 16:25:03,222:INFO:Preloading libraries
2023-09-03 16:30:38,258:INFO:Initializing plot_model()
2023-09-03 16:30:38,275:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:30:38,275:INFO:Checking exceptions
2023-09-03 16:30:38,492:INFO:Preloading libraries
2023-09-03 16:30:38,544:INFO:Copying training dataset
2023-09-03 16:30:38,545:INFO:Plot type: ks
2023-09-03 16:30:38,556:INFO:Generating predictions / predict_proba on X_test
2023-09-03 16:30:39,209:INFO:Visual Rendered Successfully
2023-09-03 16:30:40,061:INFO:plot_model() successfully completed......................................
2023-09-03 16:32:00,315:ERROR:
'explainerdashboard' is a soft dependency and not included in the pycaret installation. Please run: `pip install explainerdashboard` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-09-03 16:36:13,912:INFO:Initializing evaluate_model()
2023-09-03 16:36:13,912:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-09-03 16:36:14,303:INFO:Initializing plot_model()
2023-09-03 16:36:14,303:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:36:14,303:INFO:Checking exceptions
2023-09-03 16:36:14,329:INFO:Preloading libraries
2023-09-03 16:36:14,377:INFO:Copying training dataset
2023-09-03 16:36:14,377:INFO:Plot type: pipeline
2023-09-03 16:36:14,848:INFO:Visual Rendered Successfully
2023-09-03 16:36:16,127:INFO:plot_model() successfully completed......................................
2023-09-03 16:36:21,186:INFO:Initializing plot_model()
2023-09-03 16:36:21,186:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:36:21,187:INFO:Checking exceptions
2023-09-03 16:36:21,187:INFO:Preloading libraries
2023-09-03 16:36:21,187:INFO:Copying training dataset
2023-09-03 16:36:21,193:INFO:Plot type: ks
2023-09-03 16:36:21,193:INFO:Generating predictions / predict_proba on X_test
2023-09-03 16:36:21,575:INFO:Visual Rendered Successfully
2023-09-03 16:36:21,731:INFO:plot_model() successfully completed......................................
2023-09-03 16:36:31,516:INFO:Initializing plot_model()
2023-09-03 16:36:31,516:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:36:31,516:INFO:Checking exceptions
2023-09-03 16:36:31,518:INFO:Preloading libraries
2023-09-03 16:36:31,518:INFO:Copying training dataset
2023-09-03 16:36:31,518:INFO:Plot type: pr
2023-09-03 16:36:31,688:INFO:Fitting Model
2023-09-03 16:36:31,720:INFO:Scoring test/hold-out set
2023-09-03 16:36:32,135:INFO:Visual Rendered Successfully
2023-09-03 16:36:32,269:INFO:plot_model() successfully completed......................................
2023-09-03 16:36:37,641:INFO:Initializing plot_model()
2023-09-03 16:36:37,641:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:36:37,641:INFO:Checking exceptions
2023-09-03 16:36:37,641:INFO:Preloading libraries
2023-09-03 16:36:37,649:INFO:Copying training dataset
2023-09-03 16:36:37,649:INFO:Plot type: feature
2023-09-03 16:36:37,649:WARNING:No coef_ found. Trying feature_importances_
2023-09-03 16:36:38,003:INFO:Visual Rendered Successfully
2023-09-03 16:36:38,163:INFO:plot_model() successfully completed......................................
2023-09-03 16:36:49,389:INFO:Initializing plot_model()
2023-09-03 16:36:49,396:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:36:49,396:INFO:Checking exceptions
2023-09-03 16:36:49,397:INFO:Preloading libraries
2023-09-03 16:36:49,397:INFO:Copying training dataset
2023-09-03 16:36:49,397:INFO:Plot type: confusion_matrix
2023-09-03 16:36:49,535:INFO:Fitting Model
2023-09-03 16:36:49,535:INFO:Scoring test/hold-out set
2023-09-03 16:36:49,784:INFO:Visual Rendered Successfully
2023-09-03 16:36:49,962:INFO:plot_model() successfully completed......................................
2023-09-03 16:36:57,430:INFO:Initializing plot_model()
2023-09-03 16:36:57,430:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:36:57,430:INFO:Checking exceptions
2023-09-03 16:36:57,437:INFO:Preloading libraries
2023-09-03 16:36:57,437:INFO:Copying training dataset
2023-09-03 16:36:57,437:INFO:Plot type: pipeline
2023-09-03 16:36:57,596:INFO:Visual Rendered Successfully
2023-09-03 16:36:57,801:INFO:plot_model() successfully completed......................................
2023-09-03 16:37:00,285:INFO:Initializing plot_model()
2023-09-03 16:37:00,285:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:37:00,285:INFO:Checking exceptions
2023-09-03 16:37:00,285:INFO:Preloading libraries
2023-09-03 16:37:00,285:INFO:Copying training dataset
2023-09-03 16:37:00,285:INFO:Plot type: parameter
2023-09-03 16:37:00,307:INFO:Visual Rendered Successfully
2023-09-03 16:37:00,497:INFO:plot_model() successfully completed......................................
2023-09-03 16:37:17,954:INFO:Initializing plot_model()
2023-09-03 16:37:17,954:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, system=True)
2023-09-03 16:37:17,954:INFO:Checking exceptions
2023-09-03 16:37:17,954:INFO:Preloading libraries
2023-09-03 16:37:17,963:INFO:Copying training dataset
2023-09-03 16:37:17,963:INFO:Plot type: feature_all
2023-09-03 16:37:18,003:WARNING:No coef_ found. Trying feature_importances_
2023-09-03 16:37:18,563:INFO:Visual Rendered Successfully
2023-09-03 16:37:18,729:INFO:plot_model() successfully completed......................................
2023-09-03 16:37:29,007:INFO:Initializing predict_model()
2023-09-03 16:37:29,014:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244071CE2E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000244071BCA90>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002440A19F550>)
2023-09-03 16:37:29,014:INFO:Checking exceptions
2023-09-03 16:37:29,014:INFO:Preloading libraries
2023-09-04 16:20:25,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 16:20:25,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 16:20:25,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 16:20:25,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 16:20:28,730:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-09-04 16:30:09,561:INFO:PyCaret ClassificationExperiment
2023-09-04 16:30:09,561:INFO:Logging name: EXP_01_WANDA_2023
2023-09-04 16:30:09,561:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-04 16:30:09,561:INFO:version 3.0.0.rc9
2023-09-04 16:30:09,561:INFO:Initializing setup()
2023-09-04 16:30:09,561:INFO:self.USI: 13f2
2023-09-04 16:30:09,561:INFO:self._variable_keys: {'idx', 'gpu_param', 'logging_param', 'fix_imbalance', 'pipeline', 'seed', 'data', 'target_param', 'n_jobs_param', '_available_plots', 'exp_id', 'memory', 'X_test', 'y_test', 'X', 'y', 'log_plots_param', 'fold_generator', 'fold_shuffle_param', 'y_train', 'exp_name_log', 'X_train', 'html_param', 'gpu_n_jobs_param', '_ml_usecase', 'is_multiclass', 'fold_groups_param', 'USI'}
2023-09-04 16:30:09,561:INFO:Checking environment
2023-09-04 16:30:09,561:INFO:python_version: 3.9.13
2023-09-04 16:30:09,561:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-09-04 16:30:09,561:INFO:machine: AMD64
2023-09-04 16:30:09,561:INFO:platform: Windows-10-10.0.22621-SP0
2023-09-04 16:30:09,561:INFO:Memory: svmem(total=8266518528, available=1213272064, percent=85.3, used=7053246464, free=1213272064)
2023-09-04 16:30:09,561:INFO:Physical Core: 4
2023-09-04 16:30:09,561:INFO:Logical Core: 8
2023-09-04 16:30:09,561:INFO:Checking libraries
2023-09-04 16:30:09,561:INFO:System:
2023-09-04 16:30:09,561:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-09-04 16:30:09,561:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-09-04 16:30:09,561:INFO:   machine: Windows-10-10.0.22621-SP0
2023-09-04 16:30:09,561:INFO:PyCaret required dependencies:
2023-09-04 16:30:09,565:INFO:                 pip: 22.2.2
2023-09-04 16:30:09,565:INFO:          setuptools: 63.4.1
2023-09-04 16:30:09,565:INFO:             pycaret: 3.0.0rc9
2023-09-04 16:30:09,565:INFO:             IPython: 7.31.1
2023-09-04 16:30:09,565:INFO:          ipywidgets: 7.6.5
2023-09-04 16:30:09,565:INFO:                tqdm: 4.64.1
2023-09-04 16:30:09,565:INFO:               numpy: 1.21.5
2023-09-04 16:30:09,565:INFO:              pandas: 1.4.4
2023-09-04 16:30:09,565:INFO:              jinja2: 3.0.3
2023-09-04 16:30:09,565:INFO:               scipy: 1.9.1
2023-09-04 16:30:09,565:INFO:              joblib: 1.2.0
2023-09-04 16:30:09,565:INFO:             sklearn: 1.2.2
2023-09-04 16:30:09,565:INFO:                pyod: 1.0.7
2023-09-04 16:30:09,565:INFO:            imblearn: 0.10.1
2023-09-04 16:30:09,565:INFO:   category_encoders: 2.6.0
2023-09-04 16:30:09,565:INFO:            lightgbm: 3.3.5
2023-09-04 16:30:09,565:INFO:               numba: 0.55.1
2023-09-04 16:30:09,565:INFO:            requests: 2.28.1
2023-09-04 16:30:09,565:INFO:          matplotlib: 3.5.2
2023-09-04 16:30:09,565:INFO:          scikitplot: 0.3.7
2023-09-04 16:30:09,565:INFO:         yellowbrick: 1.5
2023-09-04 16:30:09,565:INFO:              plotly: 5.16.1
2023-09-04 16:30:09,565:INFO:             kaleido: 0.2.1
2023-09-04 16:30:09,565:INFO:         statsmodels: 0.14.0
2023-09-04 16:30:09,565:INFO:              sktime: 0.16.1
2023-09-04 16:30:09,565:INFO:               tbats: 1.1.2
2023-09-04 16:30:09,565:INFO:            pmdarima: 2.0.2
2023-09-04 16:30:09,565:INFO:              psutil: 5.9.0
2023-09-04 16:30:09,565:INFO:PyCaret optional dependencies:
2023-09-04 16:30:09,588:INFO:                shap: 0.42.1
2023-09-04 16:30:09,588:INFO:           interpret: 0.4.4
2023-09-04 16:30:09,589:INFO:                umap: 0.5.3
2023-09-04 16:30:09,589:INFO:    pandas_profiling: 4.3.1
2023-09-04 16:30:09,589:INFO:  explainerdashboard: 0.4.3
2023-09-04 16:30:09,589:INFO:             autoviz: 0.1.720
2023-09-04 16:30:09,589:INFO:           fairlearn: 0.7.0
2023-09-04 16:30:09,589:INFO:             xgboost: 1.7.5
2023-09-04 16:30:09,589:INFO:            catboost: 1.2
2023-09-04 16:30:09,589:INFO:              kmodes: Not installed
2023-09-04 16:30:09,589:INFO:             mlxtend: Not installed
2023-09-04 16:30:09,589:INFO:       statsforecast: Not installed
2023-09-04 16:30:09,589:INFO:        tune_sklearn: Not installed
2023-09-04 16:30:09,589:INFO:                 ray: Not installed
2023-09-04 16:30:09,589:INFO:            hyperopt: Not installed
2023-09-04 16:30:09,589:INFO:              optuna: Not installed
2023-09-04 16:30:09,589:INFO:               skopt: Not installed
2023-09-04 16:30:09,589:INFO:              mlflow: Not installed
2023-09-04 16:30:09,589:INFO:              gradio: Not installed
2023-09-04 16:30:09,589:INFO:             fastapi: Not installed
2023-09-04 16:30:09,589:INFO:             uvicorn: Not installed
2023-09-04 16:30:09,589:INFO:              m2cgen: 0.10.0
2023-09-04 16:30:09,589:INFO:           evidently: Not installed
2023-09-04 16:30:09,589:INFO:               fugue: Not installed
2023-09-04 16:30:09,589:INFO:           streamlit: Not installed
2023-09-04 16:30:09,589:INFO:             prophet: Not installed
2023-09-04 16:30:09,589:INFO:None
2023-09-04 16:30:09,589:INFO:Set up data.
2023-09-04 16:30:09,609:INFO:Set up train/test split.
2023-09-04 16:30:09,633:INFO:Set up index.
2023-09-04 16:30:09,633:INFO:Set up folding strategy.
2023-09-04 16:30:09,634:INFO:Assigning column types.
2023-09-04 16:30:09,643:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-04 16:30:09,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-04 16:30:09,778:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 16:30:09,872:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:10,180:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:10,572:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-04 16:30:10,572:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 16:30:10,670:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:10,679:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:10,679:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-04 16:30:10,829:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 16:30:10,933:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:10,941:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:11,109:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 16:30:11,200:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:11,209:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:11,209:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-04 16:30:11,458:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:11,468:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:11,733:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:11,741:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:11,749:INFO:Preparing preprocessing pipeline...
2023-09-04 16:30:11,749:INFO:Set up simple imputation.
2023-09-04 16:30:11,760:INFO:Set up encoding of ordinal features.
2023-09-04 16:30:11,769:INFO:Set up encoding of categorical features.
2023-09-04 16:30:11,769:INFO:Set up feature normalization.
2023-09-04 16:30:12,139:INFO:Finished creating preprocessing pipeline.
2023-09-04 16:30:12,273:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-09-04 16:30:12,273:INFO:Creating final display dataframe.
2023-09-04 16:30:13,448:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               13f2
2023-09-04 16:30:13,668:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:13,669:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:13,879:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 16:30:13,888:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 16:30:13,890:INFO:setup() successfully completed in 4.33s...............
2023-09-04 16:32:37,063:INFO:Initializing get_config()
2023-09-04 16:32:37,063:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, variable=train)
2023-09-04 16:32:37,063:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-09-04 16:32:37,068:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-04 16:32:37,089:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-09-04 16:32:37,089:INFO:get_config() successfully completed......................................
2023-09-04 16:33:12,655:INFO:Initializing get_config()
2023-09-04 16:33:12,655:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, variable=test)
2023-09-04 16:33:12,655:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-09-04 16:33:12,655:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-04 16:33:12,671:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  ALVO  
196                      1.0  LEVEL_7     0  
197                      0.0  LEVEL_3     0  
198                      0.0  LEVEL_3     1  
199                      NaN  LEVEL_3     0  
200                      0.0  LEVEL_3     0  
..                       ...      ...   ...  
298                      0.0  LEVEL_7     1  
299                      0.0  LEVEL_3     0  
300                      1.0  LEVEL_3     1  
301                      0.0  LEVEL_3     1  
302                      2.0  LEVEL_7     1  

[107 rows x 14 columns]
2023-09-04 16:33:12,671:INFO:get_config() successfully completed......................................
2023-09-04 16:33:29,609:INFO:Initializing get_config()
2023-09-04 16:33:29,609:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, variable=X_train_transformed)
2023-09-04 16:33:29,680:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-09-04 16:33:29,680:INFO:get_config() successfully completed......................................
2023-09-04 16:36:10,241:INFO:Initializing compare_models()
2023-09-04 16:36:10,249:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-09-04 16:36:10,249:INFO:Checking exceptions
2023-09-04 16:36:10,258:INFO:Preparing display monitor
2023-09-04 16:36:10,350:INFO:Initializing Logistic Regression
2023-09-04 16:36:10,350:INFO:Total runtime is 0.0 minutes
2023-09-04 16:36:10,359:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:10,359:INFO:Initializing create_model()
2023-09-04 16:36:10,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:10,363:INFO:Checking exceptions
2023-09-04 16:36:10,363:INFO:Importing libraries
2023-09-04 16:36:10,363:INFO:Copying training dataset
2023-09-04 16:36:10,370:INFO:Defining folds
2023-09-04 16:36:10,370:INFO:Declaring metric variables
2023-09-04 16:36:10,380:INFO:Importing untrained model
2023-09-04 16:36:10,395:INFO:Logistic Regression Imported successfully
2023-09-04 16:36:10,410:INFO:Starting cross validation
2023-09-04 16:36:10,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:20,339:INFO:Calculating mean and std
2023-09-04 16:36:20,348:INFO:Creating metrics dataframe
2023-09-04 16:36:20,360:INFO:Uploading results into container
2023-09-04 16:36:20,360:INFO:Uploading model into container now
2023-09-04 16:36:20,363:INFO:_master_model_container: 1
2023-09-04 16:36:20,363:INFO:_display_container: 2
2023-09-04 16:36:20,363:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-04 16:36:20,368:INFO:create_model() successfully completed......................................
2023-09-04 16:36:21,921:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:21,921:INFO:Creating metrics dataframe
2023-09-04 16:36:21,945:INFO:Initializing K Neighbors Classifier
2023-09-04 16:36:21,948:INFO:Total runtime is 0.19330441157023112 minutes
2023-09-04 16:36:21,959:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:21,959:INFO:Initializing create_model()
2023-09-04 16:36:21,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:21,959:INFO:Checking exceptions
2023-09-04 16:36:21,959:INFO:Importing libraries
2023-09-04 16:36:21,959:INFO:Copying training dataset
2023-09-04 16:36:21,970:INFO:Defining folds
2023-09-04 16:36:21,970:INFO:Declaring metric variables
2023-09-04 16:36:21,979:INFO:Importing untrained model
2023-09-04 16:36:21,989:INFO:K Neighbors Classifier Imported successfully
2023-09-04 16:36:22,003:INFO:Starting cross validation
2023-09-04 16:36:22,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:24,467:INFO:Calculating mean and std
2023-09-04 16:36:24,471:INFO:Creating metrics dataframe
2023-09-04 16:36:24,478:INFO:Uploading results into container
2023-09-04 16:36:24,479:INFO:Uploading model into container now
2023-09-04 16:36:24,479:INFO:_master_model_container: 2
2023-09-04 16:36:24,479:INFO:_display_container: 2
2023-09-04 16:36:24,481:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-04 16:36:24,481:INFO:create_model() successfully completed......................................
2023-09-04 16:36:24,662:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:24,662:INFO:Creating metrics dataframe
2023-09-04 16:36:24,684:INFO:Initializing Naive Bayes
2023-09-04 16:36:24,684:INFO:Total runtime is 0.2389027992884318 minutes
2023-09-04 16:36:24,687:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:24,687:INFO:Initializing create_model()
2023-09-04 16:36:24,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:24,687:INFO:Checking exceptions
2023-09-04 16:36:24,687:INFO:Importing libraries
2023-09-04 16:36:24,687:INFO:Copying training dataset
2023-09-04 16:36:24,707:INFO:Defining folds
2023-09-04 16:36:24,707:INFO:Declaring metric variables
2023-09-04 16:36:24,719:INFO:Importing untrained model
2023-09-04 16:36:24,728:INFO:Naive Bayes Imported successfully
2023-09-04 16:36:24,747:INFO:Starting cross validation
2023-09-04 16:36:24,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:26,667:INFO:Calculating mean and std
2023-09-04 16:36:26,667:INFO:Creating metrics dataframe
2023-09-04 16:36:26,677:INFO:Uploading results into container
2023-09-04 16:36:26,680:INFO:Uploading model into container now
2023-09-04 16:36:26,680:INFO:_master_model_container: 3
2023-09-04 16:36:26,680:INFO:_display_container: 2
2023-09-04 16:36:26,680:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-04 16:36:26,680:INFO:create_model() successfully completed......................................
2023-09-04 16:36:26,826:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:26,826:INFO:Creating metrics dataframe
2023-09-04 16:36:26,850:INFO:Initializing Decision Tree Classifier
2023-09-04 16:36:26,850:INFO:Total runtime is 0.27500998973846436 minutes
2023-09-04 16:36:26,861:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:26,861:INFO:Initializing create_model()
2023-09-04 16:36:26,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:26,861:INFO:Checking exceptions
2023-09-04 16:36:26,861:INFO:Importing libraries
2023-09-04 16:36:26,861:INFO:Copying training dataset
2023-09-04 16:36:26,876:INFO:Defining folds
2023-09-04 16:36:26,877:INFO:Declaring metric variables
2023-09-04 16:36:26,886:INFO:Importing untrained model
2023-09-04 16:36:26,895:INFO:Decision Tree Classifier Imported successfully
2023-09-04 16:36:26,906:INFO:Starting cross validation
2023-09-04 16:36:26,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:29,089:INFO:Calculating mean and std
2023-09-04 16:36:29,097:INFO:Creating metrics dataframe
2023-09-04 16:36:29,106:INFO:Uploading results into container
2023-09-04 16:36:29,106:INFO:Uploading model into container now
2023-09-04 16:36:29,106:INFO:_master_model_container: 4
2023-09-04 16:36:29,106:INFO:_display_container: 2
2023-09-04 16:36:29,106:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-09-04 16:36:29,106:INFO:create_model() successfully completed......................................
2023-09-04 16:36:29,260:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:29,260:INFO:Creating metrics dataframe
2023-09-04 16:36:29,293:INFO:Initializing SVM - Linear Kernel
2023-09-04 16:36:29,293:INFO:Total runtime is 0.3157127817471822 minutes
2023-09-04 16:36:29,301:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:29,301:INFO:Initializing create_model()
2023-09-04 16:36:29,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:29,301:INFO:Checking exceptions
2023-09-04 16:36:29,301:INFO:Importing libraries
2023-09-04 16:36:29,301:INFO:Copying training dataset
2023-09-04 16:36:29,316:INFO:Defining folds
2023-09-04 16:36:29,317:INFO:Declaring metric variables
2023-09-04 16:36:29,327:INFO:Importing untrained model
2023-09-04 16:36:29,336:INFO:SVM - Linear Kernel Imported successfully
2023-09-04 16:36:29,356:INFO:Starting cross validation
2023-09-04 16:36:29,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:31,337:INFO:Calculating mean and std
2023-09-04 16:36:31,337:INFO:Creating metrics dataframe
2023-09-04 16:36:31,350:INFO:Uploading results into container
2023-09-04 16:36:31,352:INFO:Uploading model into container now
2023-09-04 16:36:31,352:INFO:_master_model_container: 5
2023-09-04 16:36:31,352:INFO:_display_container: 2
2023-09-04 16:36:31,352:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-04 16:36:31,352:INFO:create_model() successfully completed......................................
2023-09-04 16:36:31,510:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:31,510:INFO:Creating metrics dataframe
2023-09-04 16:36:31,535:INFO:Initializing Ridge Classifier
2023-09-04 16:36:31,535:INFO:Total runtime is 0.35309451818466187 minutes
2023-09-04 16:36:31,550:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:31,551:INFO:Initializing create_model()
2023-09-04 16:36:31,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:31,551:INFO:Checking exceptions
2023-09-04 16:36:31,551:INFO:Importing libraries
2023-09-04 16:36:31,551:INFO:Copying training dataset
2023-09-04 16:36:31,566:INFO:Defining folds
2023-09-04 16:36:31,566:INFO:Declaring metric variables
2023-09-04 16:36:31,583:INFO:Importing untrained model
2023-09-04 16:36:31,591:INFO:Ridge Classifier Imported successfully
2023-09-04 16:36:31,608:INFO:Starting cross validation
2023-09-04 16:36:31,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:33,626:INFO:Calculating mean and std
2023-09-04 16:36:33,630:INFO:Creating metrics dataframe
2023-09-04 16:36:33,638:INFO:Uploading results into container
2023-09-04 16:36:33,638:INFO:Uploading model into container now
2023-09-04 16:36:33,638:INFO:_master_model_container: 6
2023-09-04 16:36:33,638:INFO:_display_container: 2
2023-09-04 16:36:33,645:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1935, solver='auto',
                tol=0.0001)
2023-09-04 16:36:33,646:INFO:create_model() successfully completed......................................
2023-09-04 16:36:33,796:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:33,796:INFO:Creating metrics dataframe
2023-09-04 16:36:33,821:INFO:Initializing Random Forest Classifier
2023-09-04 16:36:33,825:INFO:Total runtime is 0.3912481864293416 minutes
2023-09-04 16:36:33,835:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:33,836:INFO:Initializing create_model()
2023-09-04 16:36:33,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:33,837:INFO:Checking exceptions
2023-09-04 16:36:33,837:INFO:Importing libraries
2023-09-04 16:36:33,837:INFO:Copying training dataset
2023-09-04 16:36:33,846:INFO:Defining folds
2023-09-04 16:36:33,846:INFO:Declaring metric variables
2023-09-04 16:36:33,857:INFO:Importing untrained model
2023-09-04 16:36:33,866:INFO:Random Forest Classifier Imported successfully
2023-09-04 16:36:33,877:INFO:Starting cross validation
2023-09-04 16:36:33,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:36,395:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:36,408:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:36,505:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:36,525:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:36,745:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:36,830:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:39,516:INFO:Calculating mean and std
2023-09-04 16:36:39,519:INFO:Creating metrics dataframe
2023-09-04 16:36:39,527:INFO:Uploading results into container
2023-09-04 16:36:39,527:INFO:Uploading model into container now
2023-09-04 16:36:39,527:INFO:_master_model_container: 7
2023-09-04 16:36:39,527:INFO:_display_container: 2
2023-09-04 16:36:39,536:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 16:36:39,536:INFO:create_model() successfully completed......................................
2023-09-04 16:36:39,757:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:39,757:INFO:Creating metrics dataframe
2023-09-04 16:36:39,796:INFO:Initializing Quadratic Discriminant Analysis
2023-09-04 16:36:39,798:INFO:Total runtime is 0.4907675862312317 minutes
2023-09-04 16:36:39,808:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:39,808:INFO:Initializing create_model()
2023-09-04 16:36:39,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:39,812:INFO:Checking exceptions
2023-09-04 16:36:39,812:INFO:Importing libraries
2023-09-04 16:36:39,812:INFO:Copying training dataset
2023-09-04 16:36:39,827:INFO:Defining folds
2023-09-04 16:36:39,827:INFO:Declaring metric variables
2023-09-04 16:36:39,836:INFO:Importing untrained model
2023-09-04 16:36:39,847:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-04 16:36:39,867:INFO:Starting cross validation
2023-09-04 16:36:39,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:40,452:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:40,457:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:40,458:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:40,460:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:40,490:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:40,516:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:40,540:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:40,572:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:41,564:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:41,747:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 16:36:42,307:INFO:Calculating mean and std
2023-09-04 16:36:42,309:INFO:Creating metrics dataframe
2023-09-04 16:36:42,318:INFO:Uploading results into container
2023-09-04 16:36:42,318:INFO:Uploading model into container now
2023-09-04 16:36:42,325:INFO:_master_model_container: 8
2023-09-04 16:36:42,326:INFO:_display_container: 2
2023-09-04 16:36:42,326:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-04 16:36:42,327:INFO:create_model() successfully completed......................................
2023-09-04 16:36:42,517:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:42,517:INFO:Creating metrics dataframe
2023-09-04 16:36:42,548:INFO:Initializing Ada Boost Classifier
2023-09-04 16:36:42,555:INFO:Total runtime is 0.5367534557978312 minutes
2023-09-04 16:36:42,557:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:42,565:INFO:Initializing create_model()
2023-09-04 16:36:42,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:42,566:INFO:Checking exceptions
2023-09-04 16:36:42,566:INFO:Importing libraries
2023-09-04 16:36:42,566:INFO:Copying training dataset
2023-09-04 16:36:42,577:INFO:Defining folds
2023-09-04 16:36:42,577:INFO:Declaring metric variables
2023-09-04 16:36:42,589:INFO:Importing untrained model
2023-09-04 16:36:42,597:INFO:Ada Boost Classifier Imported successfully
2023-09-04 16:36:42,621:INFO:Starting cross validation
2023-09-04 16:36:42,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:46,717:INFO:Calculating mean and std
2023-09-04 16:36:46,717:INFO:Creating metrics dataframe
2023-09-04 16:36:46,730:INFO:Uploading results into container
2023-09-04 16:36:46,730:INFO:Uploading model into container now
2023-09-04 16:36:46,733:INFO:_master_model_container: 9
2023-09-04 16:36:46,733:INFO:_display_container: 2
2023-09-04 16:36:46,735:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1935)
2023-09-04 16:36:46,735:INFO:create_model() successfully completed......................................
2023-09-04 16:36:46,887:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:46,887:INFO:Creating metrics dataframe
2023-09-04 16:36:46,916:INFO:Initializing Gradient Boosting Classifier
2023-09-04 16:36:46,916:INFO:Total runtime is 0.6094295303026834 minutes
2023-09-04 16:36:46,932:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:46,932:INFO:Initializing create_model()
2023-09-04 16:36:46,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:46,932:INFO:Checking exceptions
2023-09-04 16:36:46,932:INFO:Importing libraries
2023-09-04 16:36:46,932:INFO:Copying training dataset
2023-09-04 16:36:46,949:INFO:Defining folds
2023-09-04 16:36:46,949:INFO:Declaring metric variables
2023-09-04 16:36:46,957:INFO:Importing untrained model
2023-09-04 16:36:46,965:INFO:Gradient Boosting Classifier Imported successfully
2023-09-04 16:36:46,989:INFO:Starting cross validation
2023-09-04 16:36:46,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:51,370:INFO:Calculating mean and std
2023-09-04 16:36:51,376:INFO:Creating metrics dataframe
2023-09-04 16:36:51,387:INFO:Uploading results into container
2023-09-04 16:36:51,387:INFO:Uploading model into container now
2023-09-04 16:36:51,387:INFO:_master_model_container: 10
2023-09-04 16:36:51,387:INFO:_display_container: 2
2023-09-04 16:36:51,387:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-04 16:36:51,387:INFO:create_model() successfully completed......................................
2023-09-04 16:36:51,576:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:51,576:INFO:Creating metrics dataframe
2023-09-04 16:36:51,618:INFO:Initializing Linear Discriminant Analysis
2023-09-04 16:36:51,618:INFO:Total runtime is 0.6877995053927103 minutes
2023-09-04 16:36:51,627:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:51,627:INFO:Initializing create_model()
2023-09-04 16:36:51,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:51,627:INFO:Checking exceptions
2023-09-04 16:36:51,634:INFO:Importing libraries
2023-09-04 16:36:51,634:INFO:Copying training dataset
2023-09-04 16:36:51,646:INFO:Defining folds
2023-09-04 16:36:51,646:INFO:Declaring metric variables
2023-09-04 16:36:51,656:INFO:Importing untrained model
2023-09-04 16:36:51,667:INFO:Linear Discriminant Analysis Imported successfully
2023-09-04 16:36:51,687:INFO:Starting cross validation
2023-09-04 16:36:51,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:54,076:INFO:Calculating mean and std
2023-09-04 16:36:54,077:INFO:Creating metrics dataframe
2023-09-04 16:36:54,089:INFO:Uploading results into container
2023-09-04 16:36:54,089:INFO:Uploading model into container now
2023-09-04 16:36:54,089:INFO:_master_model_container: 11
2023-09-04 16:36:54,089:INFO:_display_container: 2
2023-09-04 16:36:54,089:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-04 16:36:54,089:INFO:create_model() successfully completed......................................
2023-09-04 16:36:54,256:INFO:SubProcess create_model() end ==================================
2023-09-04 16:36:54,256:INFO:Creating metrics dataframe
2023-09-04 16:36:54,296:INFO:Initializing Extra Trees Classifier
2023-09-04 16:36:54,296:INFO:Total runtime is 0.7324297467867532 minutes
2023-09-04 16:36:54,306:INFO:SubProcess create_model() called ==================================
2023-09-04 16:36:54,306:INFO:Initializing create_model()
2023-09-04 16:36:54,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:36:54,310:INFO:Checking exceptions
2023-09-04 16:36:54,310:INFO:Importing libraries
2023-09-04 16:36:54,310:INFO:Copying training dataset
2023-09-04 16:36:54,326:INFO:Defining folds
2023-09-04 16:36:54,326:INFO:Declaring metric variables
2023-09-04 16:36:54,335:INFO:Importing untrained model
2023-09-04 16:36:54,346:INFO:Extra Trees Classifier Imported successfully
2023-09-04 16:36:54,366:INFO:Starting cross validation
2023-09-04 16:36:54,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:36:56,977:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:56,977:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:56,985:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:57,297:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:57,361:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:57,394:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 16:36:59,986:INFO:Calculating mean and std
2023-09-04 16:36:59,987:INFO:Creating metrics dataframe
2023-09-04 16:36:59,996:INFO:Uploading results into container
2023-09-04 16:37:00,000:INFO:Uploading model into container now
2023-09-04 16:37:00,000:INFO:_master_model_container: 12
2023-09-04 16:37:00,000:INFO:_display_container: 2
2023-09-04 16:37:00,005:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-09-04 16:37:00,005:INFO:create_model() successfully completed......................................
2023-09-04 16:37:00,177:INFO:SubProcess create_model() end ==================================
2023-09-04 16:37:00,177:INFO:Creating metrics dataframe
2023-09-04 16:37:00,206:INFO:Initializing Extreme Gradient Boosting
2023-09-04 16:37:00,206:INFO:Total runtime is 0.8309343020121255 minutes
2023-09-04 16:37:00,222:INFO:SubProcess create_model() called ==================================
2023-09-04 16:37:00,222:INFO:Initializing create_model()
2023-09-04 16:37:00,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:37:00,222:INFO:Checking exceptions
2023-09-04 16:37:00,222:INFO:Importing libraries
2023-09-04 16:37:00,222:INFO:Copying training dataset
2023-09-04 16:37:00,238:INFO:Defining folds
2023-09-04 16:37:00,238:INFO:Declaring metric variables
2023-09-04 16:37:00,256:INFO:Importing untrained model
2023-09-04 16:37:00,267:INFO:Extreme Gradient Boosting Imported successfully
2023-09-04 16:37:00,286:INFO:Starting cross validation
2023-09-04 16:37:00,287:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:37:02,936:INFO:Calculating mean and std
2023-09-04 16:37:02,939:INFO:Creating metrics dataframe
2023-09-04 16:37:02,947:INFO:Uploading results into container
2023-09-04 16:37:02,947:INFO:Uploading model into container now
2023-09-04 16:37:02,947:INFO:_master_model_container: 13
2023-09-04 16:37:02,947:INFO:_display_container: 2
2023-09-04 16:37:02,956:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-04 16:37:02,956:INFO:create_model() successfully completed......................................
2023-09-04 16:37:03,127:INFO:SubProcess create_model() end ==================================
2023-09-04 16:37:03,127:INFO:Creating metrics dataframe
2023-09-04 16:37:03,168:INFO:Initializing Light Gradient Boosting Machine
2023-09-04 16:37:03,168:INFO:Total runtime is 0.8803092797597247 minutes
2023-09-04 16:37:03,177:INFO:SubProcess create_model() called ==================================
2023-09-04 16:37:03,177:INFO:Initializing create_model()
2023-09-04 16:37:03,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:37:03,177:INFO:Checking exceptions
2023-09-04 16:37:03,177:INFO:Importing libraries
2023-09-04 16:37:03,177:INFO:Copying training dataset
2023-09-04 16:37:03,194:INFO:Defining folds
2023-09-04 16:37:03,194:INFO:Declaring metric variables
2023-09-04 16:37:03,202:INFO:Importing untrained model
2023-09-04 16:37:03,215:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-04 16:37:03,236:INFO:Starting cross validation
2023-09-04 16:37:03,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:37:06,003:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(

2023-09-04 16:37:06,042:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(

2023-09-04 16:37:07,920:INFO:Calculating mean and std
2023-09-04 16:37:07,925:INFO:Creating metrics dataframe
2023-09-04 16:37:07,931:INFO:Uploading results into container
2023-09-04 16:37:07,936:INFO:Uploading model into container now
2023-09-04 16:37:07,936:INFO:_master_model_container: 14
2023-09-04 16:37:07,936:INFO:_display_container: 2
2023-09-04 16:37:07,939:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-09-04 16:37:07,939:INFO:create_model() successfully completed......................................
2023-09-04 16:37:08,110:INFO:SubProcess create_model() end ==================================
2023-09-04 16:37:08,110:INFO:Creating metrics dataframe
2023-09-04 16:37:08,157:INFO:Initializing CatBoost Classifier
2023-09-04 16:37:08,160:INFO:Total runtime is 0.9635024150212603 minutes
2023-09-04 16:37:08,168:INFO:SubProcess create_model() called ==================================
2023-09-04 16:37:08,168:INFO:Initializing create_model()
2023-09-04 16:37:08,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:37:08,168:INFO:Checking exceptions
2023-09-04 16:37:08,168:INFO:Importing libraries
2023-09-04 16:37:08,168:INFO:Copying training dataset
2023-09-04 16:37:08,177:INFO:Defining folds
2023-09-04 16:37:08,184:INFO:Declaring metric variables
2023-09-04 16:37:08,196:INFO:Importing untrained model
2023-09-04 16:37:08,225:INFO:CatBoost Classifier Imported successfully
2023-09-04 16:37:08,247:INFO:Starting cross validation
2023-09-04 16:37:08,251:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:37:11,697:INFO:Calculating mean and std
2023-09-04 16:37:11,702:INFO:Creating metrics dataframe
2023-09-04 16:37:11,710:INFO:Uploading results into container
2023-09-04 16:37:11,710:INFO:Uploading model into container now
2023-09-04 16:37:11,710:INFO:_master_model_container: 15
2023-09-04 16:37:11,710:INFO:_display_container: 2
2023-09-04 16:37:11,710:INFO:<catboost.core.CatBoostClassifier object at 0x000001F119199880>
2023-09-04 16:37:11,716:INFO:create_model() successfully completed......................................
2023-09-04 16:37:11,940:INFO:SubProcess create_model() end ==================================
2023-09-04 16:37:11,940:INFO:Creating metrics dataframe
2023-09-04 16:37:11,995:INFO:Initializing Dummy Classifier
2023-09-04 16:37:11,995:INFO:Total runtime is 1.027417457103729 minutes
2023-09-04 16:37:12,006:INFO:SubProcess create_model() called ==================================
2023-09-04 16:37:12,006:INFO:Initializing create_model()
2023-09-04 16:37:12,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F118B50C10>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:37:12,006:INFO:Checking exceptions
2023-09-04 16:37:12,006:INFO:Importing libraries
2023-09-04 16:37:12,006:INFO:Copying training dataset
2023-09-04 16:37:12,022:INFO:Defining folds
2023-09-04 16:37:12,022:INFO:Declaring metric variables
2023-09-04 16:37:12,030:INFO:Importing untrained model
2023-09-04 16:37:12,038:INFO:Dummy Classifier Imported successfully
2023-09-04 16:37:12,056:INFO:Starting cross validation
2023-09-04 16:37:12,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 16:37:13,318:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:13,318:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:13,318:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:13,398:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:13,479:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:13,488:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:13,505:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:13,529:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:14,308:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:14,341:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 16:37:14,349:INFO:Calculating mean and std
2023-09-04 16:37:14,356:INFO:Creating metrics dataframe
2023-09-04 16:37:14,358:INFO:Uploading results into container
2023-09-04 16:37:14,366:INFO:Uploading model into container now
2023-09-04 16:37:14,367:INFO:_master_model_container: 16
2023-09-04 16:37:14,367:INFO:_display_container: 2
2023-09-04 16:37:14,367:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-09-04 16:37:14,367:INFO:create_model() successfully completed......................................
2023-09-04 16:37:14,530:INFO:SubProcess create_model() end ==================================
2023-09-04 16:37:14,530:INFO:Creating metrics dataframe
2023-09-04 16:37:14,605:INFO:Initializing create_model()
2023-09-04 16:37:14,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F118B50E50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-04 16:37:14,605:INFO:Checking exceptions
2023-09-04 16:37:14,616:INFO:Importing libraries
2023-09-04 16:37:14,616:INFO:Copying training dataset
2023-09-04 16:37:14,626:INFO:Defining folds
2023-09-04 16:37:14,626:INFO:Declaring metric variables
2023-09-04 16:37:14,626:INFO:Importing untrained model
2023-09-04 16:37:14,626:INFO:Declaring custom model
2023-09-04 16:37:14,628:INFO:Random Forest Classifier Imported successfully
2023-09-04 16:37:14,629:INFO:Cross validation set to False
2023-09-04 16:37:14,629:INFO:Fitting Model
2023-09-04 16:37:15,869:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 16:37:15,875:INFO:create_model() successfully completed......................................
2023-09-04 16:37:16,085:INFO:_master_model_container: 16
2023-09-04 16:37:16,086:INFO:_display_container: 2
2023-09-04 16:37:16,086:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 16:37:16,086:INFO:compare_models() successfully completed......................................
2023-09-04 21:37:38,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 21:37:38,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 21:37:38,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 21:37:38,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-04 21:37:41,407:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-09-04 21:47:08,422:INFO:PyCaret ClassificationExperiment
2023-09-04 21:47:08,426:INFO:Logging name: EXP_01_WANDA_2023
2023-09-04 21:47:08,426:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-04 21:47:08,426:INFO:version 3.0.0.rc9
2023-09-04 21:47:08,426:INFO:Initializing setup()
2023-09-04 21:47:08,427:INFO:self.USI: 0c7a
2023-09-04 21:47:08,427:INFO:self._variable_keys: {'exp_name_log', 'gpu_param', 'y_train', 'y', 'log_plots_param', '_available_plots', 'html_param', 'fold_shuffle_param', 'fold_generator', 'idx', 'gpu_n_jobs_param', 'X', 'memory', 'X_train', 'exp_id', 'USI', 'data', 'target_param', 'fold_groups_param', 'pipeline', 'is_multiclass', 'fix_imbalance', 'X_test', 'logging_param', 'n_jobs_param', 'seed', '_ml_usecase', 'y_test'}
2023-09-04 21:47:08,427:INFO:Checking environment
2023-09-04 21:47:08,427:INFO:python_version: 3.9.13
2023-09-04 21:47:08,427:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-09-04 21:47:08,427:INFO:machine: AMD64
2023-09-04 21:47:08,427:INFO:platform: Windows-10-10.0.22621-SP0
2023-09-04 21:47:08,427:INFO:Memory: svmem(total=8266518528, available=1114918912, percent=86.5, used=7151599616, free=1114918912)
2023-09-04 21:47:08,427:INFO:Physical Core: 4
2023-09-04 21:47:08,427:INFO:Logical Core: 8
2023-09-04 21:47:08,427:INFO:Checking libraries
2023-09-04 21:47:08,427:INFO:System:
2023-09-04 21:47:08,427:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-09-04 21:47:08,427:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-09-04 21:47:08,427:INFO:   machine: Windows-10-10.0.22621-SP0
2023-09-04 21:47:08,427:INFO:PyCaret required dependencies:
2023-09-04 21:47:08,427:INFO:                 pip: 22.2.2
2023-09-04 21:47:08,427:INFO:          setuptools: 63.4.1
2023-09-04 21:47:08,427:INFO:             pycaret: 3.0.0rc9
2023-09-04 21:47:08,427:INFO:             IPython: 7.31.1
2023-09-04 21:47:08,427:INFO:          ipywidgets: 7.6.5
2023-09-04 21:47:08,427:INFO:                tqdm: 4.64.1
2023-09-04 21:47:08,427:INFO:               numpy: 1.21.5
2023-09-04 21:47:08,427:INFO:              pandas: 1.4.4
2023-09-04 21:47:08,427:INFO:              jinja2: 3.0.3
2023-09-04 21:47:08,427:INFO:               scipy: 1.9.1
2023-09-04 21:47:08,435:INFO:              joblib: 1.2.0
2023-09-04 21:47:08,435:INFO:             sklearn: 1.2.2
2023-09-04 21:47:08,435:INFO:                pyod: 1.0.7
2023-09-04 21:47:08,435:INFO:            imblearn: 0.10.1
2023-09-04 21:47:08,435:INFO:   category_encoders: 2.6.0
2023-09-04 21:47:08,435:INFO:            lightgbm: 3.3.5
2023-09-04 21:47:08,435:INFO:               numba: 0.55.1
2023-09-04 21:47:08,435:INFO:            requests: 2.28.1
2023-09-04 21:47:08,435:INFO:          matplotlib: 3.5.2
2023-09-04 21:47:08,435:INFO:          scikitplot: 0.3.7
2023-09-04 21:47:08,435:INFO:         yellowbrick: 1.5
2023-09-04 21:47:08,435:INFO:              plotly: 5.16.1
2023-09-04 21:47:08,435:INFO:             kaleido: 0.2.1
2023-09-04 21:47:08,435:INFO:         statsmodels: 0.14.0
2023-09-04 21:47:08,435:INFO:              sktime: 0.16.1
2023-09-04 21:47:08,435:INFO:               tbats: 1.1.2
2023-09-04 21:47:08,435:INFO:            pmdarima: 2.0.2
2023-09-04 21:47:08,435:INFO:              psutil: 5.9.0
2023-09-04 21:47:08,435:INFO:PyCaret optional dependencies:
2023-09-04 21:47:08,458:INFO:                shap: 0.42.1
2023-09-04 21:47:08,458:INFO:           interpret: 0.4.4
2023-09-04 21:47:08,458:INFO:                umap: 0.5.3
2023-09-04 21:47:08,458:INFO:    pandas_profiling: 4.3.1
2023-09-04 21:47:08,458:INFO:  explainerdashboard: 0.4.3
2023-09-04 21:47:08,458:INFO:             autoviz: 0.1.720
2023-09-04 21:47:08,458:INFO:           fairlearn: 0.7.0
2023-09-04 21:47:08,458:INFO:             xgboost: 1.7.5
2023-09-04 21:47:08,458:INFO:            catboost: 1.2
2023-09-04 21:47:08,458:INFO:              kmodes: Not installed
2023-09-04 21:47:08,458:INFO:             mlxtend: Not installed
2023-09-04 21:47:08,458:INFO:       statsforecast: Not installed
2023-09-04 21:47:08,458:INFO:        tune_sklearn: Not installed
2023-09-04 21:47:08,458:INFO:                 ray: Not installed
2023-09-04 21:47:08,458:INFO:            hyperopt: Not installed
2023-09-04 21:47:08,458:INFO:              optuna: Not installed
2023-09-04 21:47:08,458:INFO:               skopt: Not installed
2023-09-04 21:47:08,458:INFO:              mlflow: Not installed
2023-09-04 21:47:08,458:INFO:              gradio: Not installed
2023-09-04 21:47:08,458:INFO:             fastapi: Not installed
2023-09-04 21:47:08,458:INFO:             uvicorn: Not installed
2023-09-04 21:47:08,458:INFO:              m2cgen: 0.10.0
2023-09-04 21:47:08,458:INFO:           evidently: Not installed
2023-09-04 21:47:08,458:INFO:               fugue: Not installed
2023-09-04 21:47:08,458:INFO:           streamlit: Not installed
2023-09-04 21:47:08,458:INFO:             prophet: Not installed
2023-09-04 21:47:08,458:INFO:None
2023-09-04 21:47:08,458:INFO:Set up data.
2023-09-04 21:47:08,492:INFO:Set up train/test split.
2023-09-04 21:47:08,515:INFO:Set up index.
2023-09-04 21:47:08,515:INFO:Set up folding strategy.
2023-09-04 21:47:08,515:INFO:Assigning column types.
2023-09-04 21:47:08,523:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-04 21:47:08,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-04 21:47:08,659:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 21:47:08,764:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:09,076:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:09,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-04 21:47:09,439:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 21:47:09,513:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:09,521:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:09,529:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-04 21:47:09,658:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 21:47:09,738:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:09,746:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:09,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-04 21:47:09,954:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:09,962:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:09,962:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-04 21:47:10,187:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:10,194:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:10,403:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:10,411:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:10,427:INFO:Preparing preprocessing pipeline...
2023-09-04 21:47:10,435:INFO:Set up simple imputation.
2023-09-04 21:47:10,443:INFO:Set up encoding of ordinal features.
2023-09-04 21:47:10,451:INFO:Set up encoding of categorical features.
2023-09-04 21:47:10,451:INFO:Set up feature normalization.
2023-09-04 21:47:10,796:INFO:Finished creating preprocessing pipeline.
2023-09-04 21:47:10,908:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-09-04 21:47:10,908:INFO:Creating final display dataframe.
2023-09-04 21:47:11,495:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               0c7a
2023-09-04 21:47:11,712:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:11,720:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:11,928:INFO:Soft dependency imported: xgboost: 1.7.5
2023-09-04 21:47:11,936:INFO:Soft dependency imported: catboost: 1.2
2023-09-04 21:47:11,936:INFO:setup() successfully completed in 3.52s...............
2023-09-04 21:47:13,340:INFO:Initializing get_config()
2023-09-04 21:47:13,340:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, variable=train)
2023-09-04 21:47:13,340:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-09-04 21:47:13,343:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-04 21:47:13,362:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-09-04 21:47:13,362:INFO:get_config() successfully completed......................................
2023-09-04 21:47:24,372:INFO:Initializing get_config()
2023-09-04 21:47:24,372:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, variable=test)
2023-09-04 21:47:24,372:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-09-04 21:47:24,372:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-09-04 21:47:24,389:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  ALVO  
196                      1.0  LEVEL_7     0  
197                      0.0  LEVEL_3     0  
198                      0.0  LEVEL_3     1  
199                      NaN  LEVEL_3     0  
200                      0.0  LEVEL_3     0  
..                       ...      ...   ...  
298                      0.0  LEVEL_7     1  
299                      0.0  LEVEL_3     0  
300                      1.0  LEVEL_3     1  
301                      0.0  LEVEL_3     1  
302                      2.0  LEVEL_7     1  

[107 rows x 14 columns]
2023-09-04 21:47:24,389:INFO:get_config() successfully completed......................................
2023-09-04 21:48:08,117:INFO:Initializing get_config()
2023-09-04 21:48:08,117:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, variable=X_train_transformed)
2023-09-04 21:48:08,197:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-09-04 21:48:08,197:INFO:get_config() successfully completed......................................
2023-09-04 21:48:51,083:INFO:Initializing compare_models()
2023-09-04 21:48:51,088:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-09-04 21:48:51,088:INFO:Checking exceptions
2023-09-04 21:48:51,091:INFO:Preparing display monitor
2023-09-04 21:48:51,176:INFO:Initializing Logistic Regression
2023-09-04 21:48:51,176:INFO:Total runtime is 0.0 minutes
2023-09-04 21:48:51,181:INFO:SubProcess create_model() called ==================================
2023-09-04 21:48:51,181:INFO:Initializing create_model()
2023-09-04 21:48:51,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:48:51,181:INFO:Checking exceptions
2023-09-04 21:48:51,181:INFO:Importing libraries
2023-09-04 21:48:51,181:INFO:Copying training dataset
2023-09-04 21:48:51,205:INFO:Defining folds
2023-09-04 21:48:51,205:INFO:Declaring metric variables
2023-09-04 21:48:51,213:INFO:Importing untrained model
2023-09-04 21:48:51,221:INFO:Logistic Regression Imported successfully
2023-09-04 21:48:51,237:INFO:Starting cross validation
2023-09-04 21:48:51,245:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:00,805:INFO:Calculating mean and std
2023-09-04 21:49:00,821:INFO:Creating metrics dataframe
2023-09-04 21:49:00,832:INFO:Uploading results into container
2023-09-04 21:49:00,832:INFO:Uploading model into container now
2023-09-04 21:49:00,837:INFO:_master_model_container: 1
2023-09-04 21:49:00,837:INFO:_display_container: 2
2023-09-04 21:49:00,837:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-04 21:49:00,837:INFO:create_model() successfully completed......................................
2023-09-04 21:49:02,598:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:02,598:INFO:Creating metrics dataframe
2023-09-04 21:49:02,614:INFO:Initializing K Neighbors Classifier
2023-09-04 21:49:02,614:INFO:Total runtime is 0.19064580996831257 minutes
2023-09-04 21:49:02,623:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:02,623:INFO:Initializing create_model()
2023-09-04 21:49:02,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:02,627:INFO:Checking exceptions
2023-09-04 21:49:02,627:INFO:Importing libraries
2023-09-04 21:49:02,627:INFO:Copying training dataset
2023-09-04 21:49:02,639:INFO:Defining folds
2023-09-04 21:49:02,639:INFO:Declaring metric variables
2023-09-04 21:49:02,647:INFO:Importing untrained model
2023-09-04 21:49:02,655:INFO:K Neighbors Classifier Imported successfully
2023-09-04 21:49:02,672:INFO:Starting cross validation
2023-09-04 21:49:02,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:04,555:INFO:Calculating mean and std
2023-09-04 21:49:04,555:INFO:Creating metrics dataframe
2023-09-04 21:49:04,567:INFO:Uploading results into container
2023-09-04 21:49:04,572:INFO:Uploading model into container now
2023-09-04 21:49:04,572:INFO:_master_model_container: 2
2023-09-04 21:49:04,572:INFO:_display_container: 2
2023-09-04 21:49:04,572:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-04 21:49:04,572:INFO:create_model() successfully completed......................................
2023-09-04 21:49:04,732:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:04,732:INFO:Creating metrics dataframe
2023-09-04 21:49:04,755:INFO:Initializing Naive Bayes
2023-09-04 21:49:04,755:INFO:Total runtime is 0.22631514867146807 minutes
2023-09-04 21:49:04,763:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:04,763:INFO:Initializing create_model()
2023-09-04 21:49:04,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:04,763:INFO:Checking exceptions
2023-09-04 21:49:04,763:INFO:Importing libraries
2023-09-04 21:49:04,763:INFO:Copying training dataset
2023-09-04 21:49:04,782:INFO:Defining folds
2023-09-04 21:49:04,782:INFO:Declaring metric variables
2023-09-04 21:49:04,792:INFO:Importing untrained model
2023-09-04 21:49:04,796:INFO:Naive Bayes Imported successfully
2023-09-04 21:49:04,813:INFO:Starting cross validation
2023-09-04 21:49:04,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:06,272:INFO:Calculating mean and std
2023-09-04 21:49:06,282:INFO:Creating metrics dataframe
2023-09-04 21:49:06,282:INFO:Uploading results into container
2023-09-04 21:49:06,282:INFO:Uploading model into container now
2023-09-04 21:49:06,288:INFO:_master_model_container: 3
2023-09-04 21:49:06,288:INFO:_display_container: 2
2023-09-04 21:49:06,289:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-04 21:49:06,289:INFO:create_model() successfully completed......................................
2023-09-04 21:49:06,421:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:06,421:INFO:Creating metrics dataframe
2023-09-04 21:49:06,452:INFO:Initializing Decision Tree Classifier
2023-09-04 21:49:06,452:INFO:Total runtime is 0.25460542837778727 minutes
2023-09-04 21:49:06,454:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:06,462:INFO:Initializing create_model()
2023-09-04 21:49:06,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:06,462:INFO:Checking exceptions
2023-09-04 21:49:06,462:INFO:Importing libraries
2023-09-04 21:49:06,462:INFO:Copying training dataset
2023-09-04 21:49:06,472:INFO:Defining folds
2023-09-04 21:49:06,478:INFO:Declaring metric variables
2023-09-04 21:49:06,486:INFO:Importing untrained model
2023-09-04 21:49:06,495:INFO:Decision Tree Classifier Imported successfully
2023-09-04 21:49:06,512:INFO:Starting cross validation
2023-09-04 21:49:06,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:08,093:INFO:Calculating mean and std
2023-09-04 21:49:08,093:INFO:Creating metrics dataframe
2023-09-04 21:49:08,109:INFO:Uploading results into container
2023-09-04 21:49:08,112:INFO:Uploading model into container now
2023-09-04 21:49:08,112:INFO:_master_model_container: 4
2023-09-04 21:49:08,112:INFO:_display_container: 2
2023-09-04 21:49:08,112:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-09-04 21:49:08,112:INFO:create_model() successfully completed......................................
2023-09-04 21:49:08,267:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:08,267:INFO:Creating metrics dataframe
2023-09-04 21:49:08,292:INFO:Initializing SVM - Linear Kernel
2023-09-04 21:49:08,292:INFO:Total runtime is 0.2852680166562398 minutes
2023-09-04 21:49:08,301:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:08,301:INFO:Initializing create_model()
2023-09-04 21:49:08,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:08,301:INFO:Checking exceptions
2023-09-04 21:49:08,301:INFO:Importing libraries
2023-09-04 21:49:08,301:INFO:Copying training dataset
2023-09-04 21:49:08,316:INFO:Defining folds
2023-09-04 21:49:08,322:INFO:Declaring metric variables
2023-09-04 21:49:08,333:INFO:Importing untrained model
2023-09-04 21:49:08,342:INFO:SVM - Linear Kernel Imported successfully
2023-09-04 21:49:08,352:INFO:Starting cross validation
2023-09-04 21:49:08,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:09,722:INFO:Calculating mean and std
2023-09-04 21:49:09,728:INFO:Creating metrics dataframe
2023-09-04 21:49:09,737:INFO:Uploading results into container
2023-09-04 21:49:09,737:INFO:Uploading model into container now
2023-09-04 21:49:09,737:INFO:_master_model_container: 5
2023-09-04 21:49:09,737:INFO:_display_container: 2
2023-09-04 21:49:09,742:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-04 21:49:09,742:INFO:create_model() successfully completed......................................
2023-09-04 21:49:09,895:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:09,895:INFO:Creating metrics dataframe
2023-09-04 21:49:09,922:INFO:Initializing Ridge Classifier
2023-09-04 21:49:09,922:INFO:Total runtime is 0.31243118445078527 minutes
2023-09-04 21:49:09,931:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:09,931:INFO:Initializing create_model()
2023-09-04 21:49:09,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:09,931:INFO:Checking exceptions
2023-09-04 21:49:09,931:INFO:Importing libraries
2023-09-04 21:49:09,931:INFO:Copying training dataset
2023-09-04 21:49:09,945:INFO:Defining folds
2023-09-04 21:49:09,945:INFO:Declaring metric variables
2023-09-04 21:49:09,958:INFO:Importing untrained model
2023-09-04 21:49:09,962:INFO:Ridge Classifier Imported successfully
2023-09-04 21:49:09,982:INFO:Starting cross validation
2023-09-04 21:49:09,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:11,295:INFO:Calculating mean and std
2023-09-04 21:49:11,295:INFO:Creating metrics dataframe
2023-09-04 21:49:11,304:INFO:Uploading results into container
2023-09-04 21:49:11,312:INFO:Uploading model into container now
2023-09-04 21:49:11,312:INFO:_master_model_container: 6
2023-09-04 21:49:11,312:INFO:_display_container: 2
2023-09-04 21:49:11,312:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1935, solver='auto',
                tol=0.0001)
2023-09-04 21:49:11,312:INFO:create_model() successfully completed......................................
2023-09-04 21:49:11,462:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:11,462:INFO:Creating metrics dataframe
2023-09-04 21:49:11,495:INFO:Initializing Random Forest Classifier
2023-09-04 21:49:11,495:INFO:Total runtime is 0.33865031003952023 minutes
2023-09-04 21:49:11,503:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:11,503:INFO:Initializing create_model()
2023-09-04 21:49:11,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:11,503:INFO:Checking exceptions
2023-09-04 21:49:11,503:INFO:Importing libraries
2023-09-04 21:49:11,503:INFO:Copying training dataset
2023-09-04 21:49:11,520:INFO:Defining folds
2023-09-04 21:49:11,522:INFO:Declaring metric variables
2023-09-04 21:49:11,528:INFO:Importing untrained model
2023-09-04 21:49:11,541:INFO:Random Forest Classifier Imported successfully
2023-09-04 21:49:11,559:INFO:Starting cross validation
2023-09-04 21:49:11,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:14,238:INFO:Calculating mean and std
2023-09-04 21:49:14,242:INFO:Creating metrics dataframe
2023-09-04 21:49:14,252:INFO:Uploading results into container
2023-09-04 21:49:14,252:INFO:Uploading model into container now
2023-09-04 21:49:14,252:INFO:_master_model_container: 7
2023-09-04 21:49:14,255:INFO:_display_container: 2
2023-09-04 21:49:14,255:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 21:49:14,255:INFO:create_model() successfully completed......................................
2023-09-04 21:49:14,412:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:14,412:INFO:Creating metrics dataframe
2023-09-04 21:49:14,437:INFO:Initializing Quadratic Discriminant Analysis
2023-09-04 21:49:14,437:INFO:Total runtime is 0.3876828551292419 minutes
2023-09-04 21:49:14,445:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:14,445:INFO:Initializing create_model()
2023-09-04 21:49:14,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:14,445:INFO:Checking exceptions
2023-09-04 21:49:14,452:INFO:Importing libraries
2023-09-04 21:49:14,452:INFO:Copying training dataset
2023-09-04 21:49:14,462:INFO:Defining folds
2023-09-04 21:49:14,462:INFO:Declaring metric variables
2023-09-04 21:49:14,472:INFO:Importing untrained model
2023-09-04 21:49:14,482:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-04 21:49:14,493:INFO:Starting cross validation
2023-09-04 21:49:14,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:14,963:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:14,963:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:14,965:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:14,973:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:14,992:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:15,002:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:15,014:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:15,472:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:15,472:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-09-04 21:49:15,995:INFO:Calculating mean and std
2023-09-04 21:49:15,999:INFO:Creating metrics dataframe
2023-09-04 21:49:16,006:INFO:Uploading results into container
2023-09-04 21:49:16,006:INFO:Uploading model into container now
2023-09-04 21:49:16,006:INFO:_master_model_container: 8
2023-09-04 21:49:16,006:INFO:_display_container: 2
2023-09-04 21:49:16,006:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-04 21:49:16,006:INFO:create_model() successfully completed......................................
2023-09-04 21:49:16,155:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:16,159:INFO:Creating metrics dataframe
2023-09-04 21:49:16,194:INFO:Initializing Ada Boost Classifier
2023-09-04 21:49:16,194:INFO:Total runtime is 0.41696673631668085 minutes
2023-09-04 21:49:16,204:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:16,204:INFO:Initializing create_model()
2023-09-04 21:49:16,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:16,204:INFO:Checking exceptions
2023-09-04 21:49:16,204:INFO:Importing libraries
2023-09-04 21:49:16,204:INFO:Copying training dataset
2023-09-04 21:49:16,220:INFO:Defining folds
2023-09-04 21:49:16,222:INFO:Declaring metric variables
2023-09-04 21:49:16,233:INFO:Importing untrained model
2023-09-04 21:49:16,242:INFO:Ada Boost Classifier Imported successfully
2023-09-04 21:49:16,262:INFO:Starting cross validation
2023-09-04 21:49:16,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:17,894:INFO:Calculating mean and std
2023-09-04 21:49:17,894:INFO:Creating metrics dataframe
2023-09-04 21:49:17,903:INFO:Uploading results into container
2023-09-04 21:49:17,903:INFO:Uploading model into container now
2023-09-04 21:49:17,903:INFO:_master_model_container: 9
2023-09-04 21:49:17,903:INFO:_display_container: 2
2023-09-04 21:49:17,903:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1935)
2023-09-04 21:49:17,903:INFO:create_model() successfully completed......................................
2023-09-04 21:49:18,062:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:18,067:INFO:Creating metrics dataframe
2023-09-04 21:49:18,093:INFO:Initializing Gradient Boosting Classifier
2023-09-04 21:49:18,093:INFO:Total runtime is 0.44862931569417314 minutes
2023-09-04 21:49:18,102:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:18,102:INFO:Initializing create_model()
2023-09-04 21:49:18,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:18,102:INFO:Checking exceptions
2023-09-04 21:49:18,102:INFO:Importing libraries
2023-09-04 21:49:18,108:INFO:Copying training dataset
2023-09-04 21:49:18,116:INFO:Defining folds
2023-09-04 21:49:18,116:INFO:Declaring metric variables
2023-09-04 21:49:18,124:INFO:Importing untrained model
2023-09-04 21:49:18,133:INFO:Gradient Boosting Classifier Imported successfully
2023-09-04 21:49:18,154:INFO:Starting cross validation
2023-09-04 21:49:18,159:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:20,257:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:20,257:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:20,305:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:20,317:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:20,329:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:20,453:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:20,490:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:21,047:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 21:49:22,550:INFO:Calculating mean and std
2023-09-04 21:49:22,557:INFO:Creating metrics dataframe
2023-09-04 21:49:22,568:INFO:Uploading results into container
2023-09-04 21:49:22,568:INFO:Uploading model into container now
2023-09-04 21:49:22,568:INFO:_master_model_container: 10
2023-09-04 21:49:22,568:INFO:_display_container: 2
2023-09-04 21:49:22,574:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-04 21:49:22,574:INFO:create_model() successfully completed......................................
2023-09-04 21:49:22,748:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:22,748:INFO:Creating metrics dataframe
2023-09-04 21:49:22,781:INFO:Initializing Linear Discriminant Analysis
2023-09-04 21:49:22,781:INFO:Total runtime is 0.5267528812090555 minutes
2023-09-04 21:49:22,789:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:22,789:INFO:Initializing create_model()
2023-09-04 21:49:22,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:22,789:INFO:Checking exceptions
2023-09-04 21:49:22,789:INFO:Importing libraries
2023-09-04 21:49:22,789:INFO:Copying training dataset
2023-09-04 21:49:22,806:INFO:Defining folds
2023-09-04 21:49:22,807:INFO:Declaring metric variables
2023-09-04 21:49:22,814:INFO:Importing untrained model
2023-09-04 21:49:22,823:INFO:Linear Discriminant Analysis Imported successfully
2023-09-04 21:49:22,839:INFO:Starting cross validation
2023-09-04 21:49:22,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:24,132:INFO:Calculating mean and std
2023-09-04 21:49:24,132:INFO:Creating metrics dataframe
2023-09-04 21:49:24,146:INFO:Uploading results into container
2023-09-04 21:49:24,146:INFO:Uploading model into container now
2023-09-04 21:49:24,148:INFO:_master_model_container: 11
2023-09-04 21:49:24,148:INFO:_display_container: 2
2023-09-04 21:49:24,148:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-04 21:49:24,148:INFO:create_model() successfully completed......................................
2023-09-04 21:49:24,307:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:24,307:INFO:Creating metrics dataframe
2023-09-04 21:49:24,338:INFO:Initializing Extra Trees Classifier
2023-09-04 21:49:24,338:INFO:Total runtime is 0.5527019659678141 minutes
2023-09-04 21:49:24,347:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:24,347:INFO:Initializing create_model()
2023-09-04 21:49:24,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:24,347:INFO:Checking exceptions
2023-09-04 21:49:24,347:INFO:Importing libraries
2023-09-04 21:49:24,347:INFO:Copying training dataset
2023-09-04 21:49:24,361:INFO:Defining folds
2023-09-04 21:49:24,361:INFO:Declaring metric variables
2023-09-04 21:49:24,369:INFO:Importing untrained model
2023-09-04 21:49:24,378:INFO:Extra Trees Classifier Imported successfully
2023-09-04 21:49:24,400:INFO:Starting cross validation
2023-09-04 21:49:24,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:26,880:INFO:Calculating mean and std
2023-09-04 21:49:26,880:INFO:Creating metrics dataframe
2023-09-04 21:49:26,895:INFO:Uploading results into container
2023-09-04 21:49:26,895:INFO:Uploading model into container now
2023-09-04 21:49:26,897:INFO:_master_model_container: 12
2023-09-04 21:49:26,897:INFO:_display_container: 2
2023-09-04 21:49:26,898:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-09-04 21:49:26,898:INFO:create_model() successfully completed......................................
2023-09-04 21:49:27,044:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:27,047:INFO:Creating metrics dataframe
2023-09-04 21:49:27,077:INFO:Initializing Extreme Gradient Boosting
2023-09-04 21:49:27,077:INFO:Total runtime is 0.5983631889025369 minutes
2023-09-04 21:49:27,086:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:27,086:INFO:Initializing create_model()
2023-09-04 21:49:27,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:27,087:INFO:Checking exceptions
2023-09-04 21:49:27,087:INFO:Importing libraries
2023-09-04 21:49:27,087:INFO:Copying training dataset
2023-09-04 21:49:27,098:INFO:Defining folds
2023-09-04 21:49:27,098:INFO:Declaring metric variables
2023-09-04 21:49:27,110:INFO:Importing untrained model
2023-09-04 21:49:27,118:INFO:Extreme Gradient Boosting Imported successfully
2023-09-04 21:49:27,138:INFO:Starting cross validation
2023-09-04 21:49:27,138:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:28,467:INFO:Calculating mean and std
2023-09-04 21:49:28,467:INFO:Creating metrics dataframe
2023-09-04 21:49:28,478:INFO:Uploading results into container
2023-09-04 21:49:28,478:INFO:Uploading model into container now
2023-09-04 21:49:28,478:INFO:_master_model_container: 13
2023-09-04 21:49:28,478:INFO:_display_container: 2
2023-09-04 21:49:28,484:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-04 21:49:28,484:INFO:create_model() successfully completed......................................
2023-09-04 21:49:28,643:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:28,643:INFO:Creating metrics dataframe
2023-09-04 21:49:28,678:INFO:Initializing Light Gradient Boosting Machine
2023-09-04 21:49:28,678:INFO:Total runtime is 0.6250360846519469 minutes
2023-09-04 21:49:28,687:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:28,687:INFO:Initializing create_model()
2023-09-04 21:49:28,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:28,687:INFO:Checking exceptions
2023-09-04 21:49:28,687:INFO:Importing libraries
2023-09-04 21:49:28,687:INFO:Copying training dataset
2023-09-04 21:49:28,701:INFO:Defining folds
2023-09-04 21:49:28,701:INFO:Declaring metric variables
2023-09-04 21:49:28,709:INFO:Importing untrained model
2023-09-04 21:49:28,718:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-04 21:49:28,738:INFO:Starting cross validation
2023-09-04 21:49:28,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:32,657:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(

2023-09-04 21:49:33,040:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:
https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations
  warnings.warn(

2023-09-04 21:49:33,580:INFO:Calculating mean and std
2023-09-04 21:49:33,590:INFO:Creating metrics dataframe
2023-09-04 21:49:33,602:INFO:Uploading results into container
2023-09-04 21:49:33,602:INFO:Uploading model into container now
2023-09-04 21:49:33,605:INFO:_master_model_container: 14
2023-09-04 21:49:33,606:INFO:_display_container: 2
2023-09-04 21:49:33,607:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-09-04 21:49:33,607:INFO:create_model() successfully completed......................................
2023-09-04 21:49:33,800:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:33,803:INFO:Creating metrics dataframe
2023-09-04 21:49:33,841:INFO:Initializing CatBoost Classifier
2023-09-04 21:49:33,841:INFO:Total runtime is 0.7110870917638142 minutes
2023-09-04 21:49:33,849:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:33,849:INFO:Initializing create_model()
2023-09-04 21:49:33,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:33,849:INFO:Checking exceptions
2023-09-04 21:49:33,849:INFO:Importing libraries
2023-09-04 21:49:33,849:INFO:Copying training dataset
2023-09-04 21:49:33,868:INFO:Defining folds
2023-09-04 21:49:33,868:INFO:Declaring metric variables
2023-09-04 21:49:33,877:INFO:Importing untrained model
2023-09-04 21:49:33,898:INFO:CatBoost Classifier Imported successfully
2023-09-04 21:49:33,918:INFO:Starting cross validation
2023-09-04 21:49:33,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:37,888:INFO:Calculating mean and std
2023-09-04 21:49:37,893:INFO:Creating metrics dataframe
2023-09-04 21:49:37,903:INFO:Uploading results into container
2023-09-04 21:49:37,905:INFO:Uploading model into container now
2023-09-04 21:49:37,905:INFO:_master_model_container: 15
2023-09-04 21:49:37,905:INFO:_display_container: 2
2023-09-04 21:49:37,905:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D47B4A220>
2023-09-04 21:49:37,905:INFO:create_model() successfully completed......................................
2023-09-04 21:49:38,090:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:38,090:INFO:Creating metrics dataframe
2023-09-04 21:49:38,131:INFO:Initializing Dummy Classifier
2023-09-04 21:49:38,131:INFO:Total runtime is 0.78258083264033 minutes
2023-09-04 21:49:38,139:INFO:SubProcess create_model() called ==================================
2023-09-04 21:49:38,139:INFO:Initializing create_model()
2023-09-04 21:49:38,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47A7F1F0>, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:38,139:INFO:Checking exceptions
2023-09-04 21:49:38,139:INFO:Importing libraries
2023-09-04 21:49:38,139:INFO:Copying training dataset
2023-09-04 21:49:38,158:INFO:Defining folds
2023-09-04 21:49:38,158:INFO:Declaring metric variables
2023-09-04 21:49:38,167:INFO:Importing untrained model
2023-09-04 21:49:38,177:INFO:Dummy Classifier Imported successfully
2023-09-04 21:49:38,198:INFO:Starting cross validation
2023-09-04 21:49:38,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:49:38,892:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:38,892:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:38,898:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:38,909:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:38,950:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:38,968:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:38,987:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:39,008:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:39,362:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:39,377:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-04 21:49:39,388:INFO:Calculating mean and std
2023-09-04 21:49:39,388:INFO:Creating metrics dataframe
2023-09-04 21:49:39,398:INFO:Uploading results into container
2023-09-04 21:49:39,398:INFO:Uploading model into container now
2023-09-04 21:49:39,398:INFO:_master_model_container: 16
2023-09-04 21:49:39,398:INFO:_display_container: 2
2023-09-04 21:49:39,398:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-09-04 21:49:39,398:INFO:create_model() successfully completed......................................
2023-09-04 21:49:39,554:INFO:SubProcess create_model() end ==================================
2023-09-04 21:49:39,554:INFO:Creating metrics dataframe
2023-09-04 21:49:39,612:INFO:Initializing create_model()
2023-09-04 21:49:39,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:49:39,618:INFO:Checking exceptions
2023-09-04 21:49:39,628:INFO:Importing libraries
2023-09-04 21:49:39,628:INFO:Copying training dataset
2023-09-04 21:49:39,638:INFO:Defining folds
2023-09-04 21:49:39,638:INFO:Declaring metric variables
2023-09-04 21:49:39,638:INFO:Importing untrained model
2023-09-04 21:49:39,638:INFO:Declaring custom model
2023-09-04 21:49:39,638:INFO:Random Forest Classifier Imported successfully
2023-09-04 21:49:39,643:INFO:Cross validation set to False
2023-09-04 21:49:39,644:INFO:Fitting Model
2023-09-04 21:49:40,058:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 21:49:40,058:INFO:create_model() successfully completed......................................
2023-09-04 21:49:40,306:INFO:_master_model_container: 16
2023-09-04 21:49:40,306:INFO:_display_container: 2
2023-09-04 21:49:40,306:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 21:49:40,306:INFO:compare_models() successfully completed......................................
2023-09-04 21:52:03,855:INFO:Initializing create_model()
2023-09-04 21:52:03,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-04 21:52:03,863:INFO:Checking exceptions
2023-09-04 21:52:04,057:INFO:Importing libraries
2023-09-04 21:52:04,057:INFO:Copying training dataset
2023-09-04 21:52:04,081:INFO:Defining folds
2023-09-04 21:52:04,089:INFO:Declaring metric variables
2023-09-04 21:52:04,089:INFO:Importing untrained model
2023-09-04 21:52:04,113:INFO:CatBoost Classifier Imported successfully
2023-09-04 21:52:04,129:INFO:Starting cross validation
2023-09-04 21:52:04,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 21:52:05,666:INFO:Calculating mean and std
2023-09-04 21:52:05,666:INFO:Creating metrics dataframe
2023-09-04 21:52:05,680:INFO:Finalizing model
2023-09-04 21:52:10,969:INFO:Uploading results into container
2023-09-04 21:52:10,970:INFO:Uploading model into container now
2023-09-04 21:52:11,011:INFO:_master_model_container: 17
2023-09-04 21:52:11,011:INFO:_display_container: 3
2023-09-04 21:52:11,011:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>
2023-09-04 21:52:11,011:INFO:create_model() successfully completed......................................
2023-09-04 21:52:49,713:INFO:Initializing predict_model()
2023-09-04 21:52:49,713:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D47B321F0>)
2023-09-04 21:52:49,713:INFO:Checking exceptions
2023-09-04 21:52:49,713:INFO:Preloading libraries
2023-09-04 21:52:49,717:INFO:Set up data.
2023-09-04 21:52:49,733:INFO:Set up index.
2023-09-04 21:53:13,668:INFO:Initializing predict_model()
2023-09-04 21:53:13,668:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D479F04C0>)
2023-09-04 21:53:13,675:INFO:Checking exceptions
2023-09-04 21:53:13,675:INFO:Preloading libraries
2023-09-04 21:53:13,680:INFO:Set up data.
2023-09-04 21:53:13,693:INFO:Set up index.
2023-09-04 22:00:17,578:INFO:Initializing create_model()
2023-09-04 22:00:17,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-04 22:00:17,597:INFO:Checking exceptions
2023-09-04 22:00:17,820:INFO:Importing libraries
2023-09-04 22:00:17,828:INFO:Copying training dataset
2023-09-04 22:00:17,844:INFO:Defining folds
2023-09-04 22:00:17,844:INFO:Declaring metric variables
2023-09-04 22:00:17,852:INFO:Importing untrained model
2023-09-04 22:00:17,874:INFO:Random Forest Classifier Imported successfully
2023-09-04 22:00:17,892:INFO:Starting cross validation
2023-09-04 22:00:17,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 22:00:27,869:INFO:Calculating mean and std
2023-09-04 22:00:27,877:INFO:Creating metrics dataframe
2023-09-04 22:00:27,909:INFO:Finalizing model
2023-09-04 22:00:28,545:INFO:Uploading results into container
2023-09-04 22:00:28,545:INFO:Uploading model into container now
2023-09-04 22:00:28,617:INFO:_master_model_container: 18
2023-09-04 22:00:28,617:INFO:_display_container: 6
2023-09-04 22:00:28,617:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 22:00:28,617:INFO:create_model() successfully completed......................................
2023-09-04 22:01:28,127:INFO:Initializing predict_model()
2023-09-04 22:01:28,127:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D479F0430>)
2023-09-04 22:01:28,127:INFO:Checking exceptions
2023-09-04 22:01:28,127:INFO:Preloading libraries
2023-09-04 22:01:28,135:INFO:Set up data.
2023-09-04 22:01:28,151:INFO:Set up index.
2023-09-04 22:04:59,526:INFO:Initializing tune_model()
2023-09-04 22:04:59,537:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=None, round=4, n_iter=25, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>)
2023-09-04 22:04:59,537:INFO:Checking exceptions
2023-09-04 22:04:59,693:INFO:Copying training dataset
2023-09-04 22:04:59,696:INFO:Checking base model
2023-09-04 22:04:59,704:INFO:Base model : Random Forest Classifier
2023-09-04 22:04:59,712:INFO:Declaring metric variables
2023-09-04 22:04:59,720:INFO:Defining Hyperparameters
2023-09-04 22:05:00,065:INFO:Tuning with n_jobs=-1
2023-09-04 22:05:00,065:INFO:Initializing RandomizedSearchCV
2023-09-04 22:05:02,802:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:02,883:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:02,883:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:02,891:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:02,923:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:03,035:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:03,126:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:03,612:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:04,232:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:04,272:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:04,297:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:04,304:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:04,347:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:04,553:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:04,655:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:05,237:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:07,146:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:07,150:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:07,786:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:07,834:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:07,961:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:08,298:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:08,796:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:08,934:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:09,514:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:09,623:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:09,647:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:09,899:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:10,429:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:10,445:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:11,890:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:11,963:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:12,150:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:12,214:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:12,899:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:12,923:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:13,352:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:13,906:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:13,906:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:13,994:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:14,272:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:14,693:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:14,725:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:15,330:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:16,655:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:16,800:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:17,109:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:17,167:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:17,425:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:17,425:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:17,901:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:18,024:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:19,881:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:20,058:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:20,437:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:20,468:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:20,671:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:20,718:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:20,792:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:22,583:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:23,269:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:23,406:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:23,505:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:23,638:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:24,507:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:24,775:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:24,806:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:25,658:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:26,122:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:26,140:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:26,310:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:26,650:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:27,183:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:27,421:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:27,881:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:28,385:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:28,883:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:28,969:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:29,545:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:29,712:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:30,212:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:30,456:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:31,148:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:31,799:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:32,137:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:32,202:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:32,234:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:32,323:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:32,504:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:32,524:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:33,255:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:33,536:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:34,201:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:34,234:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:34,340:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:34,517:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:35,133:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:35,141:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:35,832:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:36,060:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:36,432:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:36,839:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:37,032:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:37,073:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:38,476:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:38,891:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:38,899:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:39,903:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:40,372:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:40,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:40,467:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:41,643:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:41,767:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:41,805:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:41,925:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:42,345:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:42,436:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:42,477:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:42,833:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:43,989:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:44,019:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:44,084:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:44,337:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:45,494:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:45,590:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:45,726:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:45,787:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:46,733:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:46,762:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:46,917:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:47,201:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:47,516:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:47,548:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:48,312:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:48,345:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:49,576:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:49,684:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:50,290:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:50,476:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:50,773:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:50,773:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:51,690:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:51,747:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:52,318:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:52,382:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:52,583:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:52,663:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:52,736:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:52,801:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:53,524:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:53,620:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:54,644:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:54,698:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:55,432:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:55,443:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:56,249:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:56,273:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:56,872:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:56,976:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:57,322:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:57,403:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:57,823:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:57,874:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:05:58,176:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:58,278:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:58,867:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:05:59,022:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:00,001:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:00,151:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:00,527:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:00,627:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:01,442:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:01,490:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:02,652:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:02,682:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:03,479:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:03,479:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:06,447:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:06,544:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:06,986:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:07,067:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:07,091:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:07,163:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:07,953:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:08,007:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:08,465:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:08,465:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:08,947:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:09,011:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:09,048:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:09,081:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:10,380:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:10,474:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:11,733:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:11,733:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:11,920:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:11,926:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:12,001:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:12,028:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:13,623:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:14,033:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:14,107:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:14,435:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:16,066:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:16,135:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:16,235:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:16,308:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:17,587:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:18,420:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:18,777:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:18,911:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:19,796:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:19,797:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:19,850:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:19,880:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:20,705:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:20,713:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:21,047:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:21,513:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:21,794:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:21,794:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:21,855:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:22,515:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:24,004:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:230: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-09-04 22:06:24,377:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:24,450:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:24,925:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:25,036:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:25,164:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:25,184:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:25,274:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:26,626:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:26,628:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:26,754:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:26,985:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:27,058:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:27,100:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:27,137:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:27,319:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:29,617:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:30,242:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:30,315:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:30,428:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:30,670:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:30,702:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:31,542:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:31,549:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:32,810:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:32,834:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:32,850:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:33,202:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:33,318:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:33,376:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:34,064:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:34,069:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:36,219:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:36,227:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:36,293:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:36,333:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:36,982:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:37,588:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:37,703:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:38,101:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:38,170:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:38,228:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:38,735:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:38,963:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:39,750:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:39,800:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:40,447:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:40,515:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:40,517:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:41,508:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:41,880:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:42,032:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:42,057:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:42,983:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:43,093:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:43,256:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:43,509:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:43,983:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:44,104:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:44,194:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:44,436:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:45,171:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:45,392:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:45,637:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:45,923:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:46,207:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:46,304:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:46,465:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:47,760:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:223: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-09-04 22:06:48,219:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:48,329:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:48,716:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:48,723:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:49,441:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:49,569:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:49,700:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:50,106:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:50,463:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:51,325:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:51,392:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:52,242:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:52,436:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:53,356:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:53,356:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:53,386:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:53,564:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:54,219:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:54,813:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:55,428:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:56,461:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:56,651:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:56,730:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:57,056:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:57,136:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:58,476:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:58,723:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:59,305:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:59,423:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:06:59,438:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:06:59,568:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:00,157:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:00,216:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:01,127:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:01,267:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:01,824:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:02,709:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:02,793:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:02,929:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:02,986:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:03,773:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:05,166:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:05,288:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:05,441:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:05,511:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:05,740:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:06,129:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:06,843:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:06,941:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:07,772:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:07,901:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:08,434:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:09,262:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:09,368:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:09,756:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:09,772:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:10,270:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:11,703:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:11,905:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:11,935:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:11,958:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-09-04 22:07:12,467:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:12,759:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:12,887:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:13,795:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:14,087:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:14,287:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:15,408:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:15,776:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:15,898:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:16,296:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:16,345:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:16,687:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:16,827:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:18,059:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-09-04 22:07:18,123:INFO:Hyperparameter search completed
2023-09-04 22:07:18,131:INFO:SubProcess create_model() called ==================================
2023-09-04 22:07:18,146:INFO:Initializing create_model()
2023-09-04 22:07:18,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D47772B80>, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': False})
2023-09-04 22:07:18,146:INFO:Checking exceptions
2023-09-04 22:07:18,148:INFO:Importing libraries
2023-09-04 22:07:18,148:INFO:Copying training dataset
2023-09-04 22:07:18,211:INFO:Defining folds
2023-09-04 22:07:18,211:INFO:Declaring metric variables
2023-09-04 22:07:18,307:INFO:Importing untrained model
2023-09-04 22:07:18,307:INFO:Declaring custom model
2023-09-04 22:07:18,332:INFO:Random Forest Classifier Imported successfully
2023-09-04 22:07:18,356:INFO:Starting cross validation
2023-09-04 22:07:18,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 22:07:23,493:INFO:Calculating mean and std
2023-09-04 22:07:23,493:INFO:Creating metrics dataframe
2023-09-04 22:07:23,534:INFO:Finalizing model
2023-09-04 22:07:26,037:INFO:Uploading results into container
2023-09-04 22:07:26,037:INFO:Uploading model into container now
2023-09-04 22:07:26,041:INFO:_master_model_container: 19
2023-09-04 22:07:26,041:INFO:_display_container: 8
2023-09-04 22:07:26,041:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 22:07:26,041:INFO:create_model() successfully completed......................................
2023-09-04 22:07:27,577:INFO:SubProcess create_model() end ==================================
2023-09-04 22:07:27,577:INFO:choose_better activated
2023-09-04 22:07:27,585:INFO:SubProcess create_model() called ==================================
2023-09-04 22:07:27,585:INFO:Initializing create_model()
2023-09-04 22:07:27,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-04 22:07:27,585:INFO:Checking exceptions
2023-09-04 22:07:27,593:INFO:Importing libraries
2023-09-04 22:07:27,593:INFO:Copying training dataset
2023-09-04 22:07:27,608:INFO:Defining folds
2023-09-04 22:07:27,608:INFO:Declaring metric variables
2023-09-04 22:07:27,608:INFO:Importing untrained model
2023-09-04 22:07:27,608:INFO:Declaring custom model
2023-09-04 22:07:27,608:INFO:Random Forest Classifier Imported successfully
2023-09-04 22:07:27,608:INFO:Starting cross validation
2023-09-04 22:07:27,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 22:07:29,833:INFO:Calculating mean and std
2023-09-04 22:07:29,833:INFO:Creating metrics dataframe
2023-09-04 22:07:29,841:INFO:Finalizing model
2023-09-04 22:07:30,244:INFO:Uploading results into container
2023-09-04 22:07:30,252:INFO:Uploading model into container now
2023-09-04 22:07:30,252:INFO:_master_model_container: 20
2023-09-04 22:07:30,252:INFO:_display_container: 9
2023-09-04 22:07:30,252:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 22:07:30,252:INFO:create_model() successfully completed......................................
2023-09-04 22:07:30,444:INFO:SubProcess create_model() end ==================================
2023-09-04 22:07:30,444:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) result for Accuracy is 0.8268
2023-09-04 22:07:30,444:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) result for Accuracy is 0.8424
2023-09-04 22:07:30,444:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) is best model
2023-09-04 22:07:30,444:INFO:choose_better completed
2023-09-04 22:07:30,476:INFO:_master_model_container: 20
2023-09-04 22:07:30,476:INFO:_display_container: 8
2023-09-04 22:07:30,476:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-09-04 22:07:30,476:INFO:tune_model() successfully completed......................................
2023-09-04 22:07:30,661:INFO:Initializing tune_model()
2023-09-04 22:07:30,661:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>)
2023-09-04 22:07:30,661:INFO:Checking exceptions
2023-09-04 22:07:30,719:INFO:Copying training dataset
2023-09-04 22:07:30,727:INFO:Checking base model
2023-09-04 22:07:30,728:INFO:Base model : CatBoost Classifier
2023-09-04 22:07:30,744:INFO:Declaring metric variables
2023-09-04 22:07:30,752:INFO:Defining Hyperparameters
2023-09-04 22:07:30,881:INFO:Tuning with n_jobs=-1
2023-09-04 22:07:30,889:INFO:Initializing RandomizedSearchCV
2023-09-04 22:07:36,987:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:37,059:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:37,196:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:37,576:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:37,589:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:37,597:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:38,757:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:39,000:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:42,261:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:42,478:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:42,478:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:42,568:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:42,689:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:42,703:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:44,523:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:44,573:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:45,384:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:45,483:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:46,396:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:46,404:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:48,289:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:48,346:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:48,354:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:49,087:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:49,775:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:49,779:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:49,864:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:50,232:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:51,379:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:51,386:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:51,517:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:51,631:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:51,817:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:51,906:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:52,740:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:52,948:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:53,015:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:53,034:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:53,265:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:53,273:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:53,850:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:54,507:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:55,272:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:55,642:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:56,018:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:56,034:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:56,213:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:56,220:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:57,602:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:57,804:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:58,347:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:58,768:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:59,525:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:07:59,775:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:05,066:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:05,170:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:06,011:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:06,133:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:06,979:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:07,165:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:08,028:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:08,504:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:13,396:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:13,493:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:16,855:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:17,147:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:17,830:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:18,082:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:19,021:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:19,826:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:23,031:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:23,442:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:24,261:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:24,360:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:25,229:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:26,419:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:26,598:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:27,201:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:28,548:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:28,725:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:28,773:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:29,824:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:30,013:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:30,066:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:30,082:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:31,402:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-09-04 22:08:32,166:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 100, 'actual_estimator__eta': 0.01, 'actual_estimator__depth': 3}
2023-09-04 22:08:32,174:INFO:Hyperparameter search completed
2023-09-04 22:08:32,174:INFO:SubProcess create_model() called ==================================
2023-09-04 22:08:32,174:INFO:Initializing create_model()
2023-09-04 22:08:32,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D47223DF0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027D3B7F8C70>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.8, 'n_estimators': 280, 'l2_leaf_reg': 100, 'eta': 0.01, 'depth': 3})
2023-09-04 22:08:32,174:INFO:Checking exceptions
2023-09-04 22:08:32,174:INFO:Importing libraries
2023-09-04 22:08:32,174:INFO:Copying training dataset
2023-09-04 22:08:32,182:INFO:Defining folds
2023-09-04 22:08:32,182:INFO:Declaring metric variables
2023-09-04 22:08:32,190:INFO:Importing untrained model
2023-09-04 22:08:32,198:INFO:Declaring custom model
2023-09-04 22:08:32,207:INFO:CatBoost Classifier Imported successfully
2023-09-04 22:08:32,215:INFO:Starting cross validation
2023-09-04 22:08:32,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 22:08:33,486:INFO:Calculating mean and std
2023-09-04 22:08:33,486:INFO:Creating metrics dataframe
2023-09-04 22:08:33,502:INFO:Finalizing model
2023-09-04 22:08:34,855:INFO:Uploading results into container
2023-09-04 22:08:34,855:INFO:Uploading model into container now
2023-09-04 22:08:34,855:INFO:_master_model_container: 21
2023-09-04 22:08:34,855:INFO:_display_container: 9
2023-09-04 22:08:34,855:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D47830100>
2023-09-04 22:08:34,855:INFO:create_model() successfully completed......................................
2023-09-04 22:08:35,040:INFO:SubProcess create_model() end ==================================
2023-09-04 22:08:35,040:INFO:choose_better activated
2023-09-04 22:08:35,056:INFO:SubProcess create_model() called ==================================
2023-09-04 22:08:35,056:INFO:Initializing create_model()
2023-09-04 22:08:35,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-04 22:08:35,056:INFO:Checking exceptions
2023-09-04 22:08:35,056:INFO:Importing libraries
2023-09-04 22:08:35,056:INFO:Copying training dataset
2023-09-04 22:08:35,072:INFO:Defining folds
2023-09-04 22:08:35,072:INFO:Declaring metric variables
2023-09-04 22:08:35,072:INFO:Importing untrained model
2023-09-04 22:08:35,072:INFO:Declaring custom model
2023-09-04 22:08:35,072:INFO:CatBoost Classifier Imported successfully
2023-09-04 22:08:35,072:INFO:Starting cross validation
2023-09-04 22:08:35,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-04 22:08:36,273:INFO:Calculating mean and std
2023-09-04 22:08:36,282:INFO:Creating metrics dataframe
2023-09-04 22:08:36,282:INFO:Finalizing model
2023-09-04 22:08:36,650:INFO:Uploading results into container
2023-09-04 22:08:36,650:INFO:Uploading model into container now
2023-09-04 22:08:36,650:INFO:_master_model_container: 22
2023-09-04 22:08:36,650:INFO:_display_container: 10
2023-09-04 22:08:36,650:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D474E4A90>
2023-09-04 22:08:36,650:INFO:create_model() successfully completed......................................
2023-09-04 22:08:36,811:INFO:SubProcess create_model() end ==================================
2023-09-04 22:08:36,811:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D474E4A90> result for Accuracy is 0.8268
2023-09-04 22:08:36,811:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D47830100> result for Accuracy is 0.8574
2023-09-04 22:08:36,811:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D47830100> is best model
2023-09-04 22:08:36,811:INFO:choose_better completed
2023-09-04 22:08:36,843:INFO:_master_model_container: 22
2023-09-04 22:08:36,843:INFO:_display_container: 9
2023-09-04 22:08:36,843:INFO:<catboost.core.CatBoostClassifier object at 0x0000027D47830100>
2023-09-04 22:08:36,843:INFO:tune_model() successfully completed......................................
2023-09-04 22:08:37,020:INFO:Initializing predict_model()
2023-09-04 22:08:37,020:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D47A53700>)
2023-09-04 22:08:37,020:INFO:Checking exceptions
2023-09-04 22:08:37,020:INFO:Preloading libraries
2023-09-04 22:08:37,025:INFO:Set up data.
2023-09-04 22:08:37,041:INFO:Set up index.
2023-09-04 22:08:42,800:INFO:Initializing predict_model()
2023-09-04 22:08:42,800:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D47830100>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D479A2D30>)
2023-09-04 22:08:42,800:INFO:Checking exceptions
2023-09-04 22:08:42,800:INFO:Preloading libraries
2023-09-04 22:08:42,805:INFO:Set up data.
2023-09-04 22:08:42,809:INFO:Set up index.
2023-09-04 22:10:37,860:INFO:Initializing plot_model()
2023-09-04 22:10:37,860:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:10:37,860:INFO:Checking exceptions
2023-09-04 22:10:37,892:INFO:Preloading libraries
2023-09-04 22:10:37,908:INFO:Copying training dataset
2023-09-04 22:10:37,908:INFO:Plot type: auc
2023-09-04 22:10:38,133:INFO:Fitting Model
2023-09-04 22:10:38,166:INFO:Scoring test/hold-out set
2023-09-04 22:10:38,806:INFO:Visual Rendered Successfully
2023-09-04 22:10:39,024:INFO:plot_model() successfully completed......................................
2023-09-04 22:11:08,161:INFO:Initializing plot_model()
2023-09-04 22:11:08,161:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:11:08,169:INFO:Checking exceptions
2023-09-04 22:11:08,177:INFO:Preloading libraries
2023-09-04 22:11:08,180:INFO:Copying training dataset
2023-09-04 22:11:08,180:INFO:Plot type: ks
2023-09-04 22:11:08,180:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:11:08,611:INFO:Visual Rendered Successfully
2023-09-04 22:11:08,787:INFO:plot_model() successfully completed......................................
2023-09-04 22:12:53,005:INFO:Initializing predict_model()
2023-09-04 22:12:53,005:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D479F08B0>)
2023-09-04 22:12:53,005:INFO:Checking exceptions
2023-09-04 22:12:53,007:INFO:Preloading libraries
2023-09-04 22:12:53,013:INFO:Set up data.
2023-09-04 22:12:53,030:INFO:Set up index.
2023-09-04 22:13:09,836:INFO:Initializing predict_model()
2023-09-04 22:13:09,836:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D479A2B80>)
2023-09-04 22:13:09,836:INFO:Checking exceptions
2023-09-04 22:13:09,836:INFO:Preloading libraries
2023-09-04 22:13:09,836:INFO:Set up data.
2023-09-04 22:13:09,850:INFO:Set up index.
2023-09-04 22:13:17,786:INFO:Initializing predict_model()
2023-09-04 22:13:17,786:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D4A755430>)
2023-09-04 22:13:17,786:INFO:Checking exceptions
2023-09-04 22:13:17,786:INFO:Preloading libraries
2023-09-04 22:13:17,786:INFO:Set up data.
2023-09-04 22:13:17,803:INFO:Set up index.
2023-09-04 22:13:37,140:INFO:Initializing predict_model()
2023-09-04 22:13:37,140:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D479A2550>)
2023-09-04 22:13:37,140:INFO:Checking exceptions
2023-09-04 22:13:37,140:INFO:Preloading libraries
2023-09-04 22:14:45,242:INFO:Initializing plot_model()
2023-09-04 22:14:45,242:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:14:45,242:INFO:Checking exceptions
2023-09-04 22:14:45,291:INFO:Preloading libraries
2023-09-04 22:14:45,332:INFO:Copying training dataset
2023-09-04 22:14:45,332:INFO:Plot type: ks
2023-09-04 22:14:45,332:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:14:45,847:INFO:Visual Rendered Successfully
2023-09-04 22:14:46,023:INFO:plot_model() successfully completed......................................
2023-09-04 22:15:04,178:INFO:Initializing plot_model()
2023-09-04 22:15:04,178:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:15:04,178:INFO:Checking exceptions
2023-09-04 22:15:04,195:INFO:Preloading libraries
2023-09-04 22:15:04,198:INFO:Copying training dataset
2023-09-04 22:15:04,198:INFO:Plot type: ks
2023-09-04 22:15:04,198:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:15:04,611:INFO:Visual Rendered Successfully
2023-09-04 22:15:04,780:INFO:plot_model() successfully completed......................................
2023-09-04 22:15:37,285:INFO:Initializing plot_model()
2023-09-04 22:15:37,285:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:15:37,285:INFO:Checking exceptions
2023-09-04 22:15:37,327:INFO:Preloading libraries
2023-09-04 22:15:37,338:INFO:Copying training dataset
2023-09-04 22:15:37,338:INFO:Plot type: ks
2023-09-04 22:15:37,338:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:15:37,784:INFO:Visual Rendered Successfully
2023-09-04 22:15:37,953:INFO:plot_model() successfully completed......................................
2023-09-04 22:16:06,303:INFO:Initializing plot_model()
2023-09-04 22:16:06,303:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:16:06,303:INFO:Checking exceptions
2023-09-04 22:16:06,384:INFO:Preloading libraries
2023-09-04 22:16:06,448:INFO:Copying training dataset
2023-09-04 22:16:06,448:INFO:Plot type: ks
2023-09-04 22:16:06,448:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:16:06,961:INFO:Visual Rendered Successfully
2023-09-04 22:16:07,130:INFO:plot_model() successfully completed......................................
2023-09-04 22:16:26,210:INFO:Initializing plot_model()
2023-09-04 22:16:26,210:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D47830100>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:16:26,210:INFO:Checking exceptions
2023-09-04 22:16:26,218:INFO:Preloading libraries
2023-09-04 22:16:26,222:INFO:Copying training dataset
2023-09-04 22:16:26,222:INFO:Plot type: ks
2023-09-04 22:16:26,223:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:16:26,659:INFO:Visual Rendered Successfully
2023-09-04 22:16:26,819:INFO:plot_model() successfully completed......................................
2023-09-04 22:16:51,130:INFO:Initializing plot_model()
2023-09-04 22:16:51,130:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:16:51,130:INFO:Checking exceptions
2023-09-04 22:16:51,145:INFO:Preloading libraries
2023-09-04 22:16:51,146:INFO:Copying training dataset
2023-09-04 22:16:51,146:INFO:Plot type: ks
2023-09-04 22:16:51,149:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:16:51,684:INFO:Visual Rendered Successfully
2023-09-04 22:16:51,852:INFO:plot_model() successfully completed......................................
2023-09-04 22:18:01,677:INFO:Initializing plot_model()
2023-09-04 22:18:01,677:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:18:01,677:INFO:Checking exceptions
2023-09-04 22:18:01,689:INFO:Preloading libraries
2023-09-04 22:18:01,689:INFO:Copying training dataset
2023-09-04 22:18:01,689:INFO:Plot type: confusion_matrix
2023-09-04 22:18:01,895:INFO:Fitting Model
2023-09-04 22:18:01,895:INFO:Scoring test/hold-out set
2023-09-04 22:18:02,185:INFO:Visual Rendered Successfully
2023-09-04 22:18:02,377:INFO:plot_model() successfully completed......................................
2023-09-04 22:18:37,098:INFO:Initializing evaluate_model()
2023-09-04 22:18:37,098:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-09-04 22:18:37,155:INFO:Initializing plot_model()
2023-09-04 22:18:37,155:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:18:37,155:INFO:Checking exceptions
2023-09-04 22:18:37,163:INFO:Preloading libraries
2023-09-04 22:18:37,171:INFO:Copying training dataset
2023-09-04 22:18:37,171:INFO:Plot type: pipeline
2023-09-04 22:18:37,581:INFO:Visual Rendered Successfully
2023-09-04 22:18:37,752:INFO:plot_model() successfully completed......................................
2023-09-04 22:18:47,631:INFO:Initializing plot_model()
2023-09-04 22:18:47,631:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:18:47,636:INFO:Checking exceptions
2023-09-04 22:18:47,644:INFO:Preloading libraries
2023-09-04 22:18:47,644:INFO:Copying training dataset
2023-09-04 22:18:47,644:INFO:Plot type: ks
2023-09-04 22:18:47,644:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:18:48,126:INFO:Visual Rendered Successfully
2023-09-04 22:18:48,336:INFO:plot_model() successfully completed......................................
2023-09-04 22:18:53,443:INFO:Initializing plot_model()
2023-09-04 22:18:53,443:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:18:53,443:INFO:Checking exceptions
2023-09-04 22:18:53,443:INFO:Preloading libraries
2023-09-04 22:18:53,451:INFO:Copying training dataset
2023-09-04 22:18:53,451:INFO:Plot type: pipeline
2023-09-04 22:18:53,676:INFO:Visual Rendered Successfully
2023-09-04 22:18:53,853:INFO:plot_model() successfully completed......................................
2023-09-04 22:18:56,496:INFO:Initializing plot_model()
2023-09-04 22:18:56,496:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:18:56,496:INFO:Checking exceptions
2023-09-04 22:18:56,501:INFO:Preloading libraries
2023-09-04 22:18:56,501:INFO:Copying training dataset
2023-09-04 22:18:56,501:INFO:Plot type: pr
2023-09-04 22:18:56,710:INFO:Fitting Model
2023-09-04 22:18:56,710:INFO:Scoring test/hold-out set
2023-09-04 22:18:57,039:INFO:Visual Rendered Successfully
2023-09-04 22:18:57,223:INFO:plot_model() successfully completed......................................
2023-09-04 22:18:59,483:INFO:Initializing plot_model()
2023-09-04 22:18:59,483:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:18:59,483:INFO:Checking exceptions
2023-09-04 22:18:59,483:INFO:Preloading libraries
2023-09-04 22:18:59,491:INFO:Copying training dataset
2023-09-04 22:18:59,491:INFO:Plot type: auc
2023-09-04 22:18:59,691:INFO:Fitting Model
2023-09-04 22:18:59,691:INFO:Scoring test/hold-out set
2023-09-04 22:19:00,061:INFO:Visual Rendered Successfully
2023-09-04 22:19:00,261:INFO:plot_model() successfully completed......................................
2023-09-04 22:19:05,577:INFO:Initializing plot_model()
2023-09-04 22:19:05,577:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:19:05,577:INFO:Checking exceptions
2023-09-04 22:19:05,585:INFO:Preloading libraries
2023-09-04 22:19:05,585:INFO:Copying training dataset
2023-09-04 22:19:05,585:INFO:Plot type: feature
2023-09-04 22:19:05,585:WARNING:No coef_ found. Trying feature_importances_
2023-09-04 22:19:05,922:INFO:Visual Rendered Successfully
2023-09-04 22:19:06,090:INFO:plot_model() successfully completed......................................
2023-09-04 22:19:22,652:INFO:Initializing plot_model()
2023-09-04 22:19:22,652:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:19:22,652:INFO:Checking exceptions
2023-09-04 22:19:22,662:INFO:Preloading libraries
2023-09-04 22:19:22,662:INFO:Copying training dataset
2023-09-04 22:19:22,662:INFO:Plot type: learning
2023-09-04 22:19:22,886:INFO:Fitting Model
2023-09-04 22:21:45,538:INFO:Visual Rendered Successfully
2023-09-04 22:21:48,968:INFO:plot_model() successfully completed......................................
2023-09-04 22:21:49,014:INFO:Initializing plot_model()
2023-09-04 22:21:49,014:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:21:49,015:INFO:Checking exceptions
2023-09-04 22:21:49,048:INFO:Preloading libraries
2023-09-04 22:21:49,112:INFO:Copying training dataset
2023-09-04 22:21:49,112:INFO:Plot type: threshold
2023-09-04 22:21:49,480:INFO:Fitting Model
2023-09-04 22:25:08,078:INFO:Initializing plot_model()
2023-09-04 22:25:08,086:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:25:08,086:INFO:Checking exceptions
2023-09-04 22:25:08,086:INFO:Preloading libraries
2023-09-04 22:25:08,094:INFO:Copying training dataset
2023-09-04 22:25:08,094:INFO:Plot type: class_report
2023-09-04 22:25:08,304:INFO:Fitting Model
2023-09-04 22:25:08,312:INFO:Scoring test/hold-out set
2023-09-04 22:25:08,771:INFO:Visual Rendered Successfully
2023-09-04 22:25:09,067:INFO:plot_model() successfully completed......................................
2023-09-04 22:25:09,086:INFO:Initializing plot_model()
2023-09-04 22:25:09,086:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:25:09,086:INFO:Checking exceptions
2023-09-04 22:25:09,092:INFO:Preloading libraries
2023-09-04 22:25:09,098:INFO:Copying training dataset
2023-09-04 22:25:09,098:INFO:Plot type: auc
2023-09-04 22:25:09,293:INFO:Fitting Model
2023-09-04 22:25:09,293:INFO:Scoring test/hold-out set
2023-09-04 22:25:09,688:INFO:Visual Rendered Successfully
2023-09-04 22:25:09,880:INFO:plot_model() successfully completed......................................
2023-09-04 22:25:09,904:INFO:Initializing plot_model()
2023-09-04 22:25:09,904:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:25:09,904:INFO:Checking exceptions
2023-09-04 22:25:09,936:INFO:Initializing plot_model()
2023-09-04 22:25:09,936:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:25:09,936:INFO:Checking exceptions
2023-09-04 22:25:09,938:INFO:Preloading libraries
2023-09-04 22:25:09,944:INFO:Copying training dataset
2023-09-04 22:25:09,944:INFO:Plot type: gain
2023-09-04 22:25:09,944:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:25:10,363:INFO:Visual Rendered Successfully
2023-09-04 22:25:10,571:INFO:plot_model() successfully completed......................................
2023-09-04 22:25:18,173:INFO:Initializing plot_model()
2023-09-04 22:25:18,173:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:25:18,173:INFO:Checking exceptions
2023-09-04 22:25:18,177:INFO:Preloading libraries
2023-09-04 22:25:18,177:INFO:Copying training dataset
2023-09-04 22:25:18,177:INFO:Plot type: ks
2023-09-04 22:25:18,185:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:25:18,586:INFO:Visual Rendered Successfully
2023-09-04 22:25:18,755:INFO:plot_model() successfully completed......................................
2023-09-04 22:25:51,521:INFO:Initializing interpret_model()
2023-09-04 22:25:51,521:INFO:interpret_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>)
2023-09-04 22:25:51,521:INFO:Checking exceptions
2023-09-04 22:25:51,521:INFO:Soft dependency imported: shap: 0.42.1
2023-09-04 22:25:53,005:WARNING:Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)

2023-09-04 22:25:53,357:INFO:plot type: summary
2023-09-04 22:25:53,357:INFO:Creating TreeExplainer
2023-09-04 22:25:53,558:INFO:Compiling shap values
2023-09-04 22:25:56,257:INFO:Visual Rendered Successfully
2023-09-04 22:25:56,257:INFO:interpret_model() successfully completed......................................
2023-09-04 22:26:24,611:INFO:Initializing plot_model()
2023-09-04 22:26:24,611:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:26:24,611:INFO:Checking exceptions
2023-09-04 22:26:24,619:INFO:Preloading libraries
2023-09-04 22:26:24,627:INFO:Copying training dataset
2023-09-04 22:26:24,627:INFO:Plot type: feature
2023-09-04 22:26:24,627:WARNING:No coef_ found. Trying feature_importances_
2023-09-04 22:26:24,957:INFO:Visual Rendered Successfully
2023-09-04 22:26:25,166:INFO:plot_model() successfully completed......................................
2023-09-04 22:28:46,010:INFO:Initializing plot_model()
2023-09-04 22:28:46,018:INFO:plot_model(plot=ks, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D47830100>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:28:46,018:INFO:Checking exceptions
2023-09-04 22:28:46,027:INFO:Preloading libraries
2023-09-04 22:28:46,034:INFO:Copying training dataset
2023-09-04 22:28:46,034:INFO:Plot type: ks
2023-09-04 22:28:46,035:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:28:46,572:INFO:Visual Rendered Successfully
2023-09-04 22:28:46,784:INFO:plot_model() successfully completed......................................
2023-09-04 22:29:07,457:INFO:Initializing plot_model()
2023-09-04 22:29:07,457:INFO:plot_model(plot=ks, fold=None, use_train_data=True, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, system=True)
2023-09-04 22:29:07,457:INFO:Checking exceptions
2023-09-04 22:29:07,467:INFO:Preloading libraries
2023-09-04 22:29:07,472:INFO:Copying training dataset
2023-09-04 22:29:07,472:INFO:Plot type: ks
2023-09-04 22:29:07,474:INFO:Generating predictions / predict_proba on X_test
2023-09-04 22:29:07,930:INFO:Visual Rendered Successfully
2023-09-04 22:29:08,107:INFO:plot_model() successfully completed......................................
2023-09-04 22:29:24,693:INFO:Initializing predict_model()
2023-09-04 22:29:24,693:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D4C11A790>)
2023-09-04 22:29:24,693:INFO:Checking exceptions
2023-09-04 22:29:24,693:INFO:Preloading libraries
2023-09-04 22:34:16,917:INFO:Initializing predict_model()
2023-09-04 22:34:16,925:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D4C11A8B0>)
2023-09-04 22:34:16,925:INFO:Checking exceptions
2023-09-04 22:34:16,925:INFO:Preloading libraries
2023-09-04 22:35:01,707:INFO:Initializing predict_model()
2023-09-04 22:35:01,707:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D4C11A1F0>)
2023-09-04 22:35:01,707:INFO:Checking exceptions
2023-09-04 22:35:01,707:INFO:Preloading libraries
2023-09-04 22:35:01,715:INFO:Set up data.
2023-09-04 22:35:01,731:INFO:Set up index.
2023-09-04 22:35:05,811:INFO:Initializing predict_model()
2023-09-04 22:35:05,811:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027D4C11A670>)
2023-09-04 22:35:05,811:INFO:Checking exceptions
2023-09-04 22:35:05,811:INFO:Preloading libraries
2023-09-04 22:35:05,823:INFO:Set up data.
2023-09-04 22:35:05,845:INFO:Set up index.
2023-09-04 22:39:46,837:INFO:Initializing save_model()
2023-09-04 22:39:46,837:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, model_name=exp_01_catboost, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-09-04 22:39:46,837:INFO:Adding model into prep_pipe
2023-09-04 22:39:46,885:INFO:exp_01_catboost.pkl saved in current working directory
2023-09-04 22:39:47,006:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>)],
         verbose=False)
2023-09-04 22:39:47,006:INFO:save_model() successfully completed......................................
2023-09-04 22:53:56,134:INFO:Initializing load_model()
2023-09-04 22:53:56,142:INFO:load_model(model_name=exp_01_catboost, platform=None, authentication=None, verbose=True)
2023-09-04 22:55:34,969:INFO:Initializing finalize_model()
2023-09-04 22:55:34,969:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-09-04 22:55:34,972:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>
2023-09-04 22:55:34,993:INFO:Initializing create_model()
2023-09-04 22:55:34,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027D471CC3D0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000027D471E2F70>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-09-04 22:55:34,993:INFO:Checking exceptions
2023-09-04 22:55:35,017:INFO:Importing libraries
2023-09-04 22:55:35,017:INFO:Copying training dataset
2023-09-04 22:55:35,017:INFO:Defining folds
2023-09-04 22:55:35,017:INFO:Declaring metric variables
2023-09-04 22:55:35,025:INFO:Importing untrained model
2023-09-04 22:55:35,025:INFO:Declaring custom model
2023-09-04 22:55:35,033:INFO:CatBoost Classifier Imported successfully
2023-09-04 22:55:35,041:INFO:Cross validation set to False
2023-09-04 22:55:35,041:INFO:Fitting Model
2023-09-04 22:55:40,439:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000027D4B0FB790>)],
         verbose=False)
2023-09-04 22:55:40,439:INFO:create_model() successfully completed......................................
2023-09-04 22:55:41,236:INFO:_master_model_container: 22
2023-09-04 22:55:41,236:INFO:_display_container: 19
2023-09-04 22:55:41,382:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000027D4B0FB790>)],
         verbose=False)
2023-09-04 22:55:41,382:INFO:finalize_model() successfully completed......................................
2023-10-11 19:39:48,047:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-11 19:39:48,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-11 19:39:48,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-11 19:39:48,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-11 19:39:49,167:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-11 20:05:16,982:INFO:PyCaret ClassificationExperiment
2023-10-11 20:05:16,982:INFO:Logging name: EXP_01_WANDA_2023
2023-10-11 20:05:16,982:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-10-11 20:05:16,982:INFO:version 3.0.0.rc9
2023-10-11 20:05:16,982:INFO:Initializing setup()
2023-10-11 20:05:16,982:INFO:self.USI: 6ade
2023-10-11 20:05:16,982:INFO:self._variable_keys: {'exp_name_log', 'seed', 'memory', 'y_train', 'fix_imbalance', 'is_multiclass', '_available_plots', 'fold_generator', 'target_param', 'gpu_n_jobs_param', 'y_test', 'X_test', 'X_train', 'fold_shuffle_param', 'idx', 'pipeline', '_ml_usecase', 'n_jobs_param', 'log_plots_param', 'data', 'y', 'logging_param', 'USI', 'exp_id', 'X', 'fold_groups_param', 'gpu_param', 'html_param'}
2023-10-11 20:05:16,982:INFO:Checking environment
2023-10-11 20:05:16,982:INFO:python_version: 3.9.13
2023-10-11 20:05:16,982:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-10-11 20:05:16,982:INFO:machine: AMD64
2023-10-11 20:05:16,982:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-11 20:05:16,998:INFO:Memory: svmem(total=8266518528, available=1525219328, percent=81.5, used=6741299200, free=1525219328)
2023-10-11 20:05:16,998:INFO:Physical Core: 4
2023-10-11 20:05:16,998:INFO:Logical Core: 8
2023-10-11 20:05:16,998:INFO:Checking libraries
2023-10-11 20:05:16,998:INFO:System:
2023-10-11 20:05:16,998:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-10-11 20:05:16,998:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-10-11 20:05:16,998:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-11 20:05:16,998:INFO:PyCaret required dependencies:
2023-10-11 20:05:16,998:INFO:                 pip: 22.2.2
2023-10-11 20:05:16,998:INFO:          setuptools: 63.4.1
2023-10-11 20:05:16,998:INFO:             pycaret: 3.0.0rc9
2023-10-11 20:05:16,998:INFO:             IPython: 7.31.1
2023-10-11 20:05:16,998:INFO:          ipywidgets: 7.6.5
2023-10-11 20:05:16,998:INFO:                tqdm: 4.64.1
2023-10-11 20:05:16,998:INFO:               numpy: 1.21.5
2023-10-11 20:05:16,998:INFO:              pandas: 1.4.4
2023-10-11 20:05:16,998:INFO:              jinja2: 3.0.3
2023-10-11 20:05:16,998:INFO:               scipy: 1.9.1
2023-10-11 20:05:16,998:INFO:              joblib: 1.2.0
2023-10-11 20:05:16,998:INFO:             sklearn: 1.2.2
2023-10-11 20:05:16,998:INFO:                pyod: 1.0.7
2023-10-11 20:05:16,998:INFO:            imblearn: 0.10.1
2023-10-11 20:05:16,998:INFO:   category_encoders: 2.6.0
2023-10-11 20:05:16,998:INFO:            lightgbm: 3.3.5
2023-10-11 20:05:16,998:INFO:               numba: 0.55.1
2023-10-11 20:05:16,998:INFO:            requests: 2.28.1
2023-10-11 20:05:16,998:INFO:          matplotlib: 3.5.2
2023-10-11 20:05:16,998:INFO:          scikitplot: 0.3.7
2023-10-11 20:05:16,998:INFO:         yellowbrick: 1.5
2023-10-11 20:05:16,998:INFO:              plotly: 5.16.1
2023-10-11 20:05:16,998:INFO:             kaleido: 0.2.1
2023-10-11 20:05:16,998:INFO:         statsmodels: 0.14.0
2023-10-11 20:05:16,998:INFO:              sktime: 0.16.1
2023-10-11 20:05:17,014:INFO:               tbats: 1.1.2
2023-10-11 20:05:17,014:INFO:            pmdarima: 2.0.2
2023-10-11 20:05:17,014:INFO:              psutil: 5.9.0
2023-10-11 20:05:17,014:INFO:PyCaret optional dependencies:
2023-10-11 20:05:17,045:INFO:                shap: 0.42.1
2023-10-11 20:05:17,045:INFO:           interpret: 0.4.4
2023-10-11 20:05:17,045:INFO:                umap: 0.5.3
2023-10-11 20:05:17,045:INFO:    pandas_profiling: 4.3.1
2023-10-11 20:05:17,045:INFO:  explainerdashboard: 0.4.3
2023-10-11 20:05:17,045:INFO:             autoviz: 0.1.720
2023-10-11 20:05:17,045:INFO:           fairlearn: 0.7.0
2023-10-11 20:05:17,045:INFO:             xgboost: 1.7.5
2023-10-11 20:05:17,045:INFO:            catboost: 1.2
2023-10-11 20:05:17,045:INFO:              kmodes: Not installed
2023-10-11 20:05:17,045:INFO:             mlxtend: Not installed
2023-10-11 20:05:17,045:INFO:       statsforecast: Not installed
2023-10-11 20:05:17,045:INFO:        tune_sklearn: Not installed
2023-10-11 20:05:17,045:INFO:                 ray: Not installed
2023-10-11 20:05:17,045:INFO:            hyperopt: Not installed
2023-10-11 20:05:17,045:INFO:              optuna: Not installed
2023-10-11 20:05:17,045:INFO:               skopt: Not installed
2023-10-11 20:05:17,045:INFO:              mlflow: Not installed
2023-10-11 20:05:17,045:INFO:              gradio: Not installed
2023-10-11 20:05:17,045:INFO:             fastapi: Not installed
2023-10-11 20:05:17,045:INFO:             uvicorn: Not installed
2023-10-11 20:05:17,045:INFO:              m2cgen: 0.10.0
2023-10-11 20:05:17,045:INFO:           evidently: Not installed
2023-10-11 20:05:17,045:INFO:               fugue: Not installed
2023-10-11 20:05:17,045:INFO:           streamlit: Not installed
2023-10-11 20:05:17,045:INFO:             prophet: Not installed
2023-10-11 20:05:17,045:INFO:None
2023-10-11 20:05:17,045:INFO:Set up data.
2023-10-11 20:05:17,209:INFO:Set up train/test split.
2023-10-11 20:05:17,247:INFO:Set up index.
2023-10-11 20:05:17,247:INFO:Set up folding strategy.
2023-10-11 20:05:17,247:INFO:Assigning column types.
2023-10-11 20:05:17,263:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-11 20:05:17,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-11 20:05:17,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-11 20:05:17,451:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:17,754:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:17,965:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-11 20:05:17,966:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-11 20:05:17,997:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:18,000:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:18,001:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-11 20:05:18,066:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-11 20:05:18,106:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:18,109:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:18,152:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-11 20:05:18,202:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:18,205:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:18,206:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-10-11 20:05:18,311:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:18,311:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:18,390:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:18,390:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:18,401:INFO:Preparing preprocessing pipeline...
2023-10-11 20:05:18,406:INFO:Set up simple imputation.
2023-10-11 20:05:18,406:INFO:Set up encoding of ordinal features.
2023-10-11 20:05:18,406:INFO:Set up encoding of categorical features.
2023-10-11 20:05:18,406:INFO:Set up feature normalization.
2023-10-11 20:05:18,592:INFO:Finished creating preprocessing pipeline.
2023-10-11 20:05:18,652:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-10-11 20:05:18,652:INFO:Creating final display dataframe.
2023-10-11 20:05:19,226:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               6ade
2023-10-11 20:05:19,350:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:19,350:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:19,439:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-11 20:05:19,442:INFO:Soft dependency imported: catboost: 1.2
2023-10-11 20:05:19,445:INFO:setup() successfully completed in 2.54s...............
2023-10-11 20:15:12,652:INFO:Initializing get_config()
2023-10-11 20:15:12,652:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, variable=train)
2023-10-11 20:15:12,653:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-10-11 20:15:12,656:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-10-11 20:15:12,667:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-10-11 20:15:12,667:INFO:get_config() successfully completed......................................
2023-10-11 20:16:06,451:INFO:Initializing get_config()
2023-10-11 20:16:06,451:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, variable=test)
2023-10-11 20:16:06,451:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-10-11 20:16:06,451:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-10-11 20:16:06,461:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  ALVO  
196                      1.0  LEVEL_7     0  
197                      0.0  LEVEL_3     0  
198                      0.0  LEVEL_3     1  
199                      NaN  LEVEL_3     0  
200                      0.0  LEVEL_3     0  
..                       ...      ...   ...  
298                      0.0  LEVEL_7     1  
299                      0.0  LEVEL_3     0  
300                      1.0  LEVEL_3     1  
301                      0.0  LEVEL_3     1  
302                      2.0  LEVEL_7     1  

[107 rows x 14 columns]
2023-10-11 20:16:06,462:INFO:get_config() successfully completed......................................
2023-10-11 20:17:44,437:INFO:Initializing get_config()
2023-10-11 20:17:44,438:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, variable=X_train_transformed)
2023-10-11 20:17:44,520:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-10-11 20:17:44,520:INFO:get_config() successfully completed......................................
2023-10-11 20:18:56,848:INFO:Initializing compare_models()
2023-10-11 20:18:56,849:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-10-11 20:18:56,849:INFO:Checking exceptions
2023-10-11 20:18:56,853:INFO:Preparing display monitor
2023-10-11 20:18:56,916:INFO:Initializing Logistic Regression
2023-10-11 20:18:56,917:INFO:Total runtime is 1.866022745768229e-05 minutes
2023-10-11 20:18:56,921:INFO:SubProcess create_model() called ==================================
2023-10-11 20:18:56,924:INFO:Initializing create_model()
2023-10-11 20:18:56,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:18:56,924:INFO:Checking exceptions
2023-10-11 20:18:56,924:INFO:Importing libraries
2023-10-11 20:18:56,924:INFO:Copying training dataset
2023-10-11 20:18:56,928:INFO:Defining folds
2023-10-11 20:18:56,929:INFO:Declaring metric variables
2023-10-11 20:18:56,932:INFO:Importing untrained model
2023-10-11 20:18:56,935:INFO:Logistic Regression Imported successfully
2023-10-11 20:18:56,940:INFO:Starting cross validation
2023-10-11 20:18:56,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:06,819:INFO:Calculating mean and std
2023-10-11 20:19:06,819:INFO:Creating metrics dataframe
2023-10-11 20:19:06,839:INFO:Uploading results into container
2023-10-11 20:19:06,840:INFO:Uploading model into container now
2023-10-11 20:19:06,841:INFO:_master_model_container: 1
2023-10-11 20:19:06,841:INFO:_display_container: 2
2023-10-11 20:19:06,841:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-10-11 20:19:06,842:INFO:create_model() successfully completed......................................
2023-10-11 20:19:07,544:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:07,544:INFO:Creating metrics dataframe
2023-10-11 20:19:07,560:INFO:Initializing K Neighbors Classifier
2023-10-11 20:19:07,560:INFO:Total runtime is 0.17739412784576417 minutes
2023-10-11 20:19:07,560:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:07,569:INFO:Initializing create_model()
2023-10-11 20:19:07,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:07,569:INFO:Checking exceptions
2023-10-11 20:19:07,569:INFO:Importing libraries
2023-10-11 20:19:07,569:INFO:Copying training dataset
2023-10-11 20:19:07,576:INFO:Defining folds
2023-10-11 20:19:07,576:INFO:Declaring metric variables
2023-10-11 20:19:07,580:INFO:Importing untrained model
2023-10-11 20:19:07,585:INFO:K Neighbors Classifier Imported successfully
2023-10-11 20:19:07,594:INFO:Starting cross validation
2023-10-11 20:19:07,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:08,834:INFO:Calculating mean and std
2023-10-11 20:19:08,834:INFO:Creating metrics dataframe
2023-10-11 20:19:08,834:INFO:Uploading results into container
2023-10-11 20:19:08,834:INFO:Uploading model into container now
2023-10-11 20:19:08,834:INFO:_master_model_container: 2
2023-10-11 20:19:08,834:INFO:_display_container: 2
2023-10-11 20:19:08,834:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-10-11 20:19:08,834:INFO:create_model() successfully completed......................................
2023-10-11 20:19:08,929:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:08,929:INFO:Creating metrics dataframe
2023-10-11 20:19:08,951:INFO:Initializing Naive Bayes
2023-10-11 20:19:08,951:INFO:Total runtime is 0.20057440996170045 minutes
2023-10-11 20:19:08,951:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:08,951:INFO:Initializing create_model()
2023-10-11 20:19:08,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:08,951:INFO:Checking exceptions
2023-10-11 20:19:08,951:INFO:Importing libraries
2023-10-11 20:19:08,951:INFO:Copying training dataset
2023-10-11 20:19:08,961:INFO:Defining folds
2023-10-11 20:19:08,961:INFO:Declaring metric variables
2023-10-11 20:19:08,965:INFO:Importing untrained model
2023-10-11 20:19:08,968:INFO:Naive Bayes Imported successfully
2023-10-11 20:19:08,977:INFO:Starting cross validation
2023-10-11 20:19:08,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:09,928:INFO:Calculating mean and std
2023-10-11 20:19:09,928:INFO:Creating metrics dataframe
2023-10-11 20:19:09,943:INFO:Uploading results into container
2023-10-11 20:19:09,943:INFO:Uploading model into container now
2023-10-11 20:19:09,943:INFO:_master_model_container: 3
2023-10-11 20:19:09,943:INFO:_display_container: 2
2023-10-11 20:19:09,943:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-10-11 20:19:09,943:INFO:create_model() successfully completed......................................
2023-10-11 20:19:10,059:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:10,059:INFO:Creating metrics dataframe
2023-10-11 20:19:10,059:INFO:Initializing Decision Tree Classifier
2023-10-11 20:19:10,059:INFO:Total runtime is 0.21904081503550213 minutes
2023-10-11 20:19:10,078:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:10,078:INFO:Initializing create_model()
2023-10-11 20:19:10,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:10,078:INFO:Checking exceptions
2023-10-11 20:19:10,078:INFO:Importing libraries
2023-10-11 20:19:10,078:INFO:Copying training dataset
2023-10-11 20:19:10,084:INFO:Defining folds
2023-10-11 20:19:10,084:INFO:Declaring metric variables
2023-10-11 20:19:10,086:INFO:Importing untrained model
2023-10-11 20:19:10,091:INFO:Decision Tree Classifier Imported successfully
2023-10-11 20:19:10,100:INFO:Starting cross validation
2023-10-11 20:19:10,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:11,071:INFO:Calculating mean and std
2023-10-11 20:19:11,071:INFO:Creating metrics dataframe
2023-10-11 20:19:11,071:INFO:Uploading results into container
2023-10-11 20:19:11,071:INFO:Uploading model into container now
2023-10-11 20:19:11,071:INFO:_master_model_container: 4
2023-10-11 20:19:11,071:INFO:_display_container: 2
2023-10-11 20:19:11,071:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-10-11 20:19:11,071:INFO:create_model() successfully completed......................................
2023-10-11 20:19:11,190:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:11,190:INFO:Creating metrics dataframe
2023-10-11 20:19:11,209:INFO:Initializing SVM - Linear Kernel
2023-10-11 20:19:11,210:INFO:Total runtime is 0.23823656241099042 minutes
2023-10-11 20:19:11,213:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:11,213:INFO:Initializing create_model()
2023-10-11 20:19:11,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:11,214:INFO:Checking exceptions
2023-10-11 20:19:11,214:INFO:Importing libraries
2023-10-11 20:19:11,214:INFO:Copying training dataset
2023-10-11 20:19:11,220:INFO:Defining folds
2023-10-11 20:19:11,220:INFO:Declaring metric variables
2023-10-11 20:19:11,224:INFO:Importing untrained model
2023-10-11 20:19:11,229:INFO:SVM - Linear Kernel Imported successfully
2023-10-11 20:19:11,231:INFO:Starting cross validation
2023-10-11 20:19:11,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:12,259:INFO:Calculating mean and std
2023-10-11 20:19:12,259:INFO:Creating metrics dataframe
2023-10-11 20:19:12,259:INFO:Uploading results into container
2023-10-11 20:19:12,259:INFO:Uploading model into container now
2023-10-11 20:19:12,275:INFO:_master_model_container: 5
2023-10-11 20:19:12,275:INFO:_display_container: 2
2023-10-11 20:19:12,275:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-10-11 20:19:12,275:INFO:create_model() successfully completed......................................
2023-10-11 20:19:12,406:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:12,406:INFO:Creating metrics dataframe
2023-10-11 20:19:12,426:INFO:Initializing Ridge Classifier
2023-10-11 20:19:12,426:INFO:Total runtime is 0.25849823156992596 minutes
2023-10-11 20:19:12,426:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:12,426:INFO:Initializing create_model()
2023-10-11 20:19:12,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:12,426:INFO:Checking exceptions
2023-10-11 20:19:12,426:INFO:Importing libraries
2023-10-11 20:19:12,426:INFO:Copying training dataset
2023-10-11 20:19:12,446:INFO:Defining folds
2023-10-11 20:19:12,447:INFO:Declaring metric variables
2023-10-11 20:19:12,448:INFO:Importing untrained model
2023-10-11 20:19:12,448:INFO:Ridge Classifier Imported successfully
2023-10-11 20:19:12,463:INFO:Starting cross validation
2023-10-11 20:19:12,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:14,718:INFO:Calculating mean and std
2023-10-11 20:19:14,718:INFO:Creating metrics dataframe
2023-10-11 20:19:14,736:INFO:Uploading results into container
2023-10-11 20:19:14,737:INFO:Uploading model into container now
2023-10-11 20:19:14,738:INFO:_master_model_container: 6
2023-10-11 20:19:14,738:INFO:_display_container: 2
2023-10-11 20:19:14,738:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1935, solver='auto',
                tol=0.0001)
2023-10-11 20:19:14,738:INFO:create_model() successfully completed......................................
2023-10-11 20:19:14,907:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:14,907:INFO:Creating metrics dataframe
2023-10-11 20:19:14,926:INFO:Initializing Random Forest Classifier
2023-10-11 20:19:14,926:INFO:Total runtime is 0.3001581390698751 minutes
2023-10-11 20:19:14,926:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:14,926:INFO:Initializing create_model()
2023-10-11 20:19:14,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:14,926:INFO:Checking exceptions
2023-10-11 20:19:14,926:INFO:Importing libraries
2023-10-11 20:19:14,926:INFO:Copying training dataset
2023-10-11 20:19:14,950:INFO:Defining folds
2023-10-11 20:19:14,950:INFO:Declaring metric variables
2023-10-11 20:19:14,952:INFO:Importing untrained model
2023-10-11 20:19:14,962:INFO:Random Forest Classifier Imported successfully
2023-10-11 20:19:14,968:INFO:Starting cross validation
2023-10-11 20:19:14,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:17,566:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:17,597:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:17,597:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:17,613:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:17,629:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:17,644:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:17,660:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:17,785:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:20,143:INFO:Calculating mean and std
2023-10-11 20:19:20,143:INFO:Creating metrics dataframe
2023-10-11 20:19:20,143:INFO:Uploading results into container
2023-10-11 20:19:20,143:INFO:Uploading model into container now
2023-10-11 20:19:20,143:INFO:_master_model_container: 7
2023-10-11 20:19:20,143:INFO:_display_container: 2
2023-10-11 20:19:20,143:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:19:20,143:INFO:create_model() successfully completed......................................
2023-10-11 20:19:20,305:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:20,305:INFO:Creating metrics dataframe
2023-10-11 20:19:20,327:INFO:Initializing Quadratic Discriminant Analysis
2023-10-11 20:19:20,327:INFO:Total runtime is 0.39018855889638265 minutes
2023-10-11 20:19:20,329:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:20,329:INFO:Initializing create_model()
2023-10-11 20:19:20,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:20,329:INFO:Checking exceptions
2023-10-11 20:19:20,329:INFO:Importing libraries
2023-10-11 20:19:20,329:INFO:Copying training dataset
2023-10-11 20:19:20,329:INFO:Defining folds
2023-10-11 20:19:20,329:INFO:Declaring metric variables
2023-10-11 20:19:20,347:INFO:Importing untrained model
2023-10-11 20:19:20,352:INFO:Quadratic Discriminant Analysis Imported successfully
2023-10-11 20:19:20,360:INFO:Starting cross validation
2023-10-11 20:19:20,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:20,666:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:20,666:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:20,666:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:20,666:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:20,666:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:20,682:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:20,682:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:20,698:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:21,389:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:21,437:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-11 20:19:21,939:INFO:Calculating mean and std
2023-10-11 20:19:21,939:INFO:Creating metrics dataframe
2023-10-11 20:19:21,955:INFO:Uploading results into container
2023-10-11 20:19:21,955:INFO:Uploading model into container now
2023-10-11 20:19:21,956:INFO:_master_model_container: 8
2023-10-11 20:19:21,956:INFO:_display_container: 2
2023-10-11 20:19:21,957:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-10-11 20:19:21,957:INFO:create_model() successfully completed......................................
2023-10-11 20:19:22,121:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:22,121:INFO:Creating metrics dataframe
2023-10-11 20:19:22,141:INFO:Initializing Ada Boost Classifier
2023-10-11 20:19:22,141:INFO:Total runtime is 0.42041749159495034 minutes
2023-10-11 20:19:22,141:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:22,141:INFO:Initializing create_model()
2023-10-11 20:19:22,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:22,141:INFO:Checking exceptions
2023-10-11 20:19:22,141:INFO:Importing libraries
2023-10-11 20:19:22,141:INFO:Copying training dataset
2023-10-11 20:19:22,159:INFO:Defining folds
2023-10-11 20:19:22,159:INFO:Declaring metric variables
2023-10-11 20:19:22,163:INFO:Importing untrained model
2023-10-11 20:19:22,167:INFO:Ada Boost Classifier Imported successfully
2023-10-11 20:19:22,177:INFO:Starting cross validation
2023-10-11 20:19:22,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:25,484:INFO:Calculating mean and std
2023-10-11 20:19:25,500:INFO:Creating metrics dataframe
2023-10-11 20:19:25,500:INFO:Uploading results into container
2023-10-11 20:19:25,500:INFO:Uploading model into container now
2023-10-11 20:19:25,500:INFO:_master_model_container: 9
2023-10-11 20:19:25,500:INFO:_display_container: 2
2023-10-11 20:19:25,500:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1935)
2023-10-11 20:19:25,500:INFO:create_model() successfully completed......................................
2023-10-11 20:19:25,642:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:25,642:INFO:Creating metrics dataframe
2023-10-11 20:19:25,657:INFO:Initializing Gradient Boosting Classifier
2023-10-11 20:19:25,657:INFO:Total runtime is 0.4790206631024678 minutes
2023-10-11 20:19:25,669:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:25,670:INFO:Initializing create_model()
2023-10-11 20:19:25,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:25,670:INFO:Checking exceptions
2023-10-11 20:19:25,670:INFO:Importing libraries
2023-10-11 20:19:25,670:INFO:Copying training dataset
2023-10-11 20:19:25,675:INFO:Defining folds
2023-10-11 20:19:25,675:INFO:Declaring metric variables
2023-10-11 20:19:25,680:INFO:Importing untrained model
2023-10-11 20:19:25,684:INFO:Gradient Boosting Classifier Imported successfully
2023-10-11 20:19:25,692:INFO:Starting cross validation
2023-10-11 20:19:25,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:28,937:INFO:Calculating mean and std
2023-10-11 20:19:28,953:INFO:Creating metrics dataframe
2023-10-11 20:19:28,959:INFO:Uploading results into container
2023-10-11 20:19:28,960:INFO:Uploading model into container now
2023-10-11 20:19:28,961:INFO:_master_model_container: 10
2023-10-11 20:19:28,961:INFO:_display_container: 2
2023-10-11 20:19:28,962:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-10-11 20:19:28,962:INFO:create_model() successfully completed......................................
2023-10-11 20:19:29,088:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:29,088:INFO:Creating metrics dataframe
2023-10-11 20:19:29,120:INFO:Initializing Linear Discriminant Analysis
2023-10-11 20:19:29,120:INFO:Total runtime is 0.5367257436116536 minutes
2023-10-11 20:19:29,120:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:29,120:INFO:Initializing create_model()
2023-10-11 20:19:29,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:29,120:INFO:Checking exceptions
2023-10-11 20:19:29,120:INFO:Importing libraries
2023-10-11 20:19:29,120:INFO:Copying training dataset
2023-10-11 20:19:29,136:INFO:Defining folds
2023-10-11 20:19:29,137:INFO:Declaring metric variables
2023-10-11 20:19:29,140:INFO:Importing untrained model
2023-10-11 20:19:29,143:INFO:Linear Discriminant Analysis Imported successfully
2023-10-11 20:19:29,148:INFO:Starting cross validation
2023-10-11 20:19:29,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:30,700:INFO:Calculating mean and std
2023-10-11 20:19:30,700:INFO:Creating metrics dataframe
2023-10-11 20:19:30,700:INFO:Uploading results into container
2023-10-11 20:19:30,700:INFO:Uploading model into container now
2023-10-11 20:19:30,700:INFO:_master_model_container: 11
2023-10-11 20:19:30,700:INFO:_display_container: 2
2023-10-11 20:19:30,700:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-10-11 20:19:30,700:INFO:create_model() successfully completed......................................
2023-10-11 20:19:30,858:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:30,858:INFO:Creating metrics dataframe
2023-10-11 20:19:30,877:INFO:Initializing Extra Trees Classifier
2023-10-11 20:19:30,877:INFO:Total runtime is 0.566019066174825 minutes
2023-10-11 20:19:30,877:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:30,877:INFO:Initializing create_model()
2023-10-11 20:19:30,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:30,877:INFO:Checking exceptions
2023-10-11 20:19:30,877:INFO:Importing libraries
2023-10-11 20:19:30,877:INFO:Copying training dataset
2023-10-11 20:19:30,896:INFO:Defining folds
2023-10-11 20:19:30,896:INFO:Declaring metric variables
2023-10-11 20:19:30,900:INFO:Importing untrained model
2023-10-11 20:19:30,907:INFO:Extra Trees Classifier Imported successfully
2023-10-11 20:19:30,915:INFO:Starting cross validation
2023-10-11 20:19:30,917:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:32,946:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:32,965:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:32,973:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:33,001:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:33,076:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:33,089:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:33,142:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:33,458:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:35,121:INFO:Calculating mean and std
2023-10-11 20:19:35,124:INFO:Creating metrics dataframe
2023-10-11 20:19:35,130:INFO:Uploading results into container
2023-10-11 20:19:35,131:INFO:Uploading model into container now
2023-10-11 20:19:35,132:INFO:_master_model_container: 12
2023-10-11 20:19:35,132:INFO:_display_container: 2
2023-10-11 20:19:35,133:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:19:35,133:INFO:create_model() successfully completed......................................
2023-10-11 20:19:35,260:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:35,260:INFO:Creating metrics dataframe
2023-10-11 20:19:35,278:INFO:Initializing Extreme Gradient Boosting
2023-10-11 20:19:35,278:INFO:Total runtime is 0.6393675287564595 minutes
2023-10-11 20:19:35,278:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:35,278:INFO:Initializing create_model()
2023-10-11 20:19:35,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:35,278:INFO:Checking exceptions
2023-10-11 20:19:35,284:INFO:Importing libraries
2023-10-11 20:19:35,284:INFO:Copying training dataset
2023-10-11 20:19:35,291:INFO:Defining folds
2023-10-11 20:19:35,291:INFO:Declaring metric variables
2023-10-11 20:19:35,295:INFO:Importing untrained model
2023-10-11 20:19:35,301:INFO:Extreme Gradient Boosting Imported successfully
2023-10-11 20:19:35,310:INFO:Starting cross validation
2023-10-11 20:19:35,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:37,590:INFO:Calculating mean and std
2023-10-11 20:19:37,607:INFO:Creating metrics dataframe
2023-10-11 20:19:37,612:INFO:Uploading results into container
2023-10-11 20:19:37,613:INFO:Uploading model into container now
2023-10-11 20:19:37,615:INFO:_master_model_container: 13
2023-10-11 20:19:37,615:INFO:_display_container: 2
2023-10-11 20:19:37,616:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-10-11 20:19:37,616:INFO:create_model() successfully completed......................................
2023-10-11 20:19:37,739:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:37,739:INFO:Creating metrics dataframe
2023-10-11 20:19:37,759:INFO:Initializing Light Gradient Boosting Machine
2023-10-11 20:19:37,759:INFO:Total runtime is 0.6807184855143229 minutes
2023-10-11 20:19:37,765:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:37,766:INFO:Initializing create_model()
2023-10-11 20:19:37,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:37,766:INFO:Checking exceptions
2023-10-11 20:19:37,766:INFO:Importing libraries
2023-10-11 20:19:37,766:INFO:Copying training dataset
2023-10-11 20:19:37,774:INFO:Defining folds
2023-10-11 20:19:37,774:INFO:Declaring metric variables
2023-10-11 20:19:37,781:INFO:Importing untrained model
2023-10-11 20:19:37,786:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-11 20:19:37,795:INFO:Starting cross validation
2023-10-11 20:19:37,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:19:42,377:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:19:43,358:INFO:Calculating mean and std
2023-10-11 20:19:43,358:INFO:Creating metrics dataframe
2023-10-11 20:19:43,374:INFO:Uploading results into container
2023-10-11 20:19:43,374:INFO:Uploading model into container now
2023-10-11 20:19:43,374:INFO:_master_model_container: 14
2023-10-11 20:19:43,374:INFO:_display_container: 2
2023-10-11 20:19:43,374:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-10-11 20:19:43,374:INFO:create_model() successfully completed......................................
2023-10-11 20:19:43,564:INFO:SubProcess create_model() end ==================================
2023-10-11 20:19:43,579:INFO:Creating metrics dataframe
2023-10-11 20:19:43,605:INFO:Initializing CatBoost Classifier
2023-10-11 20:19:43,605:INFO:Total runtime is 0.7781517227490743 minutes
2023-10-11 20:19:43,605:INFO:SubProcess create_model() called ==================================
2023-10-11 20:19:43,605:INFO:Initializing create_model()
2023-10-11 20:19:43,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:19:43,605:INFO:Checking exceptions
2023-10-11 20:19:43,605:INFO:Importing libraries
2023-10-11 20:19:43,605:INFO:Copying training dataset
2023-10-11 20:19:43,605:INFO:Defining folds
2023-10-11 20:19:43,605:INFO:Declaring metric variables
2023-10-11 20:19:43,622:INFO:Importing untrained model
2023-10-11 20:19:43,626:INFO:CatBoost Classifier Imported successfully
2023-10-11 20:19:43,634:INFO:Starting cross validation
2023-10-11 20:19:43,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:20:00,780:INFO:Calculating mean and std
2023-10-11 20:20:00,780:INFO:Creating metrics dataframe
2023-10-11 20:20:00,796:INFO:Uploading results into container
2023-10-11 20:20:00,796:INFO:Uploading model into container now
2023-10-11 20:20:00,796:INFO:_master_model_container: 15
2023-10-11 20:20:00,796:INFO:_display_container: 2
2023-10-11 20:20:00,796:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69BB107F0>
2023-10-11 20:20:00,796:INFO:create_model() successfully completed......................................
2023-10-11 20:20:00,977:INFO:SubProcess create_model() end ==================================
2023-10-11 20:20:00,977:INFO:Creating metrics dataframe
2023-10-11 20:20:01,002:INFO:Initializing Dummy Classifier
2023-10-11 20:20:01,002:INFO:Total runtime is 1.0680962006251018 minutes
2023-10-11 20:20:01,012:INFO:SubProcess create_model() called ==================================
2023-10-11 20:20:01,013:INFO:Initializing create_model()
2023-10-11 20:20:01,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA80D00>, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:20:01,013:INFO:Checking exceptions
2023-10-11 20:20:01,013:INFO:Importing libraries
2023-10-11 20:20:01,013:INFO:Copying training dataset
2023-10-11 20:20:01,020:INFO:Defining folds
2023-10-11 20:20:01,020:INFO:Declaring metric variables
2023-10-11 20:20:01,025:INFO:Importing untrained model
2023-10-11 20:20:01,029:INFO:Dummy Classifier Imported successfully
2023-10-11 20:20:01,036:INFO:Starting cross validation
2023-10-11 20:20:01,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:20:01,766:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:01,811:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:01,909:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:01,918:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:01,943:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:01,963:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:01,979:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:01,999:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:02,654:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:02,687:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-11 20:20:02,704:INFO:Calculating mean and std
2023-10-11 20:20:02,704:INFO:Creating metrics dataframe
2023-10-11 20:20:02,718:INFO:Uploading results into container
2023-10-11 20:20:02,719:INFO:Uploading model into container now
2023-10-11 20:20:02,720:INFO:_master_model_container: 16
2023-10-11 20:20:02,720:INFO:_display_container: 2
2023-10-11 20:20:02,721:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-10-11 20:20:02,721:INFO:create_model() successfully completed......................................
2023-10-11 20:20:02,885:INFO:SubProcess create_model() end ==================================
2023-10-11 20:20:02,885:INFO:Creating metrics dataframe
2023-10-11 20:20:02,949:INFO:Initializing create_model()
2023-10-11 20:20:02,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:20:02,949:INFO:Checking exceptions
2023-10-11 20:20:02,953:INFO:Importing libraries
2023-10-11 20:20:02,953:INFO:Copying training dataset
2023-10-11 20:20:02,959:INFO:Defining folds
2023-10-11 20:20:02,959:INFO:Declaring metric variables
2023-10-11 20:20:02,959:INFO:Importing untrained model
2023-10-11 20:20:02,959:INFO:Declaring custom model
2023-10-11 20:20:02,960:INFO:Random Forest Classifier Imported successfully
2023-10-11 20:20:02,963:INFO:Cross validation set to False
2023-10-11 20:20:02,963:INFO:Fitting Model
2023-10-11 20:20:03,790:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:20:03,790:INFO:create_model() successfully completed......................................
2023-10-11 20:20:03,949:INFO:_master_model_container: 16
2023-10-11 20:20:03,949:INFO:_display_container: 2
2023-10-11 20:20:03,949:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:20:03,949:INFO:compare_models() successfully completed......................................
2023-10-11 20:25:36,880:INFO:Initializing create_model()
2023-10-11 20:25:36,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:25:36,881:INFO:Checking exceptions
2023-10-11 20:25:36,923:INFO:Importing libraries
2023-10-11 20:25:36,924:INFO:Copying training dataset
2023-10-11 20:25:36,931:INFO:Defining folds
2023-10-11 20:25:36,932:INFO:Declaring metric variables
2023-10-11 20:25:36,935:INFO:Importing untrained model
2023-10-11 20:25:36,940:INFO:CatBoost Classifier Imported successfully
2023-10-11 20:25:36,950:INFO:Starting cross validation
2023-10-11 20:25:36,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:25:46,086:INFO:Calculating mean and std
2023-10-11 20:25:46,086:INFO:Creating metrics dataframe
2023-10-11 20:25:46,086:INFO:Finalizing model
2023-10-11 20:25:48,441:INFO:Uploading results into container
2023-10-11 20:25:48,452:INFO:Uploading model into container now
2023-10-11 20:25:48,461:INFO:_master_model_container: 17
2023-10-11 20:25:48,462:INFO:_display_container: 3
2023-10-11 20:25:48,462:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>
2023-10-11 20:25:48,462:INFO:create_model() successfully completed......................................
2023-10-11 20:33:31,249:INFO:Initializing predict_model()
2023-10-11 20:33:31,249:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E69C22D9D0>)
2023-10-11 20:33:31,249:INFO:Checking exceptions
2023-10-11 20:33:31,249:INFO:Preloading libraries
2023-10-11 20:33:31,252:INFO:Set up data.
2023-10-11 20:33:31,259:INFO:Set up index.
2023-10-11 20:35:03,571:INFO:Initializing create_model()
2023-10-11 20:35:03,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:35:03,571:INFO:Checking exceptions
2023-10-11 20:35:03,600:INFO:Importing libraries
2023-10-11 20:35:03,601:INFO:Copying training dataset
2023-10-11 20:35:03,605:INFO:Defining folds
2023-10-11 20:35:03,605:INFO:Declaring metric variables
2023-10-11 20:35:03,609:INFO:Importing untrained model
2023-10-11 20:35:03,612:INFO:Random Forest Classifier Imported successfully
2023-10-11 20:35:03,622:INFO:Starting cross validation
2023-10-11 20:35:03,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:35:11,889:INFO:Calculating mean and std
2023-10-11 20:35:11,889:INFO:Creating metrics dataframe
2023-10-11 20:35:11,904:INFO:Finalizing model
2023-10-11 20:35:12,103:INFO:Uploading results into container
2023-10-11 20:35:12,103:INFO:Uploading model into container now
2023-10-11 20:35:12,121:INFO:_master_model_container: 18
2023-10-11 20:35:12,122:INFO:_display_container: 5
2023-10-11 20:35:12,122:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:35:12,122:INFO:create_model() successfully completed......................................
2023-10-11 20:35:22,313:INFO:Initializing predict_model()
2023-10-11 20:35:22,314:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E69C22DA60>)
2023-10-11 20:35:22,314:INFO:Checking exceptions
2023-10-11 20:35:22,314:INFO:Preloading libraries
2023-10-11 20:35:22,315:INFO:Set up data.
2023-10-11 20:35:22,321:INFO:Set up index.
2023-10-11 20:36:20,755:INFO:Initializing tune_model()
2023-10-11 20:36:20,755:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>)
2023-10-11 20:36:20,755:INFO:Checking exceptions
2023-10-11 20:36:20,778:INFO:Copying training dataset
2023-10-11 20:36:20,799:INFO:Checking base model
2023-10-11 20:36:20,800:INFO:Base model : CatBoost Classifier
2023-10-11 20:36:20,804:INFO:Declaring metric variables
2023-10-11 20:36:20,804:INFO:Defining Hyperparameters
2023-10-11 20:36:20,940:INFO:Tuning with n_jobs=-1
2023-10-11 20:36:20,941:INFO:Initializing RandomizedSearchCV
2023-10-11 20:36:26,367:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:27,864:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:28,189:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:31,622:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:33,211:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:33,398:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:36,553:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:36,648:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:37,056:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:37,365:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:37,748:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:38,407:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:38,706:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:39,649:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:44,955:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:45,049:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:47,597:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:47,628:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:48,086:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:49,288:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:49,502:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:50,476:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:53,709:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:53,725:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:54,103:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:55,030:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:55,187:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:55,706:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:55,956:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:56,240:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:57,889:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:58,376:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:58,505:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:59,116:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:36:59,494:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:37:00,234:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:37:00,570:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:37:01,448:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 100, 'actual_estimator__eta': 0.01, 'actual_estimator__depth': 3}
2023-10-11 20:37:01,464:INFO:Hyperparameter search completed
2023-10-11 20:37:01,464:INFO:SubProcess create_model() called ==================================
2023-10-11 20:37:01,464:INFO:Initializing create_model()
2023-10-11 20:37:01,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69C331A30>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69BA4CD30>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.8, 'n_estimators': 280, 'l2_leaf_reg': 100, 'eta': 0.01, 'depth': 3})
2023-10-11 20:37:01,464:INFO:Checking exceptions
2023-10-11 20:37:01,464:INFO:Importing libraries
2023-10-11 20:37:01,464:INFO:Copying training dataset
2023-10-11 20:37:01,476:INFO:Defining folds
2023-10-11 20:37:01,476:INFO:Declaring metric variables
2023-10-11 20:37:01,476:INFO:Importing untrained model
2023-10-11 20:37:01,482:INFO:Declaring custom model
2023-10-11 20:37:01,492:INFO:CatBoost Classifier Imported successfully
2023-10-11 20:37:01,508:INFO:Starting cross validation
2023-10-11 20:37:01,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:37:03,736:INFO:Calculating mean and std
2023-10-11 20:37:03,736:INFO:Creating metrics dataframe
2023-10-11 20:37:03,751:INFO:Finalizing model
2023-10-11 20:37:04,591:INFO:Uploading results into container
2023-10-11 20:37:04,592:INFO:Uploading model into container now
2023-10-11 20:37:04,593:INFO:_master_model_container: 19
2023-10-11 20:37:04,593:INFO:_display_container: 7
2023-10-11 20:37:04,593:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69C42A8E0>
2023-10-11 20:37:04,593:INFO:create_model() successfully completed......................................
2023-10-11 20:37:04,757:INFO:SubProcess create_model() end ==================================
2023-10-11 20:37:04,757:INFO:choose_better activated
2023-10-11 20:37:04,768:INFO:SubProcess create_model() called ==================================
2023-10-11 20:37:04,768:INFO:Initializing create_model()
2023-10-11 20:37:04,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:37:04,769:INFO:Checking exceptions
2023-10-11 20:37:04,772:INFO:Importing libraries
2023-10-11 20:37:04,772:INFO:Copying training dataset
2023-10-11 20:37:04,776:INFO:Defining folds
2023-10-11 20:37:04,776:INFO:Declaring metric variables
2023-10-11 20:37:04,776:INFO:Importing untrained model
2023-10-11 20:37:04,776:INFO:Declaring custom model
2023-10-11 20:37:04,776:INFO:CatBoost Classifier Imported successfully
2023-10-11 20:37:04,776:INFO:Starting cross validation
2023-10-11 20:37:04,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:37:06,439:INFO:Calculating mean and std
2023-10-11 20:37:06,454:INFO:Creating metrics dataframe
2023-10-11 20:37:06,454:INFO:Finalizing model
2023-10-11 20:37:06,784:INFO:Uploading results into container
2023-10-11 20:37:06,784:INFO:Uploading model into container now
2023-10-11 20:37:06,784:INFO:_master_model_container: 20
2023-10-11 20:37:06,784:INFO:_display_container: 8
2023-10-11 20:37:06,784:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69C32C4F0>
2023-10-11 20:37:06,784:INFO:create_model() successfully completed......................................
2023-10-11 20:37:06,942:INFO:SubProcess create_model() end ==================================
2023-10-11 20:37:06,942:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69C32C4F0> result for Accuracy is 0.8268
2023-10-11 20:37:06,942:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69C42A8E0> result for Accuracy is 0.8574
2023-10-11 20:37:06,942:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69C42A8E0> is best model
2023-10-11 20:37:06,942:INFO:choose_better completed
2023-10-11 20:37:06,973:INFO:_master_model_container: 20
2023-10-11 20:37:06,973:INFO:_display_container: 7
2023-10-11 20:37:06,973:INFO:<catboost.core.CatBoostClassifier object at 0x000001E69C42A8E0>
2023-10-11 20:37:06,973:INFO:tune_model() successfully completed......................................
2023-10-11 20:38:26,465:INFO:Initializing predict_model()
2023-10-11 20:38:26,465:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69C42A8E0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E69C1F7E50>)
2023-10-11 20:38:26,465:INFO:Checking exceptions
2023-10-11 20:38:26,466:INFO:Preloading libraries
2023-10-11 20:38:26,468:INFO:Set up data.
2023-10-11 20:38:26,474:INFO:Set up index.
2023-10-11 20:41:17,924:INFO:Initializing tune_model()
2023-10-11 20:41:17,924:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=None, round=4, n_iter=25, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>)
2023-10-11 20:41:17,924:INFO:Checking exceptions
2023-10-11 20:41:17,956:INFO:Copying training dataset
2023-10-11 20:41:17,956:INFO:Checking base model
2023-10-11 20:41:17,956:INFO:Base model : Random Forest Classifier
2023-10-11 20:41:17,975:INFO:Declaring metric variables
2023-10-11 20:41:17,975:INFO:Defining Hyperparameters
2023-10-11 20:41:18,108:INFO:Tuning with n_jobs=-1
2023-10-11 20:41:18,108:INFO:Initializing RandomizedSearchCV
2023-10-11 20:41:21,639:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:23,136:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:23,201:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:23,271:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:24,005:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:27,714:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:27,928:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:30,422:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:33,155:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:33,187:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:33,359:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:34,160:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:34,191:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:34,317:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:34,349:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:35,425:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:35,509:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:35,556:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:35,969:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:36,688:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:36,769:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:36,802:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:36,944:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:37,838:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:37,917:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:38,922:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:39,314:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:39,832:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:39,864:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:39,879:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:40,020:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:41,025:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:41,056:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:41,056:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:41,512:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:41,622:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:41,637:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:41,669:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:41,873:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:43,115:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:43,131:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:44,123:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:44,232:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:44,295:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:44,374:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:44,546:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:45,488:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:45,551:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:45,881:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:46,431:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:47,453:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:49,048:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:49,120:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:49,645:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:49,975:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:50,007:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:50,023:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:50,132:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:50,714:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:50,887:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:50,952:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:51,770:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:51,980:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:52,043:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:52,090:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:52,297:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:53,004:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:54,239:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:54,281:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:55,143:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:55,278:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:55,294:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:55,294:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:55,468:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:55,880:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:55,891:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:56,231:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:56,859:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:57,000:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:57,016:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:57,016:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:57,257:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:58,136:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:41:58,916:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:41:58,932:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:00,127:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:00,174:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:00,897:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:00,913:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:02,277:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:02,328:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:02,403:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:02,812:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:04,818:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:04,834:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:04,849:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:05,306:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:05,727:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:05,743:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:05,743:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:06,034:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:06,768:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:06,851:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:06,900:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:07,368:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:07,768:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:08,025:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:08,066:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:08,285:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:08,980:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:10,184:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:10,267:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:10,318:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:10,799:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:10,831:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:11,026:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:11,131:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:11,296:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:12,446:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:12,635:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:13,494:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:13,918:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:13,955:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:13,987:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:14,128:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:14,252:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:15,234:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:15,391:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:15,820:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:16,113:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:16,333:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:16,479:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:16,600:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:16,946:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:16,993:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:17,025:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:18,281:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:18,461:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:18,461:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:18,603:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:18,826:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:18,916:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:19,771:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:19,834:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:20,308:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:20,664:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:20,838:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:20,884:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:21,308:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:21,308:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:21,457:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:22,662:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:22,741:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:22,851:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:23,134:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:23,328:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:23,353:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:24,082:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:24,358:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:24,641:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:24,861:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:25,426:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:25,708:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:26,384:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:26,480:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:26,589:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:26,871:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:26,936:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:27,168:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:28,180:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:28,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:28,731:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:28,889:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:28,999:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:29,124:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:29,626:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:29,784:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:29,847:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:30,377:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:30,397:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:30,662:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:32,229:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:32,375:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:32,860:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:33,001:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:33,037:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:33,505:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:33,521:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:33,852:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:36,971:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:37,977:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:37,993:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:38,307:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:39,296:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:39,421:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:40,054:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:40,559:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:40,569:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:40,947:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:40,947:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:41,339:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:42,519:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:42,519:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:42,663:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:43,303:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:43,585:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:43,790:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:43,946:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:43,978:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:44,512:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:45,471:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:45,502:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:45,549:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:45,832:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:45,879:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:46,271:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:46,271:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:46,671:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:47,473:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:47,505:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:48,636:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:48,699:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:49,142:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:49,504:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:49,787:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:50,383:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:50,807:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:51,153:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:51,180:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:51,373:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:52,315:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:52,488:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:52,912:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:53,070:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:53,462:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:53,509:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:54,751:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:55,087:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:55,160:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:55,588:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:55,820:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:56,265:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-10-11 20:42:56,762:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:57,422:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:58,003:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:58,332:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:42:59,967:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:00,030:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:00,899:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:01,070:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:01,085:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:01,148:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:01,148:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:01,227:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-11 20:43:02,467:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-10-11 20:43:02,467:INFO:Hyperparameter search completed
2023-10-11 20:43:02,467:INFO:SubProcess create_model() called ==================================
2023-10-11 20:43:02,467:INFO:Initializing create_model()
2023-10-11 20:43:02,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E69C2A3550>, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': False})
2023-10-11 20:43:02,467:INFO:Checking exceptions
2023-10-11 20:43:02,467:INFO:Importing libraries
2023-10-11 20:43:02,467:INFO:Copying training dataset
2023-10-11 20:43:02,484:INFO:Defining folds
2023-10-11 20:43:02,485:INFO:Declaring metric variables
2023-10-11 20:43:02,485:INFO:Importing untrained model
2023-10-11 20:43:02,485:INFO:Declaring custom model
2023-10-11 20:43:02,496:INFO:Random Forest Classifier Imported successfully
2023-10-11 20:43:02,512:INFO:Starting cross validation
2023-10-11 20:43:02,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:43:06,797:INFO:Calculating mean and std
2023-10-11 20:43:06,797:INFO:Creating metrics dataframe
2023-10-11 20:43:06,813:INFO:Finalizing model
2023-10-11 20:43:07,811:INFO:Uploading results into container
2023-10-11 20:43:07,817:INFO:Uploading model into container now
2023-10-11 20:43:07,817:INFO:_master_model_container: 21
2023-10-11 20:43:07,817:INFO:_display_container: 9
2023-10-11 20:43:07,818:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:43:07,819:INFO:create_model() successfully completed......................................
2023-10-11 20:43:07,911:INFO:SubProcess create_model() end ==================================
2023-10-11 20:43:07,924:INFO:choose_better activated
2023-10-11 20:43:07,924:INFO:SubProcess create_model() called ==================================
2023-10-11 20:43:07,924:INFO:Initializing create_model()
2023-10-11 20:43:07,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-11 20:43:07,924:INFO:Checking exceptions
2023-10-11 20:43:07,924:INFO:Importing libraries
2023-10-11 20:43:07,930:INFO:Copying training dataset
2023-10-11 20:43:07,936:INFO:Defining folds
2023-10-11 20:43:07,936:INFO:Declaring metric variables
2023-10-11 20:43:07,936:INFO:Importing untrained model
2023-10-11 20:43:07,936:INFO:Declaring custom model
2023-10-11 20:43:07,936:INFO:Random Forest Classifier Imported successfully
2023-10-11 20:43:07,936:INFO:Starting cross validation
2023-10-11 20:43:07,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-11 20:43:09,642:INFO:Calculating mean and std
2023-10-11 20:43:09,642:INFO:Creating metrics dataframe
2023-10-11 20:43:09,658:INFO:Finalizing model
2023-10-11 20:43:10,020:INFO:Uploading results into container
2023-10-11 20:43:10,020:INFO:Uploading model into container now
2023-10-11 20:43:10,020:INFO:_master_model_container: 22
2023-10-11 20:43:10,020:INFO:_display_container: 10
2023-10-11 20:43:10,020:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:43:10,020:INFO:create_model() successfully completed......................................
2023-10-11 20:43:10,176:INFO:SubProcess create_model() end ==================================
2023-10-11 20:43:10,176:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) result for Accuracy is 0.8268
2023-10-11 20:43:10,176:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) result for Accuracy is 0.8424
2023-10-11 20:43:10,176:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) is best model
2023-10-11 20:43:10,176:INFO:choose_better completed
2023-10-11 20:43:10,192:INFO:_master_model_container: 22
2023-10-11 20:43:10,192:INFO:_display_container: 9
2023-10-11 20:43:10,209:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-11 20:43:10,209:INFO:tune_model() successfully completed......................................
2023-10-11 20:43:25,241:INFO:Initializing predict_model()
2023-10-11 20:43:25,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E69C2A0940>)
2023-10-11 20:43:25,242:INFO:Checking exceptions
2023-10-11 20:43:25,242:INFO:Preloading libraries
2023-10-11 20:43:25,243:INFO:Set up data.
2023-10-11 20:43:25,249:INFO:Set up index.
2023-10-11 20:43:42,079:INFO:Initializing plot_model()
2023-10-11 20:43:42,079:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, system=True)
2023-10-11 20:43:42,080:INFO:Checking exceptions
2023-10-11 20:43:42,085:INFO:Preloading libraries
2023-10-11 20:43:42,089:INFO:Copying training dataset
2023-10-11 20:43:42,089:INFO:Plot type: auc
2023-10-11 20:43:42,348:INFO:Fitting Model
2023-10-11 20:43:42,365:INFO:Scoring test/hold-out set
2023-10-11 20:43:42,655:INFO:Visual Rendered Successfully
2023-10-11 20:43:42,752:INFO:plot_model() successfully completed......................................
2023-10-11 20:44:02,605:INFO:Initializing plot_model()
2023-10-11 20:44:02,606:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, system=True)
2023-10-11 20:44:02,606:INFO:Checking exceptions
2023-10-11 20:44:02,610:INFO:Preloading libraries
2023-10-11 20:44:02,612:INFO:Copying training dataset
2023-10-11 20:44:02,612:INFO:Plot type: ks
2023-10-11 20:44:02,613:INFO:Generating predictions / predict_proba on X_test
2023-10-11 20:44:02,953:INFO:Visual Rendered Successfully
2023-10-11 20:44:03,035:INFO:plot_model() successfully completed......................................
2023-10-11 20:44:53,298:INFO:Initializing plot_model()
2023-10-11 20:44:53,299:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, system=True)
2023-10-11 20:44:53,299:INFO:Checking exceptions
2023-10-11 20:44:53,304:INFO:Preloading libraries
2023-10-11 20:44:53,306:INFO:Copying training dataset
2023-10-11 20:44:53,306:INFO:Plot type: confusion_matrix
2023-10-11 20:44:53,573:INFO:Fitting Model
2023-10-11 20:44:53,573:INFO:Scoring test/hold-out set
2023-10-11 20:44:53,698:INFO:Visual Rendered Successfully
2023-10-11 20:44:53,809:INFO:plot_model() successfully completed......................................
2023-10-11 20:46:08,930:INFO:Initializing evaluate_model()
2023-10-11 20:46:08,930:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-10-11 20:46:08,959:INFO:Initializing plot_model()
2023-10-11 20:46:08,959:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, system=True)
2023-10-11 20:46:08,959:INFO:Checking exceptions
2023-10-11 20:46:08,961:INFO:Preloading libraries
2023-10-11 20:46:08,961:INFO:Copying training dataset
2023-10-11 20:46:08,961:INFO:Plot type: pipeline
2023-10-11 20:46:09,111:INFO:Visual Rendered Successfully
2023-10-11 20:46:09,228:INFO:plot_model() successfully completed......................................
2023-10-11 20:46:33,316:INFO:Initializing plot_model()
2023-10-11 20:46:33,316:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, system=True)
2023-10-11 20:46:33,316:INFO:Checking exceptions
2023-10-11 20:46:33,319:INFO:Preloading libraries
2023-10-11 20:46:33,321:INFO:Copying training dataset
2023-10-11 20:46:33,321:INFO:Plot type: ks
2023-10-11 20:46:33,321:INFO:Generating predictions / predict_proba on X_test
2023-10-11 20:46:33,578:INFO:Visual Rendered Successfully
2023-10-11 20:46:33,689:INFO:plot_model() successfully completed......................................
2023-10-11 20:46:46,521:INFO:Initializing plot_model()
2023-10-11 20:46:46,521:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, system=True)
2023-10-11 20:46:46,521:INFO:Checking exceptions
2023-10-11 20:46:46,521:INFO:Preloading libraries
2023-10-11 20:46:46,521:INFO:Copying training dataset
2023-10-11 20:46:46,521:INFO:Plot type: feature_all
2023-10-11 20:46:46,598:WARNING:No coef_ found. Trying feature_importances_
2023-10-11 20:46:46,905:INFO:Visual Rendered Successfully
2023-10-11 20:46:46,993:INFO:plot_model() successfully completed......................................
2023-10-11 20:47:29,032:INFO:Initializing interpret_model()
2023-10-11 20:47:29,033:INFO:interpret_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>)
2023-10-11 20:47:29,033:INFO:Checking exceptions
2023-10-11 20:47:29,033:INFO:Soft dependency imported: shap: 0.42.1
2023-10-11 20:47:29,682:WARNING:Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)

2023-10-11 20:47:29,868:INFO:plot type: summary
2023-10-11 20:47:29,868:INFO:Creating TreeExplainer
2023-10-11 20:47:29,963:INFO:Compiling shap values
2023-10-11 20:47:31,108:INFO:Visual Rendered Successfully
2023-10-11 20:47:31,108:INFO:interpret_model() successfully completed......................................
2023-10-11 20:47:55,701:INFO:Initializing predict_model()
2023-10-11 20:47:55,701:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E69BAE7F70>)
2023-10-11 20:47:55,701:INFO:Checking exceptions
2023-10-11 20:47:55,701:INFO:Preloading libraries
2023-10-11 20:47:55,705:INFO:Set up data.
2023-10-11 20:47:55,710:INFO:Set up index.
2023-10-11 20:48:57,954:INFO:Initializing predict_model()
2023-10-11 20:48:57,955:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001E69BC045E0>)
2023-10-11 20:48:57,955:INFO:Checking exceptions
2023-10-11 20:48:57,955:INFO:Preloading libraries
2023-10-11 20:48:57,958:INFO:Set up data.
2023-10-11 20:48:57,968:INFO:Set up index.
2023-10-11 20:50:50,993:INFO:Initializing save_model()
2023-10-11 20:50:50,994:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, model_name=exp_01_catboost, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-10-11 20:50:50,994:INFO:Adding model into prep_pipe
2023-10-11 20:50:51,005:INFO:exp_01_catboost.pkl saved in current working directory
2023-10-11 20:50:51,064:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>)],
         verbose=False)
2023-10-11 20:50:51,064:INFO:save_model() successfully completed......................................
2023-10-11 20:51:10,883:INFO:Initializing load_model()
2023-10-11 20:51:10,884:INFO:load_model(model_name=exp_01_catboost, platform=None, authentication=None, verbose=True)
2023-10-11 20:51:16,483:INFO:Initializing finalize_model()
2023-10-11 20:51:16,483:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-11 20:51:16,483:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>
2023-10-11 20:51:16,483:INFO:Initializing create_model()
2023-10-11 20:51:16,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E69BB36C40>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E69BC3B6D0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-11 20:51:16,483:INFO:Checking exceptions
2023-10-11 20:51:16,483:INFO:Importing libraries
2023-10-11 20:51:16,483:INFO:Copying training dataset
2023-10-11 20:51:16,483:INFO:Defining folds
2023-10-11 20:51:16,483:INFO:Declaring metric variables
2023-10-11 20:51:16,483:INFO:Importing untrained model
2023-10-11 20:51:16,483:INFO:Declaring custom model
2023-10-11 20:51:16,483:INFO:CatBoost Classifier Imported successfully
2023-10-11 20:51:16,495:INFO:Cross validation set to False
2023-10-11 20:51:16,495:INFO:Fitting Model
2023-10-11 20:51:18,834:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001E69E14A580>)],
         verbose=False)
2023-10-11 20:51:18,834:INFO:create_model() successfully completed......................................
2023-10-11 20:51:18,935:INFO:_master_model_container: 22
2023-10-11 20:51:18,935:INFO:_display_container: 12
2023-10-11 20:51:18,998:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001E69E14A580>)],
         verbose=False)
2023-10-11 20:51:18,998:INFO:finalize_model() successfully completed......................................
2023-10-15 16:15:41,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 16:15:41,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 16:15:41,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 16:15:41,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-15 16:15:42,819:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-10-15 16:56:13,970:INFO:PyCaret ClassificationExperiment
2023-10-15 16:56:13,980:INFO:Logging name: EXP_01_WANDA_2023
2023-10-15 16:56:13,980:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-10-15 16:56:13,980:INFO:version 3.0.0.rc9
2023-10-15 16:56:13,980:INFO:Initializing setup()
2023-10-15 16:56:13,980:INFO:self.USI: 14a7
2023-10-15 16:56:13,980:INFO:self._variable_keys: {'memory', 'y_train', 'X', 'fold_groups_param', 'log_plots_param', 'X_test', 'seed', 'target_param', 'logging_param', 'gpu_n_jobs_param', '_available_plots', 'n_jobs_param', 'exp_name_log', 'fold_shuffle_param', 'html_param', 'X_train', '_ml_usecase', 'pipeline', 'fold_generator', 'exp_id', 'USI', 'y_test', 'idx', 'y', 'fix_imbalance', 'gpu_param', 'data', 'is_multiclass'}
2023-10-15 16:56:13,980:INFO:Checking environment
2023-10-15 16:56:13,987:INFO:python_version: 3.9.13
2023-10-15 16:56:13,987:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-10-15 16:56:13,987:INFO:machine: AMD64
2023-10-15 16:56:13,987:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-15 16:56:13,994:INFO:Memory: svmem(total=8266518528, available=950886400, percent=88.5, used=7315632128, free=950886400)
2023-10-15 16:56:13,994:INFO:Physical Core: 4
2023-10-15 16:56:13,996:INFO:Logical Core: 8
2023-10-15 16:56:13,996:INFO:Checking libraries
2023-10-15 16:56:13,996:INFO:System:
2023-10-15 16:56:13,998:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-10-15 16:56:13,998:INFO:executable: C:\Users\zaian\anaconda3\python.exe
2023-10-15 16:56:13,998:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-15 16:56:13,998:INFO:PyCaret required dependencies:
2023-10-15 16:56:14,002:INFO:                 pip: 22.2.2
2023-10-15 16:56:14,002:INFO:          setuptools: 63.4.1
2023-10-15 16:56:14,002:INFO:             pycaret: 3.0.0rc9
2023-10-15 16:56:14,002:INFO:             IPython: 7.31.1
2023-10-15 16:56:14,002:INFO:          ipywidgets: 7.6.5
2023-10-15 16:56:14,002:INFO:                tqdm: 4.64.1
2023-10-15 16:56:14,002:INFO:               numpy: 1.21.5
2023-10-15 16:56:14,002:INFO:              pandas: 1.4.4
2023-10-15 16:56:14,002:INFO:              jinja2: 3.0.3
2023-10-15 16:56:14,002:INFO:               scipy: 1.9.1
2023-10-15 16:56:14,002:INFO:              joblib: 1.2.0
2023-10-15 16:56:14,002:INFO:             sklearn: 1.2.2
2023-10-15 16:56:14,002:INFO:                pyod: 1.0.7
2023-10-15 16:56:14,002:INFO:            imblearn: 0.10.1
2023-10-15 16:56:14,002:INFO:   category_encoders: 2.6.0
2023-10-15 16:56:14,002:INFO:            lightgbm: 3.3.5
2023-10-15 16:56:14,002:INFO:               numba: 0.55.1
2023-10-15 16:56:14,002:INFO:            requests: 2.28.1
2023-10-15 16:56:14,002:INFO:          matplotlib: 3.5.2
2023-10-15 16:56:14,002:INFO:          scikitplot: 0.3.7
2023-10-15 16:56:14,002:INFO:         yellowbrick: 1.5
2023-10-15 16:56:14,002:INFO:              plotly: 5.16.1
2023-10-15 16:56:14,002:INFO:             kaleido: 0.2.1
2023-10-15 16:56:14,002:INFO:         statsmodels: 0.14.0
2023-10-15 16:56:14,002:INFO:              sktime: 0.16.1
2023-10-15 16:56:14,002:INFO:               tbats: 1.1.2
2023-10-15 16:56:14,002:INFO:            pmdarima: 2.0.2
2023-10-15 16:56:14,002:INFO:              psutil: 5.9.0
2023-10-15 16:56:14,002:INFO:PyCaret optional dependencies:
2023-10-15 16:56:14,034:INFO:                shap: 0.42.1
2023-10-15 16:56:14,034:INFO:           interpret: 0.4.4
2023-10-15 16:56:14,034:INFO:                umap: 0.5.3
2023-10-15 16:56:14,034:INFO:    pandas_profiling: 4.3.1
2023-10-15 16:56:14,036:INFO:  explainerdashboard: 0.4.3
2023-10-15 16:56:14,036:INFO:             autoviz: 0.1.720
2023-10-15 16:56:14,036:INFO:           fairlearn: 0.7.0
2023-10-15 16:56:14,036:INFO:             xgboost: 1.7.5
2023-10-15 16:56:14,036:INFO:            catboost: 1.2
2023-10-15 16:56:14,036:INFO:              kmodes: Not installed
2023-10-15 16:56:14,036:INFO:             mlxtend: Not installed
2023-10-15 16:56:14,036:INFO:       statsforecast: Not installed
2023-10-15 16:56:14,036:INFO:        tune_sklearn: Not installed
2023-10-15 16:56:14,036:INFO:                 ray: Not installed
2023-10-15 16:56:14,036:INFO:            hyperopt: Not installed
2023-10-15 16:56:14,036:INFO:              optuna: Not installed
2023-10-15 16:56:14,036:INFO:               skopt: Not installed
2023-10-15 16:56:14,036:INFO:              mlflow: Not installed
2023-10-15 16:56:14,036:INFO:              gradio: Not installed
2023-10-15 16:56:14,036:INFO:             fastapi: Not installed
2023-10-15 16:56:14,036:INFO:             uvicorn: Not installed
2023-10-15 16:56:14,036:INFO:              m2cgen: 0.10.0
2023-10-15 16:56:14,036:INFO:           evidently: Not installed
2023-10-15 16:56:14,036:INFO:               fugue: Not installed
2023-10-15 16:56:14,036:INFO:           streamlit: Not installed
2023-10-15 16:56:14,036:INFO:             prophet: Not installed
2023-10-15 16:56:14,036:INFO:None
2023-10-15 16:56:14,038:INFO:Set up data.
2023-10-15 16:56:14,231:INFO:Set up train/test split.
2023-10-15 16:56:14,298:INFO:Set up index.
2023-10-15 16:56:14,298:INFO:Set up folding strategy.
2023-10-15 16:56:14,298:INFO:Assigning column types.
2023-10-15 16:56:14,306:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-15 16:56:14,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 16:56:14,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-15 16:56:14,536:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:15,026:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:15,270:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-15 16:56:15,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-15 16:56:15,298:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:15,298:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:15,298:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-15 16:56:15,336:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-15 16:56:15,360:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:15,360:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:15,401:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-15 16:56:15,426:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:15,426:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:15,426:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-10-15 16:56:15,486:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:15,491:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:15,556:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:15,557:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:15,581:INFO:Preparing preprocessing pipeline...
2023-10-15 16:56:15,590:INFO:Set up simple imputation.
2023-10-15 16:56:15,598:INFO:Set up encoding of ordinal features.
2023-10-15 16:56:15,606:INFO:Set up encoding of categorical features.
2023-10-15 16:56:15,606:INFO:Set up feature normalization.
2023-10-15 16:56:15,838:INFO:Finished creating preprocessing pipeline.
2023-10-15 16:56:15,886:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-10-15 16:56:15,886:INFO:Creating final display dataframe.
2023-10-15 16:56:16,296:INFO:Setup _display_container:                     Description              Value
0                    Session id               1935
1                        Target               ALVO
2                   Target type             Binary
3           Original data shape          (303, 14)
4        Transformed data shape          (303, 23)
5   Transformed train set shape          (196, 23)
6    Transformed test set shape          (107, 23)
7              Ordinal features                  3
8              Numeric features                  6
9          Categorical features                  7
10     Rows with missing values               2.0%
11                   Preprocess               True
12              Imputation type             simple
13           Numeric imputation               mean
14       Categorical imputation               mode
15     Maximum one-hot encoding                 25
16              Encoding method               None
17                    Normalize               True
18             Normalize method             zscore
19               Fold Generator    StratifiedKFold
20                  Fold Number                 10
21                     CPU Jobs                 -1
22                      Use GPU              False
23               Log Experiment              False
24              Experiment Name  EXP_01_WANDA_2023
25                          USI               14a7
2023-10-15 16:56:16,418:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:16,421:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:16,482:INFO:Soft dependency imported: xgboost: 1.7.5
2023-10-15 16:56:16,484:INFO:Soft dependency imported: catboost: 1.2
2023-10-15 16:56:16,486:INFO:setup() successfully completed in 2.63s...............
2023-10-15 17:00:40,076:INFO:Initializing get_config()
2023-10-15 17:00:40,079:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, variable=train)
2023-10-15 17:00:40,079:INFO:Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
2023-10-15 17:00:40,082:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-10-15 17:00:40,098:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
0     49    MALE    LEVEL_3                     120               188   
1     39  FEMALE    LEVEL_3                     138               220   
2     52    MALE    LEVEL_4                     125               212   
3     41    MALE    LEVEL_4                     110               172   
4     57    MALE    LEVEL_4                     152               274   
..   ...     ...        ...                     ...               ...   
191   46  FEMALE    LEVEL_4                     138               243   
192   57    MALE    LEVEL_4                     110               335   
193   55    MALE    LEVEL_4                     140               217   
194   63  FEMALE    LEVEL_3                     135               252   
195   49  FEMALE    LEVEL_4                     130               269   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
0                   LOW     LEVEL_0                      139   
1                   LOW     LEVEL_0                      152   
2                   LOW     LEVEL_0                      168   
3                   LOW     LEVEL_2                      158   
4                   LOW     LEVEL_0                       88   
..                  ...         ...                      ...   
191                 LOW     LEVEL_2                      152   
192                 LOW     LEVEL_0                      143   
193                 LOW     LEVEL_0                      111   
194                 LOW     LEVEL_2                      172   
195                 LOW     LEVEL_0                      163   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
0                   NO_PAIN            2.0                  LEVEL_2   
1                   NO_PAIN            0.0                  LEVEL_2   
2                   NO_PAIN            1.0                  LEVEL_1   
3                   NO_PAIN            0.0                  LEVEL_1   
4                      PAIN            1.2                  LEVEL_2   
..                      ...            ...                      ...   
191                    PAIN            0.0                  LEVEL_2   
192                    PAIN            3.0                  LEVEL_2   
193                    PAIN            5.6                  LEVEL_3   
194                 NO_PAIN            0.0                  LEVEL_1   
195                 NO_PAIN            0.0                  LEVEL_1   

     Number_of_major_vessels     Thal  ALVO  
0                        3.0  LEVEL_7     1  
1                        0.0  LEVEL_3     0  
2                        2.0  LEVEL_7     1  
3                        0.0  LEVEL_7     1  
4                        1.0  LEVEL_7     1  
..                       ...      ...   ...  
191                      0.0  LEVEL_3     0  
192                      1.0  LEVEL_7     1  
193                      0.0  LEVEL_7     1  
194                      0.0  LEVEL_3     0  
195                      0.0  LEVEL_3     0  

[196 rows x 14 columns]
2023-10-15 17:00:40,098:INFO:get_config() successfully completed......................................
2023-10-15 17:04:01,691:INFO:Initializing get_config()
2023-10-15 17:04:01,691:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, variable=test)
2023-10-15 17:04:01,693:INFO:Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
2023-10-15 17:04:01,693:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:322: UserWarning: Variable: 'test' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'test_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-10-15 17:04:01,696:INFO:Variable:  returned as      Age     Sex Chest_pain  Resting_blood_pressure  Serum_cholestrol  \
196   68    MALE    LEVEL_3                     118               277   
197   62  FEMALE    LEVEL_4                     140               394   
198   61  FEMALE    LEVEL_4                     130               330   
199   38    MALE    LEVEL_3                     138               175   
200   53  FEMALE    LEVEL_4                     130               264   
..   ...     ...        ...                     ...               ...   
298   48    MALE    LEVEL_2                     110               229   
299   39    MALE    LEVEL_3                     140               321   
300   66    MALE    LEVEL_4                     112               212   
301   67    MALE    LEVEL_4                     120               237   
302   60    MALE    LEVEL_4                     130               206   

    Fasting_blood_sugar Resting_ECG  Max_heart_rate_achieved  \
196                 LOW     LEVEL_0                      151   
197                 LOW     LEVEL_2                      157   
198                 LOW     LEVEL_2                      169   
199                 LOW     LEVEL_0                      173   
200                 LOW     LEVEL_2                      143   
..                  ...         ...                      ...   
298                 LOW     LEVEL_0                      168   
299                 LOW     LEVEL_2                      182   
300                 LOW     LEVEL_2                      132   
301                 LOW     LEVEL_0                       71   
302                 LOW     LEVEL_2                      132   

    Exercise_induced_angina  ST_depression Peak_exercise_ST_segment  \
196                 NO_PAIN            1.0                  LEVEL_1   
197                 NO_PAIN            1.2                  LEVEL_2   
198                 NO_PAIN            0.0                  LEVEL_1   
199                 NO_PAIN            0.0                  LEVEL_1   
200                 NO_PAIN            0.4                  LEVEL_2   
..                      ...            ...                      ...   
298                 NO_PAIN            1.0                  LEVEL_3   
299                 NO_PAIN            0.0                  LEVEL_1   
300                    PAIN            0.1                  LEVEL_1   
301                 NO_PAIN            1.0                  LEVEL_2   
302                    PAIN            2.4                  LEVEL_2   

     Number_of_major_vessels     Thal  ALVO  
196                      1.0  LEVEL_7     0  
197                      0.0  LEVEL_3     0  
198                      0.0  LEVEL_3     1  
199                      NaN  LEVEL_3     0  
200                      0.0  LEVEL_3     0  
..                       ...      ...   ...  
298                      0.0  LEVEL_7     1  
299                      0.0  LEVEL_3     0  
300                      1.0  LEVEL_3     1  
301                      0.0  LEVEL_3     1  
302                      2.0  LEVEL_7     1  

[107 rows x 14 columns]
2023-10-15 17:04:01,696:INFO:get_config() successfully completed......................................
2023-10-15 17:05:18,927:INFO:Initializing get_config()
2023-10-15 17:05:18,927:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, variable=X_train_transformed)
2023-10-15 17:05:19,003:INFO:Variable: X_train returned as           Age       Sex  Chest_pain_LEVEL_3  Chest_pain_LEVEL_4  \
0   -0.631355  0.704403            1.621613           -0.940540   
1   -1.804298 -1.419642            1.621613           -0.940540   
2   -0.279472  0.704403           -0.616670            1.063219   
3   -1.569709  0.704403           -0.616670            1.063219   
4    0.307000  0.704403           -0.616670            1.063219   
..        ...       ...                 ...                 ...   
191 -0.983238 -1.419642           -0.616670            1.063219   
192  0.307000  0.704403           -0.616670            1.063219   
193  0.072411  0.704403           -0.616670            1.063219   
194  1.010766 -1.419642            1.621613           -0.940540   
195 -0.631355 -1.419642           -0.616670            1.063219   

     Chest_pain_LEVEL_1  Chest_pain_LEVEL_2  Resting_blood_pressure  \
0             -0.298142           -0.458123               -0.643981   
1             -0.298142           -0.458123                0.383128   
2             -0.298142           -0.458123               -0.358673   
3             -0.298142           -0.458123               -1.214598   
4             -0.298142           -0.458123                1.181991   
..                  ...                 ...                     ...   
191           -0.298142           -0.458123                0.383128   
192           -0.298142           -0.458123               -1.214598   
193           -0.298142           -0.458123                0.497251   
194           -0.298142           -0.458123                0.211943   
195           -0.298142           -0.458123               -0.073365   

     Serum_cholestrol  Fasting_blood_sugar  Resting_ECG_LEVEL_0  ...  \
0           -1.071874             0.441726             1.052391  ...   
1           -0.477305             0.441726             1.052391  ...   
2           -0.625947             0.441726             1.052391  ...   
3           -1.369159             0.441726            -0.950217  ...   
4            0.526031             0.441726             1.052391  ...   
..                ...                  ...                  ...  ...   
191         -0.049958             0.441726            -0.950217  ...   
192          1.659429             0.441726             1.052391  ...   
193         -0.533046             0.441726             1.052391  ...   
194          0.117264             0.441726            -0.950217  ...   
195          0.433129             0.441726             1.052391  ...   

     Max_heart_rate_achieved  Exercise_induced_angina  ST_depression  \
0                  -0.422276                -0.728869       0.758256   
1                   0.150652                -0.728869      -0.910673   
2                   0.855796                -0.728869      -0.076209   
3                   0.415081                -0.728869      -0.910673   
4                  -2.669920                 1.371989       0.090684   
..                       ...                      ...            ...   
191                 0.150652                 1.371989      -0.910673   
192                -0.245991                 1.371989       1.592720   
193                -1.656277                 1.371989       3.762328   
194                 1.032081                -0.728869      -0.910673   
195                 0.635438                -0.728869      -0.910673   

     Peak_exercise_ST_segment_LEVEL_2  Peak_exercise_ST_segment_LEVEL_1  \
0                            1.031095                         -0.902671   
1                            1.031095                         -0.902671   
2                           -0.969842                          1.107823   
3                           -0.969842                          1.107823   
4                            1.031095                         -0.902671   
..                                ...                               ...   
191                          1.031095                         -0.902671   
192                          1.031095                         -0.902671   
193                         -0.969842                         -0.902671   
194                         -0.969842                          1.107823   
195                         -0.969842                          1.107823   

     Peak_exercise_ST_segment_LEVEL_3  Number_of_major_vessels  Thal_LEVEL_7  \
0                           -0.266530                 2.610225      1.256562   
1                           -0.266530                -0.735922     -0.795822   
2                           -0.266530                 1.494842      1.256562   
3                           -0.266530                -0.735922      1.256562   
4                           -0.266530                 0.379460      1.256562   
..                                ...                      ...           ...   
191                         -0.266530                -0.735922     -0.795822   
192                         -0.266530                 0.379460      1.256562   
193                          3.751923                -0.735922      1.256562   
194                         -0.266530                -0.735922     -0.795822   
195                         -0.266530                -0.735922     -0.795822   

     Thal_LEVEL_3  Thal_LEVEL_6  
0       -1.119318     -0.243843  
1        0.893401     -0.243843  
2       -1.119318     -0.243843  
3       -1.119318     -0.243843  
4       -1.119318     -0.243843  
..            ...           ...  
191      0.893401     -0.243843  
192     -1.119318     -0.243843  
193     -1.119318     -0.243843  
194      0.893401     -0.243843  
195      0.893401     -0.243843  

[196 rows x 22 columns]
2023-10-15 17:05:19,010:INFO:get_config() successfully completed......................................
2023-10-15 17:06:22,977:INFO:Initializing compare_models()
2023-10-15 17:06:22,977:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-10-15 17:06:22,977:INFO:Checking exceptions
2023-10-15 17:06:22,982:INFO:Preparing display monitor
2023-10-15 17:06:23,106:INFO:Initializing Logistic Regression
2023-10-15 17:06:23,106:INFO:Total runtime is 0.0 minutes
2023-10-15 17:06:23,112:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:23,115:INFO:Initializing create_model()
2023-10-15 17:06:23,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:23,115:INFO:Checking exceptions
2023-10-15 17:06:23,115:INFO:Importing libraries
2023-10-15 17:06:23,115:INFO:Copying training dataset
2023-10-15 17:06:23,122:INFO:Defining folds
2023-10-15 17:06:23,122:INFO:Declaring metric variables
2023-10-15 17:06:23,123:INFO:Importing untrained model
2023-10-15 17:06:23,123:INFO:Logistic Regression Imported successfully
2023-10-15 17:06:23,132:INFO:Starting cross validation
2023-10-15 17:06:23,142:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:33,254:INFO:Calculating mean and std
2023-10-15 17:06:33,255:INFO:Creating metrics dataframe
2023-10-15 17:06:33,263:INFO:Uploading results into container
2023-10-15 17:06:33,264:INFO:Uploading model into container now
2023-10-15 17:06:33,264:INFO:_master_model_container: 1
2023-10-15 17:06:33,264:INFO:_display_container: 2
2023-10-15 17:06:33,264:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1935, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-10-15 17:06:33,264:INFO:create_model() successfully completed......................................
2023-10-15 17:06:34,307:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:34,307:INFO:Creating metrics dataframe
2023-10-15 17:06:34,321:INFO:Initializing K Neighbors Classifier
2023-10-15 17:06:34,321:INFO:Total runtime is 0.18691250483194988 minutes
2023-10-15 17:06:34,323:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:34,323:INFO:Initializing create_model()
2023-10-15 17:06:34,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:34,323:INFO:Checking exceptions
2023-10-15 17:06:34,323:INFO:Importing libraries
2023-10-15 17:06:34,323:INFO:Copying training dataset
2023-10-15 17:06:34,331:INFO:Defining folds
2023-10-15 17:06:34,331:INFO:Declaring metric variables
2023-10-15 17:06:34,331:INFO:Importing untrained model
2023-10-15 17:06:34,339:INFO:K Neighbors Classifier Imported successfully
2023-10-15 17:06:34,346:INFO:Starting cross validation
2023-10-15 17:06:34,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:35,413:INFO:Calculating mean and std
2023-10-15 17:06:35,413:INFO:Creating metrics dataframe
2023-10-15 17:06:35,423:INFO:Uploading results into container
2023-10-15 17:06:35,423:INFO:Uploading model into container now
2023-10-15 17:06:35,423:INFO:_master_model_container: 2
2023-10-15 17:06:35,423:INFO:_display_container: 2
2023-10-15 17:06:35,423:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-10-15 17:06:35,423:INFO:create_model() successfully completed......................................
2023-10-15 17:06:35,517:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:35,517:INFO:Creating metrics dataframe
2023-10-15 17:06:35,521:INFO:Initializing Naive Bayes
2023-10-15 17:06:35,521:INFO:Total runtime is 0.2069159785906474 minutes
2023-10-15 17:06:35,528:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:35,528:INFO:Initializing create_model()
2023-10-15 17:06:35,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:35,528:INFO:Checking exceptions
2023-10-15 17:06:35,528:INFO:Importing libraries
2023-10-15 17:06:35,528:INFO:Copying training dataset
2023-10-15 17:06:35,536:INFO:Defining folds
2023-10-15 17:06:35,536:INFO:Declaring metric variables
2023-10-15 17:06:35,545:INFO:Importing untrained model
2023-10-15 17:06:35,551:INFO:Naive Bayes Imported successfully
2023-10-15 17:06:35,553:INFO:Starting cross validation
2023-10-15 17:06:35,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:36,652:INFO:Calculating mean and std
2023-10-15 17:06:36,652:INFO:Creating metrics dataframe
2023-10-15 17:06:36,664:INFO:Uploading results into container
2023-10-15 17:06:36,664:INFO:Uploading model into container now
2023-10-15 17:06:36,671:INFO:_master_model_container: 3
2023-10-15 17:06:36,671:INFO:_display_container: 2
2023-10-15 17:06:36,671:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-10-15 17:06:36,671:INFO:create_model() successfully completed......................................
2023-10-15 17:06:36,797:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:36,797:INFO:Creating metrics dataframe
2023-10-15 17:06:36,811:INFO:Initializing Decision Tree Classifier
2023-10-15 17:06:36,811:INFO:Total runtime is 0.22841503222783408 minutes
2023-10-15 17:06:36,825:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:36,825:INFO:Initializing create_model()
2023-10-15 17:06:36,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:36,825:INFO:Checking exceptions
2023-10-15 17:06:36,825:INFO:Importing libraries
2023-10-15 17:06:36,825:INFO:Copying training dataset
2023-10-15 17:06:36,833:INFO:Defining folds
2023-10-15 17:06:36,833:INFO:Declaring metric variables
2023-10-15 17:06:36,851:INFO:Importing untrained model
2023-10-15 17:06:36,858:INFO:Decision Tree Classifier Imported successfully
2023-10-15 17:06:36,871:INFO:Starting cross validation
2023-10-15 17:06:36,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:38,238:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:38,352:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:38,987:INFO:Calculating mean and std
2023-10-15 17:06:39,001:INFO:Creating metrics dataframe
2023-10-15 17:06:39,003:INFO:Uploading results into container
2023-10-15 17:06:39,003:INFO:Uploading model into container now
2023-10-15 17:06:39,012:INFO:_master_model_container: 4
2023-10-15 17:06:39,012:INFO:_display_container: 2
2023-10-15 17:06:39,012:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1935, splitter='best')
2023-10-15 17:06:39,012:INFO:create_model() successfully completed......................................
2023-10-15 17:06:39,170:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:39,170:INFO:Creating metrics dataframe
2023-10-15 17:06:39,191:INFO:Initializing SVM - Linear Kernel
2023-10-15 17:06:39,191:INFO:Total runtime is 0.2680805087089539 minutes
2023-10-15 17:06:39,195:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:39,195:INFO:Initializing create_model()
2023-10-15 17:06:39,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:39,195:INFO:Checking exceptions
2023-10-15 17:06:39,195:INFO:Importing libraries
2023-10-15 17:06:39,195:INFO:Copying training dataset
2023-10-15 17:06:39,211:INFO:Defining folds
2023-10-15 17:06:39,211:INFO:Declaring metric variables
2023-10-15 17:06:39,220:INFO:Importing untrained model
2023-10-15 17:06:39,221:INFO:SVM - Linear Kernel Imported successfully
2023-10-15 17:06:39,244:INFO:Starting cross validation
2023-10-15 17:06:39,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:41,012:INFO:Calculating mean and std
2023-10-15 17:06:41,015:INFO:Creating metrics dataframe
2023-10-15 17:06:41,015:INFO:Uploading results into container
2023-10-15 17:06:41,021:INFO:Uploading model into container now
2023-10-15 17:06:41,023:INFO:_master_model_container: 5
2023-10-15 17:06:41,023:INFO:_display_container: 2
2023-10-15 17:06:41,024:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1935, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-10-15 17:06:41,024:INFO:create_model() successfully completed......................................
2023-10-15 17:06:41,148:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:41,148:INFO:Creating metrics dataframe
2023-10-15 17:06:41,173:INFO:Initializing Ridge Classifier
2023-10-15 17:06:41,173:INFO:Total runtime is 0.30111486514409386 minutes
2023-10-15 17:06:41,183:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:41,184:INFO:Initializing create_model()
2023-10-15 17:06:41,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:41,184:INFO:Checking exceptions
2023-10-15 17:06:41,184:INFO:Importing libraries
2023-10-15 17:06:41,184:INFO:Copying training dataset
2023-10-15 17:06:41,198:INFO:Defining folds
2023-10-15 17:06:41,198:INFO:Declaring metric variables
2023-10-15 17:06:41,206:INFO:Importing untrained model
2023-10-15 17:06:41,212:INFO:Ridge Classifier Imported successfully
2023-10-15 17:06:41,223:INFO:Starting cross validation
2023-10-15 17:06:41,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:42,762:INFO:Calculating mean and std
2023-10-15 17:06:42,766:INFO:Creating metrics dataframe
2023-10-15 17:06:42,774:INFO:Uploading results into container
2023-10-15 17:06:42,774:INFO:Uploading model into container now
2023-10-15 17:06:42,774:INFO:_master_model_container: 6
2023-10-15 17:06:42,774:INFO:_display_container: 2
2023-10-15 17:06:42,774:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1935, solver='auto',
                tol=0.0001)
2023-10-15 17:06:42,774:INFO:create_model() successfully completed......................................
2023-10-15 17:06:42,892:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:42,892:INFO:Creating metrics dataframe
2023-10-15 17:06:42,906:INFO:Initializing Random Forest Classifier
2023-10-15 17:06:42,906:INFO:Total runtime is 0.3300006667772929 minutes
2023-10-15 17:06:42,915:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:42,915:INFO:Initializing create_model()
2023-10-15 17:06:42,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:42,915:INFO:Checking exceptions
2023-10-15 17:06:42,915:INFO:Importing libraries
2023-10-15 17:06:42,915:INFO:Copying training dataset
2023-10-15 17:06:42,923:INFO:Defining folds
2023-10-15 17:06:42,923:INFO:Declaring metric variables
2023-10-15 17:06:42,931:INFO:Importing untrained model
2023-10-15 17:06:42,942:INFO:Random Forest Classifier Imported successfully
2023-10-15 17:06:42,956:INFO:Starting cross validation
2023-10-15 17:06:42,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:44,371:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:44,982:INFO:Calculating mean and std
2023-10-15 17:06:44,984:INFO:Creating metrics dataframe
2023-10-15 17:06:44,984:INFO:Uploading results into container
2023-10-15 17:06:44,992:INFO:Uploading model into container now
2023-10-15 17:06:44,992:INFO:_master_model_container: 7
2023-10-15 17:06:44,992:INFO:_display_container: 2
2023-10-15 17:06:44,992:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:06:44,992:INFO:create_model() successfully completed......................................
2023-10-15 17:06:45,115:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:45,115:INFO:Creating metrics dataframe
2023-10-15 17:06:45,132:INFO:Initializing Quadratic Discriminant Analysis
2023-10-15 17:06:45,132:INFO:Total runtime is 0.3670873602231344 minutes
2023-10-15 17:06:45,140:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:45,141:INFO:Initializing create_model()
2023-10-15 17:06:45,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:45,141:INFO:Checking exceptions
2023-10-15 17:06:45,141:INFO:Importing libraries
2023-10-15 17:06:45,141:INFO:Copying training dataset
2023-10-15 17:06:45,148:INFO:Defining folds
2023-10-15 17:06:45,148:INFO:Declaring metric variables
2023-10-15 17:06:45,156:INFO:Importing untrained model
2023-10-15 17:06:45,165:INFO:Quadratic Discriminant Analysis Imported successfully
2023-10-15 17:06:45,183:INFO:Starting cross validation
2023-10-15 17:06:45,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:45,532:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:45,532:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:45,549:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:45,564:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:45,592:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:45,614:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:45,614:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:45,655:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:46,442:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:46,465:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-15 17:06:46,565:INFO:Calculating mean and std
2023-10-15 17:06:46,565:INFO:Creating metrics dataframe
2023-10-15 17:06:46,573:INFO:Uploading results into container
2023-10-15 17:06:46,573:INFO:Uploading model into container now
2023-10-15 17:06:46,573:INFO:_master_model_container: 8
2023-10-15 17:06:46,573:INFO:_display_container: 2
2023-10-15 17:06:46,573:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-10-15 17:06:46,573:INFO:create_model() successfully completed......................................
2023-10-15 17:06:46,698:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:46,701:INFO:Creating metrics dataframe
2023-10-15 17:06:46,723:INFO:Initializing Ada Boost Classifier
2023-10-15 17:06:46,723:INFO:Total runtime is 0.39361699422200525 minutes
2023-10-15 17:06:46,732:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:46,732:INFO:Initializing create_model()
2023-10-15 17:06:46,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:46,732:INFO:Checking exceptions
2023-10-15 17:06:46,732:INFO:Importing libraries
2023-10-15 17:06:46,732:INFO:Copying training dataset
2023-10-15 17:06:46,741:INFO:Defining folds
2023-10-15 17:06:46,741:INFO:Declaring metric variables
2023-10-15 17:06:46,752:INFO:Importing untrained model
2023-10-15 17:06:46,761:INFO:Ada Boost Classifier Imported successfully
2023-10-15 17:06:46,778:INFO:Starting cross validation
2023-10-15 17:06:46,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:48,096:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:48,101:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:48,115:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:48,132:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:48,132:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:48,205:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:48,262:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:48,945:INFO:Calculating mean and std
2023-10-15 17:06:48,945:INFO:Creating metrics dataframe
2023-10-15 17:06:48,952:INFO:Uploading results into container
2023-10-15 17:06:48,953:INFO:Uploading model into container now
2023-10-15 17:06:48,953:INFO:_master_model_container: 9
2023-10-15 17:06:48,953:INFO:_display_container: 2
2023-10-15 17:06:48,956:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1935)
2023-10-15 17:06:48,956:INFO:create_model() successfully completed......................................
2023-10-15 17:06:49,071:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:49,071:INFO:Creating metrics dataframe
2023-10-15 17:06:49,092:INFO:Initializing Gradient Boosting Classifier
2023-10-15 17:06:49,092:INFO:Total runtime is 0.4331002076466879 minutes
2023-10-15 17:06:49,095:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:49,095:INFO:Initializing create_model()
2023-10-15 17:06:49,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:49,095:INFO:Checking exceptions
2023-10-15 17:06:49,095:INFO:Importing libraries
2023-10-15 17:06:49,095:INFO:Copying training dataset
2023-10-15 17:06:49,106:INFO:Defining folds
2023-10-15 17:06:49,106:INFO:Declaring metric variables
2023-10-15 17:06:49,111:INFO:Importing untrained model
2023-10-15 17:06:49,120:INFO:Gradient Boosting Classifier Imported successfully
2023-10-15 17:06:49,136:INFO:Starting cross validation
2023-10-15 17:06:49,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:50,681:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:50,732:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:50,925:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:51,051:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:51,394:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:51,468:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:51,921:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:52,011:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:52,891:INFO:Calculating mean and std
2023-10-15 17:06:52,895:INFO:Creating metrics dataframe
2023-10-15 17:06:52,901:INFO:Uploading results into container
2023-10-15 17:06:52,901:INFO:Uploading model into container now
2023-10-15 17:06:52,901:INFO:_master_model_container: 10
2023-10-15 17:06:52,901:INFO:_display_container: 2
2023-10-15 17:06:52,906:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1935, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-10-15 17:06:52,906:INFO:create_model() successfully completed......................................
2023-10-15 17:06:53,041:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:53,041:INFO:Creating metrics dataframe
2023-10-15 17:06:53,066:INFO:Initializing Linear Discriminant Analysis
2023-10-15 17:06:53,066:INFO:Total runtime is 0.49932236274083464 minutes
2023-10-15 17:06:53,074:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:53,074:INFO:Initializing create_model()
2023-10-15 17:06:53,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:53,074:INFO:Checking exceptions
2023-10-15 17:06:53,074:INFO:Importing libraries
2023-10-15 17:06:53,074:INFO:Copying training dataset
2023-10-15 17:06:53,081:INFO:Defining folds
2023-10-15 17:06:53,081:INFO:Declaring metric variables
2023-10-15 17:06:53,098:INFO:Importing untrained model
2023-10-15 17:06:53,107:INFO:Linear Discriminant Analysis Imported successfully
2023-10-15 17:06:53,156:INFO:Starting cross validation
2023-10-15 17:06:53,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:54,921:INFO:Calculating mean and std
2023-10-15 17:06:54,923:INFO:Creating metrics dataframe
2023-10-15 17:06:54,926:INFO:Uploading results into container
2023-10-15 17:06:54,926:INFO:Uploading model into container now
2023-10-15 17:06:54,926:INFO:_master_model_container: 11
2023-10-15 17:06:54,926:INFO:_display_container: 2
2023-10-15 17:06:54,926:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-10-15 17:06:54,926:INFO:create_model() successfully completed......................................
2023-10-15 17:06:55,051:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:55,051:INFO:Creating metrics dataframe
2023-10-15 17:06:55,074:INFO:Initializing Extra Trees Classifier
2023-10-15 17:06:55,074:INFO:Total runtime is 0.5327848354975383 minutes
2023-10-15 17:06:55,081:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:55,081:INFO:Initializing create_model()
2023-10-15 17:06:55,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:55,086:INFO:Checking exceptions
2023-10-15 17:06:55,086:INFO:Importing libraries
2023-10-15 17:06:55,086:INFO:Copying training dataset
2023-10-15 17:06:55,091:INFO:Defining folds
2023-10-15 17:06:55,091:INFO:Declaring metric variables
2023-10-15 17:06:55,098:INFO:Importing untrained model
2023-10-15 17:06:55,106:INFO:Extra Trees Classifier Imported successfully
2023-10-15 17:06:55,115:INFO:Starting cross validation
2023-10-15 17:06:55,121:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:06:56,843:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:56,885:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:56,891:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:56,904:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:56,962:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:56,976:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:57,075:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:57,075:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:06:58,126:INFO:Calculating mean and std
2023-10-15 17:06:58,131:INFO:Creating metrics dataframe
2023-10-15 17:06:58,134:INFO:Uploading results into container
2023-10-15 17:06:58,134:INFO:Uploading model into container now
2023-10-15 17:06:58,134:INFO:_master_model_container: 12
2023-10-15 17:06:58,142:INFO:_display_container: 2
2023-10-15 17:06:58,142:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:06:58,143:INFO:create_model() successfully completed......................................
2023-10-15 17:06:58,262:INFO:SubProcess create_model() end ==================================
2023-10-15 17:06:58,262:INFO:Creating metrics dataframe
2023-10-15 17:06:58,281:INFO:Initializing Extreme Gradient Boosting
2023-10-15 17:06:58,284:INFO:Total runtime is 0.5862865646680196 minutes
2023-10-15 17:06:58,286:INFO:SubProcess create_model() called ==================================
2023-10-15 17:06:58,286:INFO:Initializing create_model()
2023-10-15 17:06:58,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:06:58,292:INFO:Checking exceptions
2023-10-15 17:06:58,292:INFO:Importing libraries
2023-10-15 17:06:58,292:INFO:Copying training dataset
2023-10-15 17:06:58,293:INFO:Defining folds
2023-10-15 17:06:58,293:INFO:Declaring metric variables
2023-10-15 17:06:58,303:INFO:Importing untrained model
2023-10-15 17:06:58,311:INFO:Extreme Gradient Boosting Imported successfully
2023-10-15 17:06:58,326:INFO:Starting cross validation
2023-10-15 17:06:58,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:07:00,173:INFO:Calculating mean and std
2023-10-15 17:07:00,183:INFO:Creating metrics dataframe
2023-10-15 17:07:00,190:INFO:Uploading results into container
2023-10-15 17:07:00,191:INFO:Uploading model into container now
2023-10-15 17:07:00,191:INFO:_master_model_container: 13
2023-10-15 17:07:00,191:INFO:_display_container: 2
2023-10-15 17:07:00,191:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-10-15 17:07:00,191:INFO:create_model() successfully completed......................................
2023-10-15 17:07:00,324:INFO:SubProcess create_model() end ==================================
2023-10-15 17:07:00,324:INFO:Creating metrics dataframe
2023-10-15 17:07:00,357:INFO:Initializing Light Gradient Boosting Machine
2023-10-15 17:07:00,357:INFO:Total runtime is 0.6208353400230409 minutes
2023-10-15 17:07:00,368:INFO:SubProcess create_model() called ==================================
2023-10-15 17:07:00,368:INFO:Initializing create_model()
2023-10-15 17:07:00,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:07:00,368:INFO:Checking exceptions
2023-10-15 17:07:00,369:INFO:Importing libraries
2023-10-15 17:07:00,369:INFO:Copying training dataset
2023-10-15 17:07:00,384:INFO:Defining folds
2023-10-15 17:07:00,384:INFO:Declaring metric variables
2023-10-15 17:07:00,398:INFO:Importing untrained model
2023-10-15 17:07:00,409:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-15 17:07:00,433:INFO:Starting cross validation
2023-10-15 17:07:00,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:07:05,627:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:07:05,906:INFO:Calculating mean and std
2023-10-15 17:07:05,909:INFO:Creating metrics dataframe
2023-10-15 17:07:05,917:INFO:Uploading results into container
2023-10-15 17:07:05,921:INFO:Uploading model into container now
2023-10-15 17:07:05,923:INFO:_master_model_container: 14
2023-10-15 17:07:05,923:INFO:_display_container: 2
2023-10-15 17:07:05,923:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1935, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-10-15 17:07:05,925:INFO:create_model() successfully completed......................................
2023-10-15 17:07:06,073:INFO:SubProcess create_model() end ==================================
2023-10-15 17:07:06,073:INFO:Creating metrics dataframe
2023-10-15 17:07:06,106:INFO:Initializing CatBoost Classifier
2023-10-15 17:07:06,107:INFO:Total runtime is 0.7166743159294129 minutes
2023-10-15 17:07:06,114:INFO:SubProcess create_model() called ==================================
2023-10-15 17:07:06,114:INFO:Initializing create_model()
2023-10-15 17:07:06,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:07:06,114:INFO:Checking exceptions
2023-10-15 17:07:06,114:INFO:Importing libraries
2023-10-15 17:07:06,114:INFO:Copying training dataset
2023-10-15 17:07:06,123:INFO:Defining folds
2023-10-15 17:07:06,123:INFO:Declaring metric variables
2023-10-15 17:07:06,132:INFO:Importing untrained model
2023-10-15 17:07:06,155:INFO:CatBoost Classifier Imported successfully
2023-10-15 17:07:06,171:INFO:Starting cross validation
2023-10-15 17:07:06,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:07:09,516:INFO:Calculating mean and std
2023-10-15 17:07:09,524:INFO:Creating metrics dataframe
2023-10-15 17:07:09,531:INFO:Uploading results into container
2023-10-15 17:07:09,532:INFO:Uploading model into container now
2023-10-15 17:07:09,532:INFO:_master_model_container: 15
2023-10-15 17:07:09,532:INFO:_display_container: 2
2023-10-15 17:07:09,532:INFO:<catboost.core.CatBoostClassifier object at 0x000002767D38C070>
2023-10-15 17:07:09,532:INFO:create_model() successfully completed......................................
2023-10-15 17:07:09,673:INFO:SubProcess create_model() end ==================================
2023-10-15 17:07:09,673:INFO:Creating metrics dataframe
2023-10-15 17:07:09,702:INFO:Initializing Dummy Classifier
2023-10-15 17:07:09,702:INFO:Total runtime is 0.7765857537587484 minutes
2023-10-15 17:07:09,708:INFO:SubProcess create_model() called ==================================
2023-10-15 17:07:09,708:INFO:Initializing create_model()
2023-10-15 17:07:09,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D957100>, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:07:09,708:INFO:Checking exceptions
2023-10-15 17:07:09,708:INFO:Importing libraries
2023-10-15 17:07:09,708:INFO:Copying training dataset
2023-10-15 17:07:09,715:INFO:Defining folds
2023-10-15 17:07:09,715:INFO:Declaring metric variables
2023-10-15 17:07:09,726:INFO:Importing untrained model
2023-10-15 17:07:09,731:INFO:Dummy Classifier Imported successfully
2023-10-15 17:07:09,741:INFO:Starting cross validation
2023-10-15 17:07:09,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:07:10,623:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,640:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,648:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,671:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,693:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,713:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,736:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,781:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:10,976:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:11,017:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-15 17:07:11,025:INFO:Calculating mean and std
2023-10-15 17:07:11,025:INFO:Creating metrics dataframe
2023-10-15 17:07:11,033:INFO:Uploading results into container
2023-10-15 17:07:11,033:INFO:Uploading model into container now
2023-10-15 17:07:11,033:INFO:_master_model_container: 16
2023-10-15 17:07:11,033:INFO:_display_container: 2
2023-10-15 17:07:11,033:INFO:DummyClassifier(constant=None, random_state=1935, strategy='prior')
2023-10-15 17:07:11,033:INFO:create_model() successfully completed......................................
2023-10-15 17:07:11,151:INFO:SubProcess create_model() end ==================================
2023-10-15 17:07:11,151:INFO:Creating metrics dataframe
2023-10-15 17:07:11,207:INFO:Initializing create_model()
2023-10-15 17:07:11,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:07:11,208:INFO:Checking exceptions
2023-10-15 17:07:11,211:INFO:Importing libraries
2023-10-15 17:07:11,211:INFO:Copying training dataset
2023-10-15 17:07:11,221:INFO:Defining folds
2023-10-15 17:07:11,221:INFO:Declaring metric variables
2023-10-15 17:07:11,221:INFO:Importing untrained model
2023-10-15 17:07:11,221:INFO:Declaring custom model
2023-10-15 17:07:11,224:INFO:Random Forest Classifier Imported successfully
2023-10-15 17:07:11,224:INFO:Cross validation set to False
2023-10-15 17:07:11,224:INFO:Fitting Model
2023-10-15 17:07:11,498:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:07:11,498:INFO:create_model() successfully completed......................................
2023-10-15 17:07:11,654:INFO:_master_model_container: 16
2023-10-15 17:07:11,654:INFO:_display_container: 2
2023-10-15 17:07:11,654:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:07:11,656:INFO:compare_models() successfully completed......................................
2023-10-15 17:16:56,881:INFO:Initializing create_model()
2023-10-15 17:16:56,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:16:56,884:INFO:Checking exceptions
2023-10-15 17:16:56,932:INFO:Importing libraries
2023-10-15 17:16:56,932:INFO:Copying training dataset
2023-10-15 17:16:56,937:INFO:Defining folds
2023-10-15 17:16:56,937:INFO:Declaring metric variables
2023-10-15 17:16:56,942:INFO:Importing untrained model
2023-10-15 17:16:56,948:INFO:CatBoost Classifier Imported successfully
2023-10-15 17:16:56,952:INFO:Starting cross validation
2023-10-15 17:16:56,956:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:17:07,277:INFO:Calculating mean and std
2023-10-15 17:17:07,283:INFO:Creating metrics dataframe
2023-10-15 17:17:07,303:INFO:Finalizing model
2023-10-15 17:17:07,646:INFO:Uploading results into container
2023-10-15 17:17:07,647:INFO:Uploading model into container now
2023-10-15 17:17:07,686:INFO:_master_model_container: 17
2023-10-15 17:17:07,686:INFO:_display_container: 3
2023-10-15 17:17:07,686:INFO:<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>
2023-10-15 17:17:07,686:INFO:create_model() successfully completed......................................
2023-10-15 17:17:25,413:INFO:Initializing predict_model()
2023-10-15 17:17:25,413:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002767D449D30>)
2023-10-15 17:17:25,413:INFO:Checking exceptions
2023-10-15 17:17:25,413:INFO:Preloading libraries
2023-10-15 17:17:25,419:INFO:Set up data.
2023-10-15 17:17:25,425:INFO:Set up index.
2023-10-15 17:18:13,221:INFO:Initializing predict_model()
2023-10-15 17:18:13,221:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002767DD02310>)
2023-10-15 17:18:13,221:INFO:Checking exceptions
2023-10-15 17:18:13,226:INFO:Preloading libraries
2023-10-15 17:18:13,226:INFO:Set up data.
2023-10-15 17:18:13,235:INFO:Set up index.
2023-10-15 17:19:18,281:INFO:Initializing create_model()
2023-10-15 17:19:18,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:19:18,290:INFO:Checking exceptions
2023-10-15 17:19:18,323:INFO:Importing libraries
2023-10-15 17:19:18,323:INFO:Copying training dataset
2023-10-15 17:19:18,331:INFO:Defining folds
2023-10-15 17:19:18,331:INFO:Declaring metric variables
2023-10-15 17:19:18,331:INFO:Importing untrained model
2023-10-15 17:19:18,340:INFO:Random Forest Classifier Imported successfully
2023-10-15 17:19:18,348:INFO:Starting cross validation
2023-10-15 17:19:18,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:19:19,551:INFO:Calculating mean and std
2023-10-15 17:19:19,551:INFO:Creating metrics dataframe
2023-10-15 17:19:19,551:INFO:Finalizing model
2023-10-15 17:19:19,729:INFO:Uploading results into container
2023-10-15 17:19:19,729:INFO:Uploading model into container now
2023-10-15 17:19:19,741:INFO:_master_model_container: 18
2023-10-15 17:19:19,741:INFO:_display_container: 6
2023-10-15 17:19:19,741:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:19:19,741:INFO:create_model() successfully completed......................................
2023-10-15 17:20:56,352:INFO:Initializing predict_model()
2023-10-15 17:20:56,352:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002767DABF0D0>)
2023-10-15 17:20:56,352:INFO:Checking exceptions
2023-10-15 17:20:56,352:INFO:Preloading libraries
2023-10-15 17:20:56,362:INFO:Set up data.
2023-10-15 17:20:56,368:INFO:Set up index.
2023-10-15 17:21:53,090:INFO:Initializing tune_model()
2023-10-15 17:21:53,090:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>)
2023-10-15 17:21:53,090:INFO:Checking exceptions
2023-10-15 17:21:53,122:INFO:Copying training dataset
2023-10-15 17:21:53,124:INFO:Checking base model
2023-10-15 17:21:53,125:INFO:Base model : CatBoost Classifier
2023-10-15 17:21:53,129:INFO:Declaring metric variables
2023-10-15 17:21:53,135:INFO:Defining Hyperparameters
2023-10-15 17:21:53,229:INFO:Tuning with n_jobs=-1
2023-10-15 17:21:53,229:INFO:Initializing RandomizedSearchCV
2023-10-15 17:21:59,073:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 280, 'actual_estimator__l2_leaf_reg': 100, 'actual_estimator__eta': 0.01, 'actual_estimator__depth': 3}
2023-10-15 17:21:59,075:INFO:Hyperparameter search completed
2023-10-15 17:21:59,076:INFO:SubProcess create_model() called ==================================
2023-10-15 17:21:59,076:INFO:Initializing create_model()
2023-10-15 17:21:59,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D670550>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002767D6704C0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.8, 'n_estimators': 280, 'l2_leaf_reg': 100, 'eta': 0.01, 'depth': 3})
2023-10-15 17:21:59,076:INFO:Checking exceptions
2023-10-15 17:21:59,076:INFO:Importing libraries
2023-10-15 17:21:59,077:INFO:Copying training dataset
2023-10-15 17:21:59,082:INFO:Defining folds
2023-10-15 17:21:59,082:INFO:Declaring metric variables
2023-10-15 17:21:59,088:INFO:Importing untrained model
2023-10-15 17:21:59,088:INFO:Declaring custom model
2023-10-15 17:21:59,093:INFO:CatBoost Classifier Imported successfully
2023-10-15 17:21:59,099:INFO:Starting cross validation
2023-10-15 17:21:59,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:21:59,544:INFO:Calculating mean and std
2023-10-15 17:21:59,546:INFO:Creating metrics dataframe
2023-10-15 17:21:59,552:INFO:Finalizing model
2023-10-15 17:21:59,747:INFO:Uploading results into container
2023-10-15 17:21:59,748:INFO:Uploading model into container now
2023-10-15 17:21:59,748:INFO:_master_model_container: 19
2023-10-15 17:21:59,748:INFO:_display_container: 8
2023-10-15 17:21:59,749:INFO:<catboost.core.CatBoostClassifier object at 0x000002767D94A6A0>
2023-10-15 17:21:59,749:INFO:create_model() successfully completed......................................
2023-10-15 17:21:59,849:INFO:SubProcess create_model() end ==================================
2023-10-15 17:21:59,849:INFO:choose_better activated
2023-10-15 17:21:59,852:INFO:SubProcess create_model() called ==================================
2023-10-15 17:21:59,852:INFO:Initializing create_model()
2023-10-15 17:21:59,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:21:59,852:INFO:Checking exceptions
2023-10-15 17:21:59,854:INFO:Importing libraries
2023-10-15 17:21:59,854:INFO:Copying training dataset
2023-10-15 17:21:59,858:INFO:Defining folds
2023-10-15 17:21:59,858:INFO:Declaring metric variables
2023-10-15 17:21:59,858:INFO:Importing untrained model
2023-10-15 17:21:59,858:INFO:Declaring custom model
2023-10-15 17:21:59,858:INFO:CatBoost Classifier Imported successfully
2023-10-15 17:21:59,859:INFO:Starting cross validation
2023-10-15 17:21:59,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:22:00,510:INFO:Calculating mean and std
2023-10-15 17:22:00,511:INFO:Creating metrics dataframe
2023-10-15 17:22:00,513:INFO:Finalizing model
2023-10-15 17:22:00,604:INFO:Uploading results into container
2023-10-15 17:22:00,605:INFO:Uploading model into container now
2023-10-15 17:22:00,605:INFO:_master_model_container: 20
2023-10-15 17:22:00,605:INFO:_display_container: 9
2023-10-15 17:22:00,605:INFO:<catboost.core.CatBoostClassifier object at 0x000002767DC40BE0>
2023-10-15 17:22:00,605:INFO:create_model() successfully completed......................................
2023-10-15 17:22:00,698:INFO:SubProcess create_model() end ==================================
2023-10-15 17:22:00,699:INFO:<catboost.core.CatBoostClassifier object at 0x000002767DC40BE0> result for Accuracy is 0.8268
2023-10-15 17:22:00,699:INFO:<catboost.core.CatBoostClassifier object at 0x000002767D94A6A0> result for Accuracy is 0.8574
2023-10-15 17:22:00,699:INFO:<catboost.core.CatBoostClassifier object at 0x000002767D94A6A0> is best model
2023-10-15 17:22:00,699:INFO:choose_better completed
2023-10-15 17:22:00,710:INFO:_master_model_container: 20
2023-10-15 17:22:00,710:INFO:_display_container: 8
2023-10-15 17:22:00,710:INFO:<catboost.core.CatBoostClassifier object at 0x000002767D94A6A0>
2023-10-15 17:22:00,710:INFO:tune_model() successfully completed......................................
2023-10-15 17:22:11,508:INFO:Initializing predict_model()
2023-10-15 17:22:11,510:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D94A6A0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002767D463430>)
2023-10-15 17:22:11,510:INFO:Checking exceptions
2023-10-15 17:22:11,510:INFO:Preloading libraries
2023-10-15 17:22:11,513:INFO:Set up data.
2023-10-15 17:22:11,520:INFO:Set up index.
2023-10-15 17:23:26,584:INFO:Initializing tune_model()
2023-10-15 17:23:26,585:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=None, round=4, n_iter=25, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>)
2023-10-15 17:23:26,585:INFO:Checking exceptions
2023-10-15 17:23:26,626:INFO:Copying training dataset
2023-10-15 17:23:26,632:INFO:Checking base model
2023-10-15 17:23:26,632:INFO:Base model : Random Forest Classifier
2023-10-15 17:23:26,637:INFO:Declaring metric variables
2023-10-15 17:23:26,641:INFO:Defining Hyperparameters
2023-10-15 17:23:26,765:INFO:Tuning with n_jobs=-1
2023-10-15 17:23:26,765:INFO:Initializing RandomizedSearchCV
2023-10-15 17:23:29,407:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:29,426:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:29,616:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:29,742:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:31,243:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:33,654:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:34,334:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:34,499:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-10-15 17:23:50,698:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:223: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-10-15 17:24:11,856:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:223: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-10-15 17:24:18,683:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-10-15 17:24:18,887:INFO:Hyperparameter search completed
2023-10-15 17:24:18,897:INFO:SubProcess create_model() called ==================================
2023-10-15 17:24:18,925:INFO:Initializing create_model()
2023-10-15 17:24:18,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027671A1AA30>, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': False})
2023-10-15 17:24:18,926:INFO:Checking exceptions
2023-10-15 17:24:18,933:INFO:Importing libraries
2023-10-15 17:24:18,943:INFO:Copying training dataset
2023-10-15 17:24:19,110:INFO:Defining folds
2023-10-15 17:24:19,113:INFO:Declaring metric variables
2023-10-15 17:24:19,292:INFO:Importing untrained model
2023-10-15 17:24:19,293:INFO:Declaring custom model
2023-10-15 17:24:19,340:INFO:Random Forest Classifier Imported successfully
2023-10-15 17:24:19,368:INFO:Starting cross validation
2023-10-15 17:24:19,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:24:21,386:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:230: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-10-15 17:24:21,932:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:230: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-10-15 17:24:22,342:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:230: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-10-15 17:24:22,398:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:223: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-10-15 17:24:24,562:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:223: UserWarning: Persisting input arguments took 4.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-10-15 17:24:26,113:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:223: UserWarning: Persisting input arguments took 4.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-10-15 17:24:27,746:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:230: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-10-15 17:24:29,691:WARNING:C:\Users\zaian\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:223: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-10-15 17:24:33,681:INFO:Calculating mean and std
2023-10-15 17:24:33,697:INFO:Creating metrics dataframe
2023-10-15 17:24:33,813:INFO:Finalizing model
2023-10-15 17:24:35,456:INFO:Uploading results into container
2023-10-15 17:24:35,460:INFO:Uploading model into container now
2023-10-15 17:24:35,476:INFO:_master_model_container: 21
2023-10-15 17:24:35,476:INFO:_display_container: 10
2023-10-15 17:24:35,479:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:24:35,479:INFO:create_model() successfully completed......................................
2023-10-15 17:24:37,536:INFO:SubProcess create_model() end ==================================
2023-10-15 17:24:37,536:INFO:choose_better activated
2023-10-15 17:24:37,541:INFO:SubProcess create_model() called ==================================
2023-10-15 17:24:37,542:INFO:Initializing create_model()
2023-10-15 17:24:37,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-15 17:24:37,543:INFO:Checking exceptions
2023-10-15 17:24:37,546:INFO:Importing libraries
2023-10-15 17:24:37,546:INFO:Copying training dataset
2023-10-15 17:24:37,552:INFO:Defining folds
2023-10-15 17:24:37,552:INFO:Declaring metric variables
2023-10-15 17:24:37,553:INFO:Importing untrained model
2023-10-15 17:24:37,553:INFO:Declaring custom model
2023-10-15 17:24:37,554:INFO:Random Forest Classifier Imported successfully
2023-10-15 17:24:37,554:INFO:Starting cross validation
2023-10-15 17:24:37,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-15 17:24:39,720:INFO:Calculating mean and std
2023-10-15 17:24:39,721:INFO:Creating metrics dataframe
2023-10-15 17:24:39,724:INFO:Finalizing model
2023-10-15 17:24:39,982:INFO:Uploading results into container
2023-10-15 17:24:39,983:INFO:Uploading model into container now
2023-10-15 17:24:39,984:INFO:_master_model_container: 22
2023-10-15 17:24:39,984:INFO:_display_container: 11
2023-10-15 17:24:39,984:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:24:39,985:INFO:create_model() successfully completed......................................
2023-10-15 17:24:40,099:INFO:SubProcess create_model() end ==================================
2023-10-15 17:24:40,101:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) result for Accuracy is 0.8268
2023-10-15 17:24:40,102:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) result for Accuracy is 0.8424
2023-10-15 17:24:40,102:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False) is best model
2023-10-15 17:24:40,102:INFO:choose_better completed
2023-10-15 17:24:40,126:INFO:_master_model_container: 22
2023-10-15 17:24:40,126:INFO:_display_container: 10
2023-10-15 17:24:40,127:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False)
2023-10-15 17:24:40,127:INFO:tune_model() successfully completed......................................
2023-10-15 17:26:10,819:INFO:Initializing predict_model()
2023-10-15 17:26:10,822:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0002, min_samples_leaf=6,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1935, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000002767DB56B80>)
2023-10-15 17:26:10,822:INFO:Checking exceptions
2023-10-15 17:26:10,822:INFO:Preloading libraries
2023-10-15 17:26:10,841:INFO:Set up data.
2023-10-15 17:26:10,874:INFO:Set up index.
2023-10-15 17:28:38,519:INFO:Initializing plot_model()
2023-10-15 17:28:38,519:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:28:38,519:INFO:Checking exceptions
2023-10-15 17:28:38,550:INFO:Preloading libraries
2023-10-15 17:28:38,561:INFO:Copying training dataset
2023-10-15 17:28:38,561:INFO:Plot type: auc
2023-10-15 17:28:38,744:INFO:Fitting Model
2023-10-15 17:28:38,773:INFO:Scoring test/hold-out set
2023-10-15 17:28:39,022:INFO:Visual Rendered Successfully
2023-10-15 17:28:39,113:INFO:plot_model() successfully completed......................................
2023-10-15 17:28:59,376:INFO:Initializing plot_model()
2023-10-15 17:28:59,376:INFO:plot_model(plot=ks, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:28:59,376:INFO:Checking exceptions
2023-10-15 17:28:59,381:INFO:Preloading libraries
2023-10-15 17:28:59,383:INFO:Copying training dataset
2023-10-15 17:28:59,383:INFO:Plot type: ks
2023-10-15 17:28:59,384:INFO:Generating predictions / predict_proba on X_test
2023-10-15 17:28:59,584:INFO:Visual Rendered Successfully
2023-10-15 17:28:59,674:INFO:plot_model() successfully completed......................................
2023-10-15 17:29:08,476:INFO:Initializing plot_model()
2023-10-15 17:29:08,476:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:29:08,477:INFO:Checking exceptions
2023-10-15 17:29:08,481:INFO:Preloading libraries
2023-10-15 17:29:08,483:INFO:Copying training dataset
2023-10-15 17:29:08,483:INFO:Plot type: confusion_matrix
2023-10-15 17:29:08,659:INFO:Fitting Model
2023-10-15 17:29:08,659:INFO:Scoring test/hold-out set
2023-10-15 17:29:08,727:INFO:Visual Rendered Successfully
2023-10-15 17:29:08,810:INFO:plot_model() successfully completed......................................
2023-10-15 17:30:19,735:INFO:Initializing evaluate_model()
2023-10-15 17:30:19,735:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-10-15 17:30:19,763:INFO:Initializing plot_model()
2023-10-15 17:30:19,763:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:30:19,764:INFO:Checking exceptions
2023-10-15 17:30:19,765:INFO:Preloading libraries
2023-10-15 17:30:19,768:INFO:Copying training dataset
2023-10-15 17:30:19,768:INFO:Plot type: pipeline
2023-10-15 17:30:19,880:INFO:Visual Rendered Successfully
2023-10-15 17:30:19,977:INFO:plot_model() successfully completed......................................
2023-10-15 17:30:52,358:INFO:Initializing plot_model()
2023-10-15 17:30:52,359:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:30:52,359:INFO:Checking exceptions
2023-10-15 17:30:52,360:INFO:Preloading libraries
2023-10-15 17:30:52,362:INFO:Copying training dataset
2023-10-15 17:30:52,362:INFO:Plot type: ks
2023-10-15 17:30:52,363:INFO:Generating predictions / predict_proba on X_test
2023-10-15 17:30:52,564:INFO:Visual Rendered Successfully
2023-10-15 17:30:52,649:INFO:plot_model() successfully completed......................................
2023-10-15 17:30:57,502:INFO:Initializing plot_model()
2023-10-15 17:30:57,502:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:30:57,502:INFO:Checking exceptions
2023-10-15 17:30:57,504:INFO:Preloading libraries
2023-10-15 17:30:57,506:INFO:Copying training dataset
2023-10-15 17:30:57,506:INFO:Plot type: parameter
2023-10-15 17:30:57,518:INFO:Visual Rendered Successfully
2023-10-15 17:30:57,605:INFO:plot_model() successfully completed......................................
2023-10-15 17:31:13,169:INFO:Initializing plot_model()
2023-10-15 17:31:13,170:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:31:13,170:INFO:Checking exceptions
2023-10-15 17:31:13,171:INFO:Preloading libraries
2023-10-15 17:31:13,173:INFO:Copying training dataset
2023-10-15 17:31:13,173:INFO:Plot type: rfe
2023-10-15 17:31:13,348:INFO:Fitting Model
2023-10-15 17:34:07,373:INFO:Initializing plot_model()
2023-10-15 17:34:07,373:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:34:07,374:INFO:Checking exceptions
2023-10-15 17:34:07,379:INFO:Preloading libraries
2023-10-15 17:34:07,383:INFO:Copying training dataset
2023-10-15 17:34:07,384:INFO:Plot type: feature
2023-10-15 17:34:07,385:WARNING:No coef_ found. Trying feature_importances_
2023-10-15 17:34:07,793:INFO:Visual Rendered Successfully
2023-10-15 17:34:07,945:INFO:plot_model() successfully completed......................................
2023-10-15 17:34:52,308:INFO:Initializing plot_model()
2023-10-15 17:34:52,308:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:34:52,308:INFO:Checking exceptions
2023-10-15 17:34:52,311:INFO:Preloading libraries
2023-10-15 17:34:52,312:INFO:Copying training dataset
2023-10-15 17:34:52,312:INFO:Plot type: confusion_matrix
2023-10-15 17:34:52,413:INFO:Fitting Model
2023-10-15 17:34:52,414:INFO:Scoring test/hold-out set
2023-10-15 17:34:52,482:INFO:Visual Rendered Successfully
2023-10-15 17:34:52,573:INFO:plot_model() successfully completed......................................
2023-10-15 17:35:01,730:INFO:Initializing plot_model()
2023-10-15 17:35:01,730:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:35:01,731:INFO:Checking exceptions
2023-10-15 17:35:01,732:INFO:Preloading libraries
2023-10-15 17:35:01,734:INFO:Copying training dataset
2023-10-15 17:35:01,734:INFO:Plot type: feature_all
2023-10-15 17:35:01,760:WARNING:No coef_ found. Trying feature_importances_
2023-10-15 17:35:01,898:INFO:Visual Rendered Successfully
2023-10-15 17:35:01,997:INFO:plot_model() successfully completed......................................
2023-10-15 17:35:36,153:INFO:Initializing plot_model()
2023-10-15 17:35:36,154:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:35:36,154:INFO:Checking exceptions
2023-10-15 17:35:36,156:INFO:Preloading libraries
2023-10-15 17:35:36,157:INFO:Copying training dataset
2023-10-15 17:35:36,158:INFO:Plot type: feature
2023-10-15 17:35:36,158:WARNING:No coef_ found. Trying feature_importances_
2023-10-15 17:35:36,258:INFO:Visual Rendered Successfully
2023-10-15 17:35:36,348:INFO:plot_model() successfully completed......................................
2023-10-15 17:35:44,357:INFO:Initializing interpret_model()
2023-10-15 17:35:44,358:INFO:interpret_model(estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>)
2023-10-15 17:35:44,358:INFO:Checking exceptions
2023-10-15 17:35:44,358:INFO:Soft dependency imported: shap: 0.42.1
2023-10-15 17:35:44,875:WARNING:Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)

2023-10-15 17:35:45,024:INFO:plot type: summary
2023-10-15 17:35:45,024:INFO:Creating TreeExplainer
2023-10-15 17:35:45,098:INFO:Compiling shap values
2023-10-15 17:35:46,101:INFO:Visual Rendered Successfully
2023-10-15 17:35:46,102:INFO:interpret_model() successfully completed......................................
2023-10-15 17:37:23,729:INFO:Initializing predict_model()
2023-10-15 17:37:23,730:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027600FCACA0>)
2023-10-15 17:37:23,730:INFO:Checking exceptions
2023-10-15 17:37:23,730:INFO:Preloading libraries
2023-10-15 17:37:23,733:INFO:Set up data.
2023-10-15 17:37:23,739:INFO:Set up index.
2023-10-15 17:49:41,730:INFO:Initializing plot_model()
2023-10-15 17:49:41,737:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, system=True)
2023-10-15 17:49:41,737:INFO:Checking exceptions
2023-10-15 17:49:41,806:INFO:Preloading libraries
2023-10-15 17:49:41,836:INFO:Copying training dataset
2023-10-15 17:49:41,836:INFO:Plot type: feature_all
2023-10-15 17:49:41,905:WARNING:No coef_ found. Trying feature_importances_
2023-10-15 17:49:42,232:INFO:Visual Rendered Successfully
2023-10-15 17:49:43,061:INFO:plot_model() successfully completed......................................
2023-10-15 17:52:22,685:INFO:Initializing predict_model()
2023-10-15 17:52:22,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x0000027600FCAC10>)
2023-10-15 17:52:22,685:INFO:Checking exceptions
2023-10-15 17:52:22,685:INFO:Preloading libraries
2023-10-15 17:52:22,690:INFO:Set up data.
2023-10-15 17:52:22,710:INFO:Set up index.
2023-10-15 17:57:55,560:INFO:Initializing save_model()
2023-10-15 17:57:55,561:INFO:save_model(model=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, model_name=exp_01_catboost, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                    transformer=OneHotEncoder(cols=['Chest_pain',
                                                                    'Resting_ECG',
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-10-15 17:57:55,561:INFO:Adding model into prep_pipe
2023-10-15 17:57:55,572:INFO:exp_01_catboost.pkl saved in current working directory
2023-10-15 17:57:55,602:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Peak_exercise_ST_segment',
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 <catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>)],
         verbose=False)
2023-10-15 17:57:55,602:INFO:save_model() successfully completed......................................
2023-10-15 17:58:06,289:INFO:Initializing load_model()
2023-10-15 17:58:06,289:INFO:load_model(model_name=exp_01_catboost, platform=None, authentication=None, verbose=True)
2023-10-15 17:58:36,275:INFO:Initializing finalize_model()
2023-10-15 17:58:36,275:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-15 17:58:36,275:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>
2023-10-15 17:58:36,278:INFO:Initializing create_model()
2023-10-15 17:58:36,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002767D352E20>, estimator=<catboost.core.CatBoostClassifier object at 0x000002767D38C8B0>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-15 17:58:36,278:INFO:Checking exceptions
2023-10-15 17:58:36,281:INFO:Importing libraries
2023-10-15 17:58:36,281:INFO:Copying training dataset
2023-10-15 17:58:36,281:INFO:Defining folds
2023-10-15 17:58:36,282:INFO:Declaring metric variables
2023-10-15 17:58:36,282:INFO:Importing untrained model
2023-10-15 17:58:36,282:INFO:Declaring custom model
2023-10-15 17:58:36,282:INFO:CatBoost Classifier Imported successfully
2023-10-15 17:58:36,285:INFO:Cross validation set to False
2023-10-15 17:58:36,285:INFO:Fitting Model
2023-10-15 17:58:36,428:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000027603EBBA60>)],
         verbose=False)
2023-10-15 17:58:36,428:INFO:create_model() successfully completed......................................
2023-10-15 17:58:36,547:INFO:_master_model_container: 22
2023-10-15 17:58:36,547:INFO:_display_container: 13
2023-10-15 17:58:36,576:INFO:Pipeline(memory=FastMemory(location=C:\Users\zaian\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Resting_blood_pressure',
                                             'Serum_cholestrol',
                                             'Max_heart_rate_achieved',
                                             'ST_depression',
                                             'Number_of_major_vessels'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_f...
                                                                    'Thal'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x0000027603EBBA60>)],
         verbose=False)
2023-10-15 17:58:36,576:INFO:finalize_model() successfully completed......................................
